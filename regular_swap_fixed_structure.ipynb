{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import _linear\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from plot_module import text_plot\n",
    "from plot_module import structure_vocabulary_plots\n",
    "from plot_module import ComparePlots\n",
    "\n",
    "from model_module import maybe_download\n",
    "from model_module import read_data\n",
    "from model_module import check_not_one_byte\n",
    "from model_module import id2char\n",
    "from model_module import char2id\n",
    "from model_module import BatchGenerator\n",
    "from model_module import characters\n",
    "from model_module import batches2string\n",
    "from model_module import logprob\n",
    "from model_module import sample_distribution\n",
    "from model_module import MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of not one byte characters:  0\n",
      "min order index:  9\n",
      "max order index:  255\n",
      "total number of characters:  196\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('enwik8_filtered'):\n",
    "    if not os.path.exists('enwik8'):\n",
    "        filename = maybe_download('enwik8.zip', 36445475)\n",
    "    full_text = read_data(filename)\n",
    "    new_text = u\"\"\n",
    "    new_text_list = list()\n",
    "    for i in range(len(full_text)):\n",
    "        if (i+1) % 10000000 == 0:\n",
    "            print(\"%s characters are filtered\" % i)\n",
    "        if ord(full_text[i]) < 256:\n",
    "            new_text_list.append(full_text[i])\n",
    "    text = new_text.join(new_text_list)\n",
    "    del new_text_list\n",
    "    del new_text\n",
    "    del full_text\n",
    "\n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)\n",
    "    \n",
    "    f = open('enwik8_filtered', 'w')\n",
    "    f.write(text.encode('utf8'))\n",
    "    f.close()\n",
    "    \n",
    "else:\n",
    "    f = open('enwik8_filtered', 'r')\n",
    "    text = f.read().decode('utf8')\n",
    "    f.close() \n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99350000 n in the February 1934 riots, anarchists divided over a 'united \n",
      "10000 ture in Mutual Aid: A Factor of Evolution (1897). Subsequent ana\n"
     ]
    }
   ],
   "source": [
    "#different\n",
    "offset = 20000\n",
    "valid_size = 10000\n",
    "valid_text = text[offset:offset+valid_size]\n",
    "train_text = text[offset+valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  \t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\n",
      "char2id(u'a') = 67,  char2id(u'z') = 92,  char2id(u' ') = 2\n",
      "id2char(78) = l,  id2char(156) = Ø,  id2char(140) = È\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = number_of_characters\n",
    "vocabulary = list()\n",
    "characters_positions_in_vocabulary = list()\n",
    "\n",
    "character_position_in_vocabulary = 0\n",
    "for i in range(256):\n",
    "    if present_characters_indices[i]:\n",
    "        vocabulary.append(unichr(i))\n",
    "        characters_positions_in_vocabulary.append(character_position_in_vocabulary)\n",
    "        character_position_in_vocabulary += 1\n",
    "    else:\n",
    "        characters_positions_in_vocabulary.append(-1)\n",
    "\n",
    "\n",
    "string_vocabulary = u\"\"\n",
    "for i in range(vocabulary_size):\n",
    "    string_vocabulary += vocabulary[i]\n",
    "print(\"Vocabulary: \", string_vocabulary)\n",
    "print(\"char2id(u'a') = %s,  char2id(u'z') = %s,  char2id(u' ') = %s\" % (char2id(u'a', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u'z', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u' ', characters_positions_in_vocabulary)))\n",
    "print(\"id2char(78) = %s,  id2char(156) = %s,  id2char(140) = %s\" % (id2char(78,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(156,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(140,\n",
    "                                                                            vocabulary)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'n in the Fe', u\".\\n* ''[[Con\", u\"oldier's so\", u'\\xf6hm-Bawerk ', u'tification,', u' warrior, a', u'uot; would ', u' 115       ', u'orbata acid', u'>\\n      <co', u'ate, the co', u'other natio', u'ing the his', u'et bromine;', u' Christ&quo', u' average]] ', u' their home', u'ks and a ri', u'on]]/[[Joel', u' new era fo', u'aph that th', u' known as t', u's from the ', u'ast majorit', u'trips, thou', u'ent of regi', u'metric aspe', u'd named by ', u'Z</timestam', u'tude of 1 c', u'!&quot; [ht', u'o ==\\n\\n* [[D', u'[[Belarusia', u'iton]], Rus', u'ccessful si', u'es his theo', u' explain th', u' the South.', u'sing with a', u'd ball is h', u'e could des', u'[Friedrich ', u'th virtuall', u' foreign ac', u'variant in ', u'd and watch', u\"t; ''[[Foot\", u' became Lea', u'stern Europ', u' </contribu', u'ese terms n', u'arting in t', u'gence of th', u'of the cons', u'uickly swit', u', thus star', u'lly develop', u'g the offic', u'esult, the ', u'red HMMWV. ', u'ament is de', u'University ', u'&quot;&gt;1', u'solely deco']\n",
      "[u'ebruary 193', u'ncentrate (', u'ong.\\n\\n==Com', u' wrote exte', u', when used', u'and elder h', u' have had o', u'        Sas', u'do]]\\n[[fa: ', u'omment>fix<', u'ombined sal', u'ons who fol', u'story of th', u'; however, ', u'ot; (Mosiah', u' of .847 wa', u'e field [[O', u'idge of fur', u'l Schumache', u'or Battle.n', u'he animator', u'the [[Pacif', u' local [[co', u'ty of execu', u'ugh several', u'istrars, de', u'ects will b', u' [[Bede]] i', u'mp>\\n      <', u'centimetre.', u'ttp://www.e', u'Derivative ', u'an language', u'ssian physi', u'ingles to d', u'ory (ISBN 0', u'he ability ', u'. He was of', u'a synthesiz', u'his last co', u'scribe as e', u' von Wieser', u'ly no-one t', u'ctors or th', u' the first ', u'hed it grow', u'tball World', u'ader of the', u'pe, many of', u'utor>\\n     ', u'not only de', u'the mid-198', u'his scene (', u'spirators]]', u'tched from ', u'rting the S', u'ped than Ma', u'ces of [[Ea', u' leaders of', u' The M1114 ', u'eemed incom', u' System]]\\n*', u'14,772&lt;/', u'orative. Th']\n",
      "[u'tu']\n",
      "[u'ur']\n"
     ]
    }
   ],
   "source": [
    "batch_size_test=64\n",
    "num_unrollings_test=10\n",
    "\n",
    "train_batches_test = BatchGenerator(train_text,\n",
    "                                    batch_size_test,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    num_unrollings_test)\n",
    "valid_batches_test = BatchGenerator(valid_text,\n",
    "                                    1,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    1)\n",
    "\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class regular_swap(MODEL):\n",
    "    def layer(self, \n",
    "              inp_t,\n",
    "              state_t_minus_1,\n",
    "              memory_t_minus_1):\n",
    "        X_t = tf.concat(1, [inp_t,\n",
    "                            state_t_minus_1,\n",
    "                            memory_t_minus_1])\n",
    "        RES = tf.matmul(X_t, self.Matrix) + self.Bias\n",
    "        state_t = tf.tanh(RES)\n",
    "        return state_t\n",
    "\n",
    "    \n",
    "    def swap_iteration(self, inp, state, counter):\n",
    "        counter_update = tf.assign_add(counter, tf.constant(1, dtype=tf.int32))\n",
    "        with tf.control_dependencies([counter_update]):\n",
    "            swap = tf.equal(counter, tf.constant(self._swap_frequency))        \n",
    "        [memory, counter_update] = tf.cond(swap,\n",
    "                                           lambda: [state[0], counter.assign(tf.constant(0, dtype=tf.int32))],\n",
    "                                           lambda: [state[1], counter])\n",
    "        \n",
    "        with tf.control_dependencies([counter_update, memory]):\n",
    "            self.compare_memory_and_outputs = tf.equal(memory, state[0])\n",
    "            output = self.layer(inp,\n",
    "                                state[0],\n",
    "                                memory)\n",
    "        return output, [output, memory], swap, [counter_update]\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 swaps_per_run,\n",
    "                 num_layers,\n",
    "                 num_nodes,\n",
    "                 swap_frequency,\n",
    "                 train_text,\n",
    "                 valid_text,\n",
    "                 seed=None,\n",
    "                 mean=0.,\n",
    "                 stddev='default',\n",
    "                 shift=0.,\n",
    "                 init_learning_rate=1.):\n",
    "        self._results = list()\n",
    "        self._batch_size = batch_size\n",
    "        self._vocabulary = vocabulary\n",
    "        self._vocabulary_size = len(vocabulary)\n",
    "        self._characters_positions_in_vocabulary = characters_positions_in_vocabulary\n",
    "        self._num_unrollings = swaps_per_run * swap_frequency\n",
    "        self._num_layers = num_layers\n",
    "        self._num_nodes = num_nodes\n",
    "        self._swap_frequency = swap_frequency\n",
    "        self._train_text = train_text\n",
    "        self._valid_text = valid_text\n",
    "        self._valid_size = len(valid_text)\n",
    "        \n",
    "        self._mean = mean\n",
    "        \n",
    "        self._stddev = list()\n",
    "        if stddev == 'default':\n",
    "            self._stddev = 1.0 * np.sqrt(1./(2*num_nodes[0] + vocabulary_size))\n",
    "        else:\n",
    "            self._stddev = stddev \n",
    "        self._shift = shift\n",
    "        self._init_learning_rate = init_learning_rate\n",
    "        \n",
    "        self._indices = {\"batch_size\": 0,\n",
    "                         \"num_unrollings\": 1,\n",
    "                         \"num_layers\": 2,\n",
    "                         \"num_nodes\": 3,\n",
    "                         \"half_life\": 4,\n",
    "                         \"decay\": 5,\n",
    "                         \"num_steps\": 6,\n",
    "                         \"averaging_number\": 7,\n",
    "                         \"swap_frequency\":8,\n",
    "                         \"init_mean\": 9,\n",
    "                         \"init_stddev\": 10,\n",
    "                         \"init_shift\": 11,\n",
    "                         \"init_learning_rate\": 12,\n",
    "                         \"type\": 13}\n",
    "        self._graph = tf.Graph()\n",
    "        \n",
    "        self._last_num_steps = 0\n",
    "        with self._graph.as_default(): \n",
    "            with self._graph.device('/gpu:0'): \n",
    "                if seed is not None:\n",
    "                    tf.set_random_seed(random.randint(-2*10**9, 2*10**9))\n",
    "                self.Matrix = tf.Variable(tf.truncated_normal([self._vocabulary_size + 2*self._num_nodes[0],\n",
    "                                                               self._num_nodes[0]],\n",
    "                                                              mean=self._mean,\n",
    "                                                              stddev=self._stddev))\n",
    "                self.Bias = tf.Variable([self._shift for _ in range(self._num_nodes[0])])\n",
    "\n",
    "                # classifier \n",
    "                weights = tf.Variable(tf.truncated_normal([self._num_nodes[-1], self._vocabulary_size], stddev = 0.1))\n",
    "                bias = tf.Variable(tf.zeros([self._vocabulary_size]))\n",
    "                \n",
    "                \"\"\"swap frequency\"\"\" \n",
    "                self._freq = tf.constant(self._swap_frequency, dtype=tf.int32)\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS train data\"\"\"\n",
    "                self._train_data = list()\n",
    "                for _ in range(self._num_unrollings + 1):\n",
    "                    self._train_data.append(\n",
    "                        tf.placeholder(tf.float32, shape=[self._batch_size, self._vocabulary_size]))\n",
    "                train_inputs = self._train_data[: self._num_unrollings]\n",
    "                train_labels = self._train_data[1:]  # labels are inputs shifted by one time step.\n",
    "                # Unrolled LSTM loop.\n",
    "\n",
    "                saved_state = [tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False),\n",
    "                               tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False)]\n",
    "                \n",
    "                \"\"\"global step\"\"\"\n",
    "                self._global_step = tf.Variable(0)\n",
    "                \n",
    "                self.compare_memory_and_outputs = 0\n",
    "\n",
    "                outputs = list()\n",
    "                state = saved_state\n",
    "                \"\"\"counter after swap\"\"\"\n",
    "                for inp_idx, inp in enumerate(train_inputs):\n",
    "                    if inp_idx % self._swap_frequency == 0:\n",
    "                        memory = state[0]\n",
    "                    else:\n",
    "                        memory = state[1]\n",
    "                    output = self.layer(inp,\n",
    "                                        state[0],\n",
    "                                        memory)\n",
    "                    state = [output, memory]\n",
    "                    outputs.append(output)\n",
    "\n",
    "                save_list = list()\n",
    "                save_list.append(saved_state[0].assign(state[0]))\n",
    "                save_list.append(saved_state[1].assign(state[1]))\n",
    "                \n",
    "                \"\"\"skip operation\"\"\"\n",
    "                self._skip_operation = tf.group(*save_list)\n",
    "\n",
    "                with tf.control_dependencies(save_list):\n",
    "                        # Classifier.\n",
    "                    logits = tf.nn.xw_plus_b(tf.concat(0, outputs), weights, bias)\n",
    "                    \"\"\"loss\"\"\"\n",
    "                    self._loss = tf.reduce_mean(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                            logits, tf.concat(0, train_labels)))\n",
    "                # Optimizer.\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS half life and decay\"\"\"\n",
    "                self._half_life = tf.placeholder(tf.int32)\n",
    "                self._decay = tf.placeholder(tf.float32)\n",
    "                \"\"\"learning rate\"\"\"\n",
    "                self._learning_rate = tf.train.exponential_decay(self._init_learning_rate,\n",
    "                                                                 self._global_step,\n",
    "                                                                 self._half_life,\n",
    "                                                                 self._decay,\n",
    "                                                                 staircase=True)\n",
    "                optimizer = tf.train.GradientDescentOptimizer(self._learning_rate)\n",
    "                gradients, v = zip(*optimizer.compute_gradients(self._loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "                \"\"\"optimizer\"\"\"\n",
    "                self._optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=self._global_step)\n",
    "                \"\"\"train prediction\"\"\"\n",
    "                self._train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "                # Sampling and validation eval: batch 1, no unrolling.\n",
    "                saved_sample_state = list()\n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                \"\"\"PLACEHOLDER sample input\"\"\"\n",
    "                self._sample_input = tf.placeholder(tf.float32, shape=[1, self._vocabulary_size])\n",
    "                \n",
    "                \"\"\"counter after swap\"\"\"\n",
    "                sample_counter = tf.Variable(0, trainable=True)\n",
    "                counter_update = [sample_counter]\n",
    "                \n",
    "                reset_list = list()\n",
    "                reset_list.append(saved_sample_state[0].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "                reset_list.append(saved_sample_state[1].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "                reset_list.append(sample_counter.assign(tf.constant(0, dtype=tf.int32)))\n",
    "\n",
    "                \"\"\"reset sample state\"\"\"\n",
    "                self._reset_sample_state = tf.group(*reset_list)\n",
    "                \n",
    "                \"\"\"counter after swap\"\"\"\n",
    "                sample_counter = tf.Variable(0, trainable=True)\n",
    "                sample_counter_update = [sample_counter]\n",
    "                \n",
    "                with tf.control_dependencies(sample_counter_update):\n",
    "                    sample_output, sample_state, _, sample_counter_update = self.swap_iteration(self._sample_input, saved_sample_state, sample_counter)\n",
    "\n",
    "\n",
    "                sample_save_list = list()\n",
    "                sample_save_list.append(saved_sample_state[0].assign(sample_state[0]))\n",
    "                sample_save_list.append(saved_sample_state[1].assign(sample_state[1]))\n",
    "\n",
    "                with tf.control_dependencies(sample_save_list):\n",
    "                    \"\"\"sample prediction\"\"\"\n",
    "                    self._sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, weights, bias)) \n",
    "                \n",
    "                \n",
    "                \"\"\"saver\"\"\"\n",
    "                self.saver = tf.train.Saver(max_to_keep=None)\n",
    "                            \n",
    "                        \n",
    "    \n",
    "    def _generate_metadata(self, half_life, decay, num_averaging_iterations):\n",
    "        metadata = list()\n",
    "        metadata.append(self._batch_size)\n",
    "        metadata.append(self._num_unrollings)\n",
    "        metadata.append(self._num_layers)\n",
    "        metadata.append(self._num_nodes)\n",
    "        metadata.append(half_life)\n",
    "        metadata.append(decay)\n",
    "        metadata.append(self._last_num_steps)\n",
    "        metadata.append(num_averaging_iterations)\n",
    "        metadata.append(self._swap_frequency)\n",
    "        metadata.append(self._mean)\n",
    "        metadata.append(self._stddev)\n",
    "        metadata.append(self._shift)\n",
    "        metadata.append(self._init_learning_rate)\n",
    "        metadata.append('regular_swap')\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = regular_swap(64,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 2,\n",
    "                 1,\n",
    "                 [128],\n",
    "                     5,\n",
    "                 train_text,\n",
    "                 valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 5.269365 learning rate: 1.000000\n",
      "Percentage_of correct: 0.00%\n",
      "\n",
      "random:\n",
      "================================================================================\n",
      "9xFÔõÒB$zXÒü¡òpñJ:±öcûí«¸ªúÝx \\úuçØËT\\z¬Ýäõ°n\t^Ç°wÏ*0!´\\Ý1ê«hÛ÷jÊõõmNÛ)Ã7ÆB]¼ú\n",
      "I[9$¡vZS),¶IÑQô£ãÌ}®V(¬[!?b9ÚJj%IøiiaU{D×-ÌDwwDÍ?)À|Q%ªg\"I£k³!Öa´½·;mFGCÞ\n",
      "PÙ\n",
      "´½\t¿úueÝJ/¾7P_FªäsÍlzbÁpÀâéú:þÕÌXýÂÛ±KÖ|Ûoé§KÓGPZk«Ì}C1÷7üèìdëÀÎªsÐ-2b(@ÉÐ³'qy\n",
      "OR\tg[%$íW\\VFÆËÛ?(ìahJ\"ÐaÂ?'Lß7(iã K{m°ì+Âi6å|15OàMmö²}®ÑR©eLJZF,GñºG8êW\"*±NázAÅ\n",
      "¡=!ºf«J§ë³crÿôòg·¾oÍµ¥ÐCæ%CcÔoçBrvàáübB8a.®\t<·¤4ToÁ»×Ñ¾_S,@}ê¾¬FUØá!ó=2'ûÄT­øzj\n",
      "================================================================================\n",
      "\n",
      "from fuse:\n",
      "================================================================================\n",
      "0. fuse: my name is\n",
      "my name isJ)²×`lnÛXºÐ3úË-7àa]Á6Kv\n",
      "`ýÞsl?°sAxÀÇ?FDöb_&©;)ËÀ0`K¯ó®AäÐëN(àx·6ZJgç ,rZãÉåÑHo\n",
      "1. fuse: december elegy\n",
      "december elegyåÏ4ÆóGWïe`f\n",
      "ÅËI(Ë±-òªà'r±Èâ-ÛHËG©äcbH>g5¶S{Í*¯ n6®6jÐRZÃvÌÄñ»U('t¿´¹¯NË³Ë¨·ëóÎ\n",
      "2. fuse: they have done\n",
      "they have done?(FÏ°Áâ¶,dúÓ´\"fÏèíï_g³BRZû}l¤¬º$Ý-d£¨ï«§M­!£]ÌlûÎTùÉüX½¿f~©ýÜw±}fõOtW»Ùw\\&pl\n",
      "================================================================================\n",
      "Validation percentage of correct: 12.99%\n",
      "\n",
      "Average loss at step 200: 3.587457 learning rate: 1.000000\n",
      "Percentage_of correct: 13.89%\n",
      "Validation percentage of correct: 16.38%\n",
      "\n",
      "Average loss at step 400: 2.961737 learning rate: 0.900000\n",
      "Percentage_of correct: 24.41%\n",
      "Validation percentage of correct: 24.94%\n",
      "\n",
      "Average loss at step 600: 2.708346 learning rate: 0.900000\n",
      "Percentage_of correct: 29.73%\n",
      "Validation percentage of correct: 30.13%\n",
      "\n",
      "Average loss at step 800: 2.579477 learning rate: 0.810000\n",
      "Percentage_of correct: 30.82%\n",
      "Validation percentage of correct: 31.83%\n",
      "\n",
      "Average loss at step 1000: 2.508469 learning rate: 0.729000\n",
      "Percentage_of correct: 31.87%\n",
      "Validation percentage of correct: 33.21%\n",
      "\n",
      "Average loss at step 1200: 2.461585 learning rate: 0.729000\n",
      "Percentage_of correct: 32.97%\n",
      "Validation percentage of correct: 27.68%\n",
      "\n",
      "Average loss at step 1400: 2.430712 learning rate: 0.656100\n",
      "Percentage_of correct: 33.53%\n",
      "Validation percentage of correct: 33.88%\n",
      "\n",
      "Average loss at step 1600: 2.350793 learning rate: 0.656100\n",
      "Percentage_of correct: 35.62%\n",
      "Validation percentage of correct: 35.02%\n",
      "\n",
      "Average loss at step 1800: 2.364964 learning rate: 0.590490\n",
      "Percentage_of correct: 35.74%\n",
      "Validation percentage of correct: 34.91%\n",
      "\n",
      "Average loss at step 2000: 2.326262 learning rate: 0.531441\n",
      "Percentage_of correct: 38.05%\n",
      "\n",
      "random:\n",
      "================================================================================\n",
      "Ò&qtot;nfirg ChJmans.2\n",
      "2;3ss anh Wins corole The rioudh on i92urdaly sull Merilt\n",
      "1200]]\n",
      "*[[oermagiving Sthes\n",
      "*==Âht=[[U]]'' 1113]], Duppre:[[2\n",
      "* he [[TishenfS\n",
      " (\n",
      "¸abint iesornt [[K009his]]\n",
      "*½)ulino,|QE|ONóôo]]\n",
      "[[Rt:1920, -lewcind 2the Aobrad \n",
      "Sfaccons Ne le uger. PCon-&gt;AAM&gt; byÌvers,|1044-11398\n",
      "[[htuegans Ahová pold \n",
      "«ismo1. Af&lt;TT{-''8\n",
      "\n",
      "*[htridos]]\n",
      "* sested Marthed </ppabk]] [[Losorcer Sa} Tha\n",
      "================================================================================\n",
      "\n",
      "from fuse:\n",
      "================================================================================\n",
      "0. fuse: my name is\n",
      "my name is ricolutith I byco &lt;3&quot;.&quot;1]])}''&qwott E som&quot;1814Twed.\n",
      "\n",
      "      \n",
      "1. fuse: december elegy\n",
      "december elegy a=]]atorestoun'' MoolveW\n",
      "     Lip>119047N</id>\n",
      "* Ot.eat sulup3&quot;1192611931\n",
      "2. fuse: they have done\n",
      "they have doneriod>. Solmers]]\n",
      "[[Me:Anevsum&gt;)]]]/thest to FothP]</ad.)\n",
      "*''Ualeanelv]/Tæ|19\n",
      "================================================================================\n",
      "Validation percentage of correct: 32.61%\n",
      "\n",
      "Average loss at step 2200: 2.286253 learning rate: 0.531441\n",
      "Percentage_of correct: 37.24%\n",
      "Validation percentage of correct: 36.45%\n",
      "\n",
      "Average loss at step 2400: 2.255158 learning rate: 0.478297\n",
      "Percentage_of correct: 37.51%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2bb37bafd51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint_intermediate_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           fuse_texts=fuse_texts)\n\u001b[0m",
      "\u001b[0;32m/home/rumpelschtizhen/WIKI/model_module.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_stairs, decay, train_frequency, min_num_points, stop_percent, num_train_points_per_1_validation_point, averaging_number, optional_feed_dict, print_intermediate_results, half_life_fixed, add_operations, validation_add_operations, num_validation_prints, print_steps, validation_example_length, fuse_texts)\u001b[0m\n\u001b[1;32m    561\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             validation_result = session.run(validation_operations,\n\u001b[0;32m--> 563\u001b[0;31m                                                             {self._sample_input: b[0]})\n\u001b[0m\u001b[1;32m    564\u001b[0m                             \u001b[0mvalidation_percentage_of_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpercent_of_correct_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_add_operations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fuse_texts = [u'my name is', u'december elegy', u'they have done']\n",
    "model.run(30,\n",
    "          0.9,\n",
    "            200,\n",
    "            50,\n",
    "            3,\n",
    "            1,\n",
    "            20,\n",
    "            print_intermediate_results = True,\n",
    "          fuse_texts=fuse_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swap:  1\n",
      "Number of steps = 20000     Percentage = 47.52%     Time = 454s     Learning rate = 0.0424\n",
      "swap:  2\n",
      "Number of steps = 20000     Percentage = 47.13%     Time = 454s     Learning rate = 0.0424\n",
      "swap:  3\n",
      "Number of steps = 20000     Percentage = 47.17%     Time = 453s     Learning rate = 0.0424\n",
      "swap:  5\n",
      "Number of steps = 20000     Percentage = 47.16%     Time = 450s     Learning rate = 0.0424\n",
      "swap:  6\n",
      "Number of steps = 20000     Percentage = 47.36%     Time = 450s     Learning rate = 0.0424\n",
      "swap:  10\n",
      "Number of steps = 20000     Percentage = 47.17%     Time = 450s     Learning rate = 0.0424\n",
      "swap:  15\n",
      "Number of steps = 20000     Percentage = 47.33%     Time = 451s     Learning rate = 0.0424\n"
     ]
    }
   ],
   "source": [
    "num_unrollings = 30\n",
    "swap_values = [1, 2, 3, 5, 6, 10, 15]\n",
    "iter_num = 5\n",
    "results_GL = list()\n",
    "counter = 0    \n",
    "for swap_value in swap_values:\n",
    "    print(\"swap: \", swap_value)\n",
    "    model = regular_swap(64,\n",
    "                             vocabulary,\n",
    "                             characters_positions_in_vocabulary,\n",
    "                             num_unrollings / swap_value,\n",
    "                             1,\n",
    "                             [128],\n",
    "                             swap_value,\n",
    "                             train_text,\n",
    "                             valid_text)\n",
    "    model.simple_run(200,\n",
    "                         'regular_swap_fixed/variables/1_128_ns20000_stairs_30_ilr_1._nu_30sw%s' % (swap_value),\n",
    "                            20000,\n",
    "                               4000,\n",
    "                               5000,        #learning has a chance to be stopped after every block of steps\n",
    "                               30,\n",
    "                               0.9,\n",
    "                               3,\n",
    "                    fixed_num_steps=True)\n",
    "    results_GL.extend(model._results)\n",
    "    model.destroy()\n",
    "    del model\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling regular_swap_fixed/fixed_1_128_ns20000_hl667_dc0.9_nu30_sw1-15.pickle.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'regular_swap_fixed'\n",
    "file_name = 'fixed_1_128_ns20000_hl667_dc0.9_nu30_sw1-15.pickle'\n",
    "force = True\n",
    "pickle_dump = {'results_GL': results_GL}\n",
    "if not os.path.exists(folder_name):\n",
    "    try:\n",
    "        os.makedirs(folder_name)\n",
    "    except Exception as e:\n",
    "        print(\"Unable create folder '%s'\" % folder_name, ':', e)    \n",
    "print('Pickling %s.' % (folder_name + '/' + file_name))\n",
    "try:\n",
    "    with open(folder_name + '/' + file_name, 'wb') as f:\n",
    "        pickle.dump(pickle_dump, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', file_name, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'regular_swap_fixed'\n",
    "pickle_file = 'fixed_1_128_ns20000_hl667_dc0.9_nu30_sw1-15.pickle'\n",
    "\n",
    "with open(folder_name + '/' + pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  results_GL = save['results_GL']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plot_module import ComparePlots\n",
    "\n",
    "regular_swap_plots = ComparePlots('regular_swap')\n",
    "regular_swap_plots.add_network(results_GL, model._indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layout_variable': None, 'fixed': None, 'data': [{'y': [47.51666666666663, 47.13151041666667, 47.16666666666666, 47.16145833333334, 47.36432291666666, 47.17135416666668, 47.33151041666668], 'x': [1, 2, 3, 5, 6, 10, 15], 'layout_value': None}], 'x_variable': ('swap_frequency', None), 'several_networks': False}\n",
      "There is no labels on plot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:1288: UserWarning: findfont: Font family [u'normal'] not found. Falling back to Bitstream Vera Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEgCAYAAABmYA5zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc9ea48b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data, _ = regular_swap_plots.one_key_layout_data('regular_swap_1',\n",
    "                                         'swap_frequency',\n",
    "                                         None,\n",
    "                                                     averaging=False)\n",
    "print(plot_data[0])\n",
    "regular_swap_plots.save_layout(plot_data[0],\n",
    "                    'swap frequency effect (half life: 667, decay: 0.9)',\n",
    "                    ['swap_frequency_effect', 'plots'],\n",
    "                    'fixed_nn128;ns20000;hl667;dc0.9',\n",
    "                              continious=[True])\n",
    "regular_swap_plots.draw(plot_data[0], 'swap frequency effect (half life: 667, decay: 0.9)',\n",
    "                       continious=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
