{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import _linear\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from plot_module import text_plot\n",
    "from plot_module import structure_vocabulary_plots\n",
    "from plot_module import ComparePlots\n",
    "\n",
    "from model_module import maybe_download\n",
    "from model_module import read_data\n",
    "from model_module import check_not_one_byte\n",
    "from model_module import id2char\n",
    "from model_module import char2id\n",
    "from model_module import BatchGenerator\n",
    "from model_module import characters\n",
    "from model_module import batches2string\n",
    "from model_module import logprob\n",
    "from model_module import sample_distribution\n",
    "from model_module import MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of not one byte characters:  0\n",
      "min order index:  9\n",
      "max order index:  255\n",
      "total number of characters:  196\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('enwik8_filtered'):\n",
    "    if not os.path.exists('enwik8'):\n",
    "        filename = maybe_download('enwik8.zip', 36445475)\n",
    "    full_text = read_data(filename)\n",
    "    new_text = u\"\"\n",
    "    new_text_list = list()\n",
    "    for i in range(len(full_text)):\n",
    "        if (i+1) % 10000000 == 0:\n",
    "            print(\"%s characters are filtered\" % i)\n",
    "        if ord(full_text[i]) < 256:\n",
    "            new_text_list.append(full_text[i])\n",
    "    text = new_text.join(new_text_list)\n",
    "    del new_text_list\n",
    "    del new_text\n",
    "    del full_text\n",
    "\n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)\n",
    "    \n",
    "    f = open('enwik8_filtered', 'w')\n",
    "    f.write(text.encode('utf8'))\n",
    "    f.close()\n",
    "    \n",
    "else:\n",
    "    f = open('enwik8_filtered', 'r')\n",
    "    text = f.read().decode('utf8')\n",
    "    f.close() \n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99337500 side of the leftist milieu. It often focuses on the individual r\n",
      "22500 ture in Mutual Aid: A Factor of Evolution (1897). Subsequent ana\n"
     ]
    }
   ],
   "source": [
    "#different\n",
    "offset = 20000\n",
    "valid_size = 22500\n",
    "valid_text = text[offset:offset+valid_size]\n",
    "train_text = text[offset+valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  \t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\n",
      "char2id(u'a') = 67,  char2id(u'z') = 92,  char2id(u' ') = 2\n",
      "id2char(78) = l,  id2char(156) = Ø,  id2char(140) = È\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = number_of_characters\n",
    "vocabulary = list()\n",
    "characters_positions_in_vocabulary = list()\n",
    "\n",
    "character_position_in_vocabulary = 0\n",
    "for i in range(256):\n",
    "    if present_characters_indices[i]:\n",
    "        vocabulary.append(unichr(i))\n",
    "        characters_positions_in_vocabulary.append(character_position_in_vocabulary)\n",
    "        character_position_in_vocabulary += 1\n",
    "    else:\n",
    "        characters_positions_in_vocabulary.append(-1)\n",
    "\n",
    "\n",
    "string_vocabulary = u\"\"\n",
    "for i in range(vocabulary_size):\n",
    "    string_vocabulary += vocabulary[i]\n",
    "print(\"Vocabulary: \", string_vocabulary)\n",
    "print(\"char2id(u'a') = %s,  char2id(u'z') = %s,  char2id(u' ') = %s\" % (char2id(u'a', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u'z', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u' ', characters_positions_in_vocabulary)))\n",
    "print(\"id2char(78) = %s,  id2char(156) = %s,  id2char(140) = %s\" % (id2char(78,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(156,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(140,\n",
    "                                                                            vocabulary)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'side of the', u'though the ', u'; \\n|colspan', u'ustrian.asp', u'e most cons', u' Gaul, whic', u'h can be pr', u'pitome of t', u' first team', u'Roussimoff ', u'col. In Feb', u's]] - [[Uni', u'g oven, dis', u' exposed to', u' wrote the ', u'ird.  He co', u'a]].  The O', u'nd Lower Lo', u'In another ', u'or sensitiv', u'ents used b', u'e Chile]] i', u\"achelor's d\", u'till employ', u'flexibility', u'nects all c', u'variety of ', u' [[Cheshire', u' sleek, str', u' have led t', u'ongside man', u'eature.\\n\\n==', u'st and cent', u'oblems incl', u'aunched his', u'310)\\n\\n*&quo', u'character n', u'ward-winnin', u'ularly elec', u'expense of ', u\", '''Eyes W\", u';Hesperus i', u'sletter was', u'uction comp', u's. The conc', u'ow]] for mo', u'l football ', u' [[Hayek So', u'ed [[transl', u'amp>2006-03', u'ears, even ', u' plates for', u'[post punk]', u' equal righ', u'ng with onl', u'his English', u'lling the r', u's of Parlia', u' England.  ', u're being ma', u'endered in ', u'okomo]]\\n***', u'D&gt;&lt;FO', u'e natural r']\n",
      "[u'e leftist m', u' relationsh', u'n=&quot;7&q', u'p What is A', u'scipuous fe', u'ch lost Gau', u'rovided leg', u'the [[neocl', u'm to win wh', u' as the big', u'bruary, 200', u'ited States', u'shwasher, a', u'o sulfides.', u' Book of Mo', u'ontinued to', u'Orioles als', u'otharingia ', u' version of', u've function', u'by stand-al', u'in the Span', u'degrees. Be', u'y slow hang', u'y. To my su', u'campus buil', u' rice prepa', u'e]]; more r', u'reamlined h', u'to accusati', u'ny other re', u'=Phonology=', u'tral [[Asia', u'lude the [[', u's own label', u'ot;Those wh', u'named &quot', u'ng journali', u'ctronic sou', u' critical w', u\"Wide Shut''\", u'is Phosphor', u's abandoned', u'pany also m', u'cepts of [[', u'ore details', u' team|West ', u'ociety]], w', u'literation]', u'3-03T23:58:', u' decades, e', u'r maps of [', u']] bands li', u'hts to Cath', u'ly drums) f', u'h bride.  H', u'region. Mos', u'ament are l', u' [[Hans Hol', u'anufactured', u' revolution', u'*[[Purdue U', u'ONT SIZE=&q', u'rock was sc']\n",
      "[u'tu']\n",
      "[u'ur']\n"
     ]
    }
   ],
   "source": [
    "batch_size_test=64\n",
    "num_unrollings_test=10\n",
    "\n",
    "train_batches_test = BatchGenerator(train_text,\n",
    "                                    batch_size_test,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    num_unrollings_test)\n",
    "valid_batches_test = BatchGenerator(valid_text,\n",
    "                                    1,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    1)\n",
    "\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class adaptive_1(MODEL):\n",
    "    def layer(self, \n",
    "              inp_t,\n",
    "              state_t_minus_1,\n",
    "              memory_t_minus_1):\n",
    "        X_t = tf.concat(1, [inp_t,\n",
    "                            state_t_minus_1,\n",
    "                            memory_t_minus_1])\n",
    "        RES = tf.matmul(X_t, self.Matrix) + self.Bias\n",
    "        state_t = tf.tanh(RES)\n",
    "        return state_t\n",
    "\n",
    "    \n",
    "    def iteration(self, inp, state):\n",
    "        \n",
    "        output = self.layer(inp,\n",
    "                            state[0],\n",
    "                            state[1])\n",
    "        trigger = tf.sigmoid(tf.matmul(tf.concat(1, [inp, output, state[1]]), self.trigger_matrix) + self.trigger_bias)\n",
    "        memory_list = list()\n",
    "        current_batch_size = trigger.get_shape().as_list()[0]\n",
    "        ones = tf.ones([current_batch_size])\n",
    "        to_swap = tf.to_float(tf.greater(tf.reshape(trigger, [-1]), self.thresh))\n",
    "        memory = tf.transpose(tf.reshape(trigger, [-1])*tf.transpose(output)*to_swap + tf.transpose(state[1]) * (ones - to_swap))  \n",
    "        return output, [output, memory], trigger\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 num_unrollings,\n",
    "                 num_layers,\n",
    "                 num_nodes,\n",
    "                 init_bias,\n",
    "                 threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                 train_text,\n",
    "                 valid_text,\n",
    "                 mean=0.,\n",
    "                 stddev='default',\n",
    "                 shift=0.,\n",
    "                 init_learning_rate=1.):\n",
    "        self._results = list()\n",
    "        self._batch_size = batch_size\n",
    "        self._vocabulary = vocabulary\n",
    "        self._vocabulary_size = len(vocabulary)\n",
    "        self._characters_positions_in_vocabulary = characters_positions_in_vocabulary\n",
    "        self._num_unrollings = num_unrollings\n",
    "        self._num_layers = num_layers\n",
    "        self._num_nodes = num_nodes\n",
    "        self._init_bias = init_bias\n",
    "        self._threshold = threshold\n",
    "        self._train_text = train_text\n",
    "        self._valid_text = valid_text\n",
    "        self._valid_size = len(valid_text)\n",
    "        \n",
    "        self._mean = mean\n",
    "        \n",
    "        self._stddev = list()\n",
    "        if stddev == 'default':\n",
    "            self._stddev = 1.0 * np.sqrt(1./(num_nodes[0] + vocabulary_size))\n",
    "        else:\n",
    "            self._stddev = stddev\n",
    "            \n",
    "        self._shift = shift\n",
    "        self._init_learning_rate = init_learning_rate\n",
    "        \n",
    "        self._indices = {\"batch_size\": 0,\n",
    "                         \"num_unrollings\": 1,\n",
    "                         \"num_layers\": 2,\n",
    "                         \"num_nodes\": 3,\n",
    "                         \"half_life\": 4,\n",
    "                         \"decay\": 5,\n",
    "                         \"num_steps\": 6,\n",
    "                         \"averaging_number\": 7,\n",
    "                         \"init_bias\": 8,\n",
    "                         \"threshold\": 9,\n",
    "                         \"memory_fine\":10,\n",
    "                         \"init_mean\": 11,\n",
    "                         \"init_stddev\": 12,\n",
    "                         \"init_shift\": 13,\n",
    "                         \"init_learning_rate\": 14,\n",
    "                         \"type\": 15}\n",
    "        self._graph = tf.Graph()\n",
    "        \n",
    "        self._last_num_steps = 0\n",
    "        with self._graph.as_default(): \n",
    "            with self._graph.device('/gpu:0'): \n",
    "                self.Matrix = tf.Variable(tf.truncated_normal([self._vocabulary_size + 2*self._num_nodes[0],\n",
    "                                                               self._num_nodes[0]],\n",
    "                                                              mean=self._mean, stddev=self._stddev))\n",
    "                self.Bias = tf.Variable([self._shift for _ in range(self._num_nodes[0])])\n",
    "\n",
    "                # classifier \n",
    "                weights = tf.Variable(tf.truncated_normal([self._num_nodes[-1], self._vocabulary_size], stddev = 0.1))\n",
    "                bias = tf.Variable(tf.zeros([self._vocabulary_size]))\n",
    "                \n",
    "                self.trigger_matrix = tf.Variable(tf.truncated_normal([self._vocabulary_size + 2*self._num_nodes[0], 1], stddev = 0.1))\n",
    "                self.trigger_bias = tf.Variable([self._init_bias])\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS train data\"\"\"\n",
    "                self._train_data = list()\n",
    "                for _ in range(self._num_unrollings + 1):\n",
    "                    self._train_data.append(\n",
    "                        tf.placeholder(tf.float32, shape=[self._batch_size, self._vocabulary_size]))\n",
    "                train_inputs = self._train_data[: self._num_unrollings]\n",
    "                train_labels = self._train_data[1:]  # labels are inputs shifted by one time step.\n",
    "                # Unrolled LSTM loop.\n",
    "\n",
    "                saved_state = [tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False),\n",
    "                               tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False)]\n",
    "                \n",
    "                \"\"\"global step\"\"\"\n",
    "                self._global_step = tf.Variable(0)\n",
    "                \"\"\"self.thresh\"\"\"\n",
    "                if self._threshold['fixed']:\n",
    "                    self.thresh = tf.constant(self._threshold['min'])\n",
    "                else:\n",
    "                    thresh_range = self._threshold['max'] - self._threshold['min']\n",
    "                    self.thresh = tf.minimum(tf.constant(self._threshold['min']) + tf.to_float(self._global_step) / self._threshold['epochs'] * tf.constant(thresh_range), tf.constant(self._threshold['max']))\n",
    "                outputs = list()\n",
    "                state = saved_state\n",
    "                triggers = list()\n",
    "                for inp in train_inputs:\n",
    "                    output, state, current_trigger = self.iteration(inp, state)\n",
    "                    outputs.append(output)\n",
    "                    triggers.append(current_trigger)\n",
    "\n",
    "                save_list = list()\n",
    "                save_list.append(saved_state[0].assign(state[0]))\n",
    "                save_list.append(saved_state[1].assign(state[1]))\n",
    "                \n",
    "                \"\"\"skip operation\"\"\"\n",
    "                self._skip_operation = tf.group(*save_list)\n",
    "                \n",
    "                self.memory_fine = tf.placeholder(tf.float32)\n",
    "                with tf.control_dependencies(save_list):\n",
    "                        # Classifier.\n",
    "                    logits = tf.nn.xw_plus_b(tf.concat(0, outputs), weights, bias)\n",
    "                    \"\"\"loss\"\"\"\n",
    "                    self._loss = tf.reduce_mean(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                            logits, tf.concat(0, train_labels)))\n",
    "                    fact_loss = tf.reduce_mean(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                            logits, tf.concat(0, train_labels))) + self.memory_fine * tf.reduce_sum(tf.concat(1, triggers))\n",
    "                # Optimizer.\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS half life and decay\"\"\"\n",
    "                self._half_life = tf.placeholder(tf.int32)\n",
    "                self._decay = tf.placeholder(tf.float32)\n",
    "                \"\"\"learning rate\"\"\"\n",
    "                self._learning_rate = tf.train.exponential_decay(self._init_learning_rate,\n",
    "                                                                 self._global_step,\n",
    "                                                                 self._half_life,\n",
    "                                                                 self._decay,\n",
    "                                                                 staircase=True)\n",
    "                optimizer = tf.train.GradientDescentOptimizer(self._learning_rate)\n",
    "                gradients, v = zip(*optimizer.compute_gradients(fact_loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "                \"\"\"optimizer\"\"\"\n",
    "                self._optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=self._global_step)\n",
    "                \"\"\"train prediction\"\"\"\n",
    "                self._train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "                # Sampling and validation eval: batch 1, no unrolling.\n",
    "                saved_sample_state = list()\n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                \"\"\"PLACEHOLDER sample input\"\"\"\n",
    "                self._sample_input = tf.placeholder(tf.float32, shape=[1, self._vocabulary_size])\n",
    "\n",
    "                reset_list = list()\n",
    "                reset_list.append(saved_sample_state[0].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "                reset_list.append(saved_sample_state[1].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "\n",
    "                \"\"\"reset sample state\"\"\"\n",
    "                self._reset_sample_state = tf.group(*reset_list)\n",
    "                \n",
    "                \"\"\"trigger\"\"\"\n",
    "                sample_output, sample_state, self.trigger = self.iteration(self._sample_input, saved_sample_state)\n",
    "\n",
    "                sample_save_list = list()\n",
    "                sample_save_list.append(saved_sample_state[0].assign(sample_state[0]))\n",
    "                sample_save_list.append(saved_sample_state[1].assign(sample_state[1]))\n",
    "\n",
    "                with tf.control_dependencies(sample_save_list):\n",
    "                    \"\"\"sample prediction\"\"\"\n",
    "                    self._sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, weights, bias)) \n",
    "                \n",
    "                \n",
    "                \"\"\"saver\"\"\"\n",
    "                self.saver = tf.train.Saver(max_to_keep=None)\n",
    "                            \n",
    "                        \n",
    "    \n",
    "    def _generate_metadata(self, half_life, decay, num_averaging_iterations, optional_feed_dict):\n",
    "        metadata = list()\n",
    "        metadata.append(self._batch_size)\n",
    "        metadata.append(self._num_unrollings)\n",
    "        metadata.append(self._num_layers)\n",
    "        metadata.append(self._num_nodes)\n",
    "        metadata.append(half_life)\n",
    "        metadata.append(decay)\n",
    "        metadata.append(self._last_num_steps)\n",
    "        metadata.append(num_averaging_iterations)\n",
    "        metadata.append(self._init_bias)\n",
    "        metadata.append(dict(self._threshold))\n",
    "        metadata.append(optional_feed_dict['self.memory_fine'])\n",
    "        metadata.append(self._mean)\n",
    "        metadata.append(self._stddev)\n",
    "        metadata.append(self._shift)\n",
    "        metadata.append(self._init_learning_rate)\n",
    "        metadata.append('adaptive_1_with_trigger')\n",
    "        return metadata\n",
    "  \n",
    "    def get_triggers(self, session, num_strings=10, length=75, start_positions=None):\n",
    "        self._reset_sample_state.run()\n",
    "        self._valid_batches = BatchGenerator(self._valid_text,\n",
    "                                             1,\n",
    "                                             self._vocabulary_size,\n",
    "                                             self._characters_positions_in_vocabulary,\n",
    "                                             1)\n",
    "        if start_positions is None:\n",
    "            start_positions = list()\n",
    "            if self._valid_size / num_strings < length:\n",
    "                num_strings = self._valid_size / length\n",
    "            for i in range(num_strings):\n",
    "                start_positions.append(i* (self._valid_size / num_strings) + self._valid_size / num_strings / 2)\n",
    "            while self._valid_size - start_positions[-1] < length:\n",
    "                del start_positions[-1]\n",
    "        text_list = list()\n",
    "        trigger_list = list()\n",
    "        collect_triggers = False\n",
    "        letters_parsed = -1\n",
    "        for idx in range(self._valid_size):\n",
    "            b = self._valid_batches.next()\n",
    "            \n",
    "            if idx in start_positions or collect_triggers: \n",
    "                if letters_parsed == -1:\n",
    "                    letters_parsed = 0\n",
    "                    text = u\"\"\n",
    "                    t_list = list()\n",
    "                    collect_triggers = True\n",
    "                text += characters(b[0], self._vocabulary)[0]\n",
    "                t_list.append(self.trigger.eval({self._sample_input: b[0]}))\n",
    "                letters_parsed += 1\n",
    "                if letters_parsed >= length:\n",
    "                    collect_triggers = False\n",
    "                    trigger_list.append(t_list)\n",
    "                    text_list.append(text)\n",
    "                    letters_parsed = -1\n",
    "                    \n",
    "            _ = self._sample_prediction.eval({self._sample_input: b[0]})\n",
    "        return text_list, trigger_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = {'fixed': True, 'min': 0., 'max': 0.7, 'epochs': 10000}\n",
    "\n",
    "model = adaptive_1(64,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 30,\n",
    "                 1,\n",
    "                 [128],\n",
    "                 100.,\n",
    "                 threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                 train_text,\n",
    "                 valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 5.283900 learning rate: 1.000000\n",
      "Percentage_of correct: 0.00%\n",
      "\n",
      "random:\n",
      "================================================================================\n",
      "$ô®t3%cKgIi½ªö=þ$:q#j N5ÎeùµQ`-1¾®Ås\n",
      "Eej±Im8àìò*êl¶X3cså>Ü%D§­¨¿áÉÜÙC½Í.àöª¡)Ñg\n",
      "~åÎdÃ'rÞïÙß¿Ï±ôÆo­ÌqV¥ÚðÍ§hÂhJj±êyyaDáÕpGn¢KM8¬ëë!¯l²Ad»nfµðëì±¸ +îMI9÷uq^°<PxM\n",
      "¯4d¯tÞe¥YÄýu»Céã^©3ëP72Kêmöf5°`z_£,iòî±g*aö¥ã&#¶ât0GÉ.ôú¸ðÈ¢KÈÇð«íy:úãÃþüÇp´N ü\n",
      "¾û{N>Æ1[qÝâkF\\5È:Âå«b.ÚõÈk«+ï¯g_fl£ÿO»X>¹ø^qG÷òÝ½~F8í(Y7¬ßþFò[£X'/TÎkrªãa¹g¬ÃÔØd\n",
      ",<¬÷ÝÍþLNÐt¾:NnQ£êàa{=à¥'·¿pñyµ¬ÊSýI,èùzToF/]= 1ªÿ;ö]^ß>Å±aäÎÒ'¨û½äbbgP4Ò[pÈðªJ\n",
      "================================================================================\n",
      "Validation percentage of correct: 9.17%\n",
      "\n",
      "Average loss at step 200: 3.564994 learning rate: 1.000000\n",
      "Percentage_of correct: 14.07%\n",
      "Validation percentage of correct: 22.18%\n",
      "\n",
      "Average loss at step 400: 2.941634 learning rate: 0.900000\n",
      "Percentage_of correct: 25.36%\n",
      "Validation percentage of correct: 27.76%\n",
      "\n",
      "Average loss at step 600: 2.690653 learning rate: 0.900000\n",
      "Percentage_of correct: 29.42%\n",
      "Validation percentage of correct: 30.94%\n",
      "\n",
      "Average loss at step 800: 2.564064 learning rate: 0.810000\n",
      "Percentage_of correct: 32.54%\n",
      "Validation percentage of correct: 32.42%\n",
      "\n",
      "Average loss at step 1000: 2.449648 learning rate: 0.729000\n",
      "Percentage_of correct: 33.46%\n",
      "Validation percentage of correct: 34.44%\n",
      "\n",
      "Average loss at step 1200: 2.390335 learning rate: 0.729000\n",
      "Percentage_of correct: 35.03%\n",
      "Validation percentage of correct: 33.97%\n",
      "\n",
      "Average loss at step 1400: 2.349428 learning rate: 0.656100\n",
      "Percentage_of correct: 36.24%\n",
      "Validation percentage of correct: 36.40%\n",
      "\n",
      "Average loss at step 1600: 2.314262 learning rate: 0.656100\n",
      "Percentage_of correct: 36.92%\n",
      "Validation percentage of correct: 36.31%\n",
      "\n",
      "Average loss at step 1800: 2.287045 learning rate: 0.590490\n",
      "Percentage_of correct: 38.41%\n",
      "Validation percentage of correct: 36.03%\n",
      "\n",
      "Average loss at step 2000: 2.245830 learning rate: 0.531441\n",
      "Percentage_of correct: 38.47%\n",
      "\n",
      "random:\n",
      "================================================================================\n",
      "{Jong is ans) K  . GRo k|±R wor alto Znaby of rathlakd ind him Hilbias matiens a\n",
      "õiceshesÜ and him gloute of S IrAby, -\n",
      "\n",
      "| ''P| [[OUCen altybent sto elir Ry ''µh\n",
      "À, Wotw orvining Gy (St as the the crlthoreanwher unceld denent in]] of khes¡ ur\n",
      "nchereiny hishery furdit orment spab] o moly Bation, arapbour as hor[[rachof Bul\n",
      "¥otheoraboow Barteria conal abound [[Mare estan consremaria]] ear whi ( sofherll\n",
      "================================================================================\n",
      "Validation percentage of correct: 36.16%\n",
      "\n",
      "Average loss at step 2200: 2.209780 learning rate: 0.531441\n",
      "Percentage_of correct: 39.61%\n",
      "Validation percentage of correct: 36.98%\n",
      "\n",
      "Average loss at step 2400: 2.203274 learning rate: 0.478297\n",
      "Percentage_of correct: 39.93%\n",
      "Validation percentage of correct: 38.15%\n",
      "\n",
      "Average loss at step 2600: 2.179804 learning rate: 0.478297\n",
      "Percentage_of correct: 40.39%\n",
      "Validation percentage of correct: 36.80%\n",
      "\n",
      "Average loss at step 2800: 2.122873 learning rate: 0.430467\n",
      "Percentage_of correct: 42.14%\n",
      "Validation percentage of correct: 37.28%\n",
      "\n",
      "Average loss at step 3000: 2.137508 learning rate: 0.387420\n",
      "Percentage_of correct: 41.56%\n",
      "Validation percentage of correct: 38.03%\n",
      "\n",
      "Average loss at step 3200: 2.134293 learning rate: 0.387420\n",
      "Percentage_of correct: 41.53%\n",
      "Validation percentage of correct: 38.36%\n",
      "\n",
      "Average loss at step 3400: 2.125700 learning rate: 0.348678\n",
      "Percentage_of correct: 42.31%\n",
      "Validation percentage of correct: 39.13%\n",
      "\n",
      "Average loss at step 3600: 2.107551 learning rate: 0.348678\n",
      "Percentage_of correct: 42.68%\n",
      "Validation percentage of correct: 38.78%\n",
      "\n",
      "Average loss at step 3800: 2.098997 learning rate: 0.313810\n",
      "Percentage_of correct: 42.90%\n",
      "Validation percentage of correct: 40.01%\n",
      "\n",
      "Average loss at step 4000: 2.088689 learning rate: 0.282429\n",
      "Percentage_of correct: 42.94%\n",
      "\n",
      "random:\n",
      "================================================================================\n",
      "¹|Gabeae]]|\n",
      "\n",
      "}2 E1p13|118\n",
      "*'[[Koly]]\n",
      "[[ncs vis.lonspape powhumate peps, the Mugo\n",
      "^_ingoriagrod]]\n",
      "\n",
      "|Chruco alding the Pave Sutniesers of tacher miscer ard throded\n",
      "Ålande, has was nouncaubens to bisther sodean as Hal sondent stapting as a crand\n",
      "îdeaptaccl and manwen frrunite, by aser.  Back the righns]]\n",
      "\n",
      "''ki#-Bia ionister \n",
      "Ïhe in wns panate calss in a that is psecen forking hice an bate be. [[Theirated\n",
      "================================================================================\n",
      "Validation percentage of correct: 39.89%\n",
      "\n",
      "Average loss at step 4200: 2.072027 learning rate: 0.282429\n",
      "Percentage_of correct: 43.58%\n",
      "Validation percentage of correct: 40.44%\n",
      "\n",
      "Average loss at step 4400: 2.065778 learning rate: 0.254186\n",
      "Percentage_of correct: 43.73%\n",
      "Validation percentage of correct: 39.65%\n",
      "\n",
      "Average loss at step 4600: 2.063958 learning rate: 0.254186\n",
      "Percentage_of correct: 43.17%\n",
      "Validation percentage of correct: 40.21%\n",
      "\n",
      "Average loss at step 4800: 2.079837 learning rate: 0.228768\n",
      "Percentage_of correct: 42.79%\n",
      "Validation percentage of correct: 40.52%\n",
      "\n",
      "Average loss at step 5000: 2.050452 learning rate: 0.205891\n",
      "Percentage_of correct: 43.71%\n",
      "Validation percentage of correct: 40.41%\n",
      "\n",
      "Average loss at step 5200: 2.029951 learning rate: 0.205891\n",
      "Percentage_of correct: 44.71%\n",
      "Validation percentage of correct: 41.34%\n",
      "\n",
      "Average loss at step 5400: 2.042310 learning rate: 0.185302\n",
      "Percentage_of correct: 43.55%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3eb48060d638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0moptional_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptional_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             print_intermediate_results = True)\n\u001b[0m",
      "\u001b[0;32m/home/rumpelschtizhen/WIKI/model_module.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_stairs, decay, train_frequency, min_num_points, stop_percent, num_train_points_per_1_validation_point, averaging_number, optional_feed_dict, print_intermediate_results, half_life_fixed, add_operations, add_text_operations, print_steps, validation_add_operations, num_validation_prints, validation_example_length, fuse_texts)\u001b[0m\n\u001b[1;32m    662\u001b[0m                                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valid_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                                 validation_result = session.run(validation_operations,\n\u001b[0;32m--> 664\u001b[0;31m                                                                 {self._sample_input: b[0]})\n\u001b[0m\u001b[1;32m    665\u001b[0m                                 \u001b[0mvalidation_percentage_of_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpercent_of_correct_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mprint_intermediate_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optional_feed_dict = {'self.memory_fine': 0.0000001}\n",
    "model.run(30,\n",
    "          0.9,\n",
    "            200,\n",
    "            50,\n",
    "            3,\n",
    "            1,\n",
    "            20,\n",
    "          optional_feed_dict=optional_feed_dict,\n",
    "            print_intermediate_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     threshold:  0.5\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.63%     Time = 2286s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.40%     Time = 2266s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.41%     Time = 2261s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.57%     Time = 2258s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.66%     Time = 2255s     Learning rate = 0.0424\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.28%     Time = 2258s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.50%     Time = 2260s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.52%     Time = 2265s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.65%     Time = 2259s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.75%     Time = 2262s     Learning rate = 0.0424\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.67%     Time = 2260s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.70%     Time = 2261s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.60%     Time = 2260s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.64%     Time = 2258s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.18%     Time = 2263s     Learning rate = 0.0424\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.55%     Time = 2269s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.40%     Time = 2088s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.68%     Time = 1618s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.69%     Time = 1623s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.37%     Time = 1669s     Learning rate = 0.0424\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.61%     Time = 1679s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.82%     Time = 1673s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.69%     Time = 1810s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.66%     Time = 2272s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.74%     Time = 2268s     Learning rate = 0.0424\n",
      "     threshold:  0.7\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.77%     Time = 2269s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.71%     Time = 2262s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.34%     Time = 2270s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 48.79%     Time = 2271s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.24%     Time = 2269s     Learning rate = 0.0424\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.82%     Time = 2272s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 48.97%     Time = 2272s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.12%     Time = 2270s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.31%     Time = 2274s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.32%     Time = 2272s     Learning rate = 0.0424\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 48.99%     Time = 2272s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.23%     Time = 2263s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.61%     Time = 2274s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.64%     Time = 2270s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.53%     Time = 2274s     Learning rate = 0.0424\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.58%     Time = 2270s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.72%     Time = 2272s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.37%     Time = 2273s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.57%     Time = 2278s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.31%     Time = 2271s     Learning rate = 0.0424\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.91%     Time = 2275s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.73%     Time = 2281s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.44%     Time = 2256s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.59%     Time = 2278s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.56%     Time = 2276s     Learning rate = 0.0424\n",
      "     threshold:  0.9\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.70%     Time = 2283s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.79%     Time = 2276s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.68%     Time = 2277s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.21%     Time = 2278s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.20%     Time = 2274s     Learning rate = 0.0424\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.90%     Time = 2275s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.71%     Time = 2272s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.85%     Time = 2269s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 48.96%     Time = 2288s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.31%     Time = 2272s     Learning rate = 0.0424\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.63%     Time = 2266s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.79%     Time = 2275s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.54%     Time = 2277s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.15%     Time = 2281s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.55%     Time = 2277s     Learning rate = 0.0424\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.39%     Time = 2281s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.60%     Time = 2284s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.50%     Time = 2282s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.29%     Time = 2283s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.60%     Time = 2277s     Learning rate = 0.0424\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 40000     Percentage = 49.61%     Time = 2276s     Learning rate = 0.0424\n",
      "init bias:  0.5\n",
      "Number of steps = 40000     Percentage = 49.47%     Time = 2278s     Learning rate = 0.0424\n",
      "init bias:  1.0\n",
      "Number of steps = 40000     Percentage = 49.41%     Time = 2267s     Learning rate = 0.0424\n",
      "init bias:  2.0\n",
      "Number of steps = 40000     Percentage = 49.24%     Time = 2284s     Learning rate = 0.0424\n",
      "init bias:  5.0\n",
      "Number of steps = 40000     Percentage = 49.06%     Time = 2271s     Learning rate = 0.0424\n"
     ]
    }
   ],
   "source": [
    "#.001, .01, .1, .2, .3, .5, .7,\n",
    "threshold_values = [.5, .7, .9]\n",
    "memory_fine_values = [.00001, .000001, .0000001, .00000001, .0]\n",
    "init_bias_values = [0., .5, 1., 2., 5.]\n",
    "threshold = {'fixed': True, 'min': .2, 'max': .7, 'epochs': 10000}\n",
    "optional_feed_dict = {'self.memory_fine': 0.001}\n",
    "results_GL = list()\n",
    "for threshold_value in threshold_values:\n",
    "    print(' '*4, \"threshold: \", threshold_value)\n",
    "    threshold['min'] = threshold_value\n",
    "    for memory_fine_value in memory_fine_values:\n",
    "        print(' '*2, \"memory fine: \", memory_fine_value)\n",
    "        optional_feed_dict['self.memory_fine'] = memory_fine_value\n",
    "        for init_bias_value in init_bias_values:\n",
    "            print(\"init bias: \", init_bias_value)\n",
    "            model = adaptive_1(64,\n",
    "                             vocabulary,\n",
    "                             characters_positions_in_vocabulary,\n",
    "                             30,\n",
    "                             1,\n",
    "                             [128],\n",
    "                             init_bias_value,\n",
    "                             threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                             train_text,\n",
    "                             valid_text)\n",
    "            model.simple_run(100,\n",
    "                           'adaptive_1_with_memory/variables/1_128_nu30_ns40k_dcs30/th%s_mf%s_ib%s' % (threshold_value, memory_fine_value, init_bias_value),\n",
    "                           40000,\n",
    "                           4000,\n",
    "                           5000,        #learning has a chance to be stopped after every block of steps\n",
    "                           30,\n",
    "                           0.9,\n",
    "                           3,\n",
    "                           optional_feed_dict=optional_feed_dict,\n",
    "                            fixed_num_steps=True)\n",
    "            results_GL.extend(model._results)\n",
    "            model.destroy()\n",
    "            del model\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling adaptive_1_with_trigger/thr_from0.5_to0.9_adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf0-1e-5.pickle.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'adaptive_1_with_trigger'\n",
    "file_name = 'thr_from0.5_to0.9_adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf0-1e-5.pickle'\n",
    "force = True\n",
    "pickle_dump = {'results_GL': results_GL}\n",
    "if not os.path.exists(folder_name):\n",
    "    try:\n",
    "        os.makedirs(folder_name)\n",
    "    except Exception as e:\n",
    "        print(\"Unable create folder '%s'\" % folder_name, ':', e)    \n",
    "print('Pickling %s.' % (folder_name + '/' + file_name))\n",
    "try:\n",
    "    with open(folder_name + '/' + file_name, 'wb') as f:\n",
    "        pickle.dump(pickle_dump, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', file_name, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'adaptive_1_with_trigger'\n",
    "pickle_file = 'thr_from0.5_to0.9_adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf0-1e-5.pickle'\n",
    "\n",
    "with open(folder_name + '/' + pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  results_last = save['results_GL']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'adaptive_1_with_trigger'\n",
    "pickle_file = 'thr_from0.001_to0.3_adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf0-1e-5.pickle'\n",
    "\n",
    "with open(folder_name + '/' + pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  results_first = save['results_GL']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_GL = list(results_first)\n",
    "results_GL.extend(results_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     threshold:  0.001\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.17%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.19%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.20%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.27%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.32%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.53%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.32%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.30%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.59%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.47%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.31%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.50%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.39%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.45%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.37%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.36%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.47%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.18%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.50%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.15%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.43%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.39%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.20%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.43%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.46%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.01\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.87%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.69%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.02%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.98%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.90%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.11%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.32%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.16%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.30%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.31%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.24%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.42%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.36%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.37%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.37%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.36%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.38%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.32%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.12%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.45%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.49%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.42%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.48%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.42%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.22%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.1\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.73%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.68%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.72%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.98%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.09%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.99%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.80%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.88%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.95%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.87%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.06%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.11%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.28%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.36%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.40%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.52%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.52%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.54%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.53%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.30%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.51%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.50%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.42%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.73%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.42%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.2\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.70%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.78%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.71%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.04%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.94%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.90%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.01%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.99%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.97%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.68%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.95%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.85%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.14%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.25%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.41%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.48%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.56%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.35%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.43%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.36%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.50%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.63%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.40%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.44%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.41%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.3\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.33%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.90%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.98%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.51%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.17%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.08%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.16%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.24%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.19%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.95%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.91%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.81%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.84%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.19%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.47%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.41%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.70%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.45%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.43%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.49%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.58%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.45%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.62%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.61%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.28%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.5\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.89%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.46%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.83%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.83%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.77%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.83%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.20%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.01%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.37%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.89%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.80%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.92%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.91%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.01%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.47%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.33%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.85%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.74%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.54%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.40%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.66%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.80%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.51%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.40%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.54%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.7\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.79%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.18%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.69%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.62%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.78%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.62%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.91%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.96%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.22%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.96%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.06%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.00%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.89%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.91%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.40%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.16%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.90%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.86%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.74%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.47%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 48.83%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.78%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.57%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.65%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.39%     Time = 0s     Learning rate = 0.0148\n",
      "     threshold:  0.9\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.75%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.67%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.77%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.27%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.19%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.55%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.77%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.67%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 48.96%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 48.89%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.70%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.24%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 49.13%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.28%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.49%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.70%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 49.05%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.96%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.49%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.47%     Time = 0s     Learning rate = 0.0148\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "Number of steps = 0     Percentage = 49.72%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  0.5\n",
      "Number of steps = 0     Percentage = 48.85%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  1.0\n",
      "Number of steps = 0     Percentage = 48.71%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  2.0\n",
      "Number of steps = 0     Percentage = 49.19%     Time = 0s     Learning rate = 0.0148\n",
      "init bias:  5.0\n",
      "Number of steps = 0     Percentage = 49.43%     Time = 0s     Learning rate = 0.0148\n"
     ]
    }
   ],
   "source": [
    "#.001, .01, .1, .2, .3, .5, .7,\n",
    "threshold_values = [.001, .01, .1, .2, .3, .5, .7, .9]\n",
    "memory_fine_values = [.00001, .000001, .0000001, .00000001, .0]\n",
    "init_bias_values = [0., .5, 1., 2., 5.]\n",
    "threshold = {'fixed': True, 'min': .2, 'max': .7, 'epochs': 10000}\n",
    "optional_feed_dict = {'self.memory_fine': 0.001}\n",
    "results_GL = list()\n",
    "for threshold_value in threshold_values:\n",
    "    print(' '*4, \"threshold: \", threshold_value)\n",
    "    threshold['min'] = threshold_value\n",
    "    for memory_fine_value in memory_fine_values:\n",
    "        print(' '*2, \"memory fine: \", memory_fine_value)\n",
    "        optional_feed_dict['self.memory_fine'] = memory_fine_value\n",
    "        for init_bias_value in init_bias_values:\n",
    "            print(\"init bias: \", init_bias_value)\n",
    "            model = adaptive_1(64,\n",
    "                             vocabulary,\n",
    "                             characters_positions_in_vocabulary,\n",
    "                             30,\n",
    "                             1,\n",
    "                             [128],\n",
    "                             init_bias_value,\n",
    "                             threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                             train_text,\n",
    "                             valid_text)\n",
    "            save_path = 'adaptive_1_with_trigger/variables/1_128_nu30_ns40k_dcs30/th%s_mf%s_ib%s' % (threshold_value, memory_fine_value, init_bias_value)\n",
    "            model.get_result(save_path,\n",
    "                             100,\n",
    "                   20000,\n",
    "                   40,\n",
    "                   0.9,\n",
    "                           optional_feed_dict=optional_feed_dict,  \n",
    "                        fixed_num_steps=True)\n",
    "            results_GL.extend(model._results)\n",
    "            model.destroy()\n",
    "            del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling adaptive_1_with_memory/adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf.pickle.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'adaptive_1_with_memory'\n",
    "file_name = 'adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf.pickle'\n",
    "force = True\n",
    "pickle_dump = {'results_GL': results_GL}\n",
    "if not os.path.exists(folder_name):\n",
    "    try:\n",
    "        os.makedirs(folder_name)\n",
    "    except Exception as e:\n",
    "        print(\"Unable create folder '%s'\" % folder_name, ':', e)    \n",
    "print('Pickling %s.' % (folder_name + '/' + file_name))\n",
    "try:\n",
    "    with open(folder_name + '/' + file_name, 'wb') as f:\n",
    "        pickle.dump(pickle_dump, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', file_name, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'adaptive_1_with_memory'\n",
    "pickle_file = 'adaptive_1_with_trigger_ns_40000_hl_1333_dc_0.9_ib0_5_ilr1_thr.001_.9_mf.pickle'\n",
    "\n",
    "with open(folder_name + '/' + pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  results_GL = save['results_GL']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot_module import ComparePlots\n",
    "plot_options = {'x': 'log'}\n",
    "\n",
    "adaptive_1_plots = ComparePlots('adaptive_1_with_trigger')\n",
    "adaptive_1_plots.add_network(results_GL, model._indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:1288: UserWarning: findfont: Font family [u'normal'] not found. Falling back to Bitstream Vera Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    }
   ],
   "source": [
    "plot_options={'x': 'log'}\n",
    "threshold_values = [.001, .01, .1, .2, .3, .5, .7, .9]\n",
    "memory_fine_values = [.00001, .000001, .0000001, .00000001, .0]\n",
    "init_bias_values = [0., .5, 1., 2., 5.]\n",
    "threshold = {'fixed': True, 'min': .2, 'max': .7, 'epochs': 10000}\n",
    "optional_feed_dict = {'self.memory_fine': 0.001}\n",
    "results_GL = list()\n",
    "plot_data, _ = adaptive_1_plots.one_key_layout_data('adaptive_1_with_trigger_1',\n",
    "                                         'memory_fine',\n",
    "                                         \"threshold['min']\",\n",
    "                                                        fixed_variables_list=['init_bias'])\n",
    "for one_plot_data in plot_data:\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'memory fine effect',\n",
    "                    ['plots', 'init_bias', 'mf_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;ib%s' % one_plot_data['fixed'][('init_bias', None)],\n",
    "                     plot_options=plot_options)\n",
    "    \n",
    "plot_data, _ = adaptive_1_plots.one_key_layout_data('adaptive_1_with_trigger_1',\n",
    "                                         \"threshold['min']\",\n",
    "                                                           'memory_fine',\n",
    "                                                        fixed_variables_list=['init_bias'])\n",
    "for idx, one_plot_data in enumerate(plot_data):\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'threshold effect',\n",
    "                    ['plots', 'init_bias', 'thr_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;ib%s_log' % one_plot_data['fixed'][('init_bias', None)],\n",
    "                     plot_options=plot_options)\n",
    "for idx, one_plot_data in enumerate(plot_data):\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'threshold effect',\n",
    "                    ['plots', 'init_bias', 'thr_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;ib%s' % one_plot_data['fixed'][('init_bias', None)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data, _ = adaptive_1_plots.one_key_layout_data('adaptive_1_with_trigger_1',\n",
    "                                         'memory_fine',\n",
    "                                         \"init_bias\",\n",
    "                                                        fixed_variables_list=[\"threshold['min']\"])\n",
    "for one_plot_data in plot_data:\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'memory fine effect',\n",
    "                    ['plots', \"threshold['min']\", 'mf_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;thr%s' % one_plot_data['fixed'][('threshold', 'min')],\n",
    "                     plot_options=plot_options)\n",
    "    \n",
    "plot_data, _ = adaptive_1_plots.one_key_layout_data('adaptive_1_with_trigger_1',\n",
    "                                         \"init_bias\",\n",
    "                                         'memory_fine',\n",
    "                                                        fixed_variables_list=[\"threshold['min']\"])\n",
    "for one_plot_data in plot_data:\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'init_bias effect',\n",
    "                    ['plots', \"threshold['min']\", 'ib_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;thr%s' % one_plot_data['fixed'][('threshold', 'min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data, _ = adaptive_1_plots.one_key_layout_data('adaptive_1_with_trigger_1',\n",
    "                                         \"threshold['min']\",\n",
    "                                         \"init_bias\",\n",
    "                                                        fixed_variables_list=['memory_fine'])\n",
    "for one_plot_data in plot_data:\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'threshold effect',\n",
    "                    ['plots', \"memory_fine\", 'thr_dep_log'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;mf%s' % one_plot_data['fixed'][('memory_fine', None)],\n",
    "                     plot_options=plot_options)\n",
    "for one_plot_data in plot_data:\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'threshold effect',\n",
    "                    ['plots', \"memory_fine\", 'thr_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;mf%s' % one_plot_data['fixed'][('memory_fine', None)])\n",
    "    \n",
    "plot_data, _ = adaptive_1_plots.one_key_layout_data('adaptive_1_with_trigger_1',\n",
    "                                         \"init_bias\",\n",
    "                                         \"threshold['min']\",\n",
    "                                                        fixed_variables_list=['memory_fine'])\n",
    "for one_plot_data in plot_data:\n",
    "    adaptive_1_plots.save_layout(one_plot_data,\n",
    "                    'init_bias effect',\n",
    "                    ['plots', \"memory_fine\", 'ib_dep'],\n",
    "                    'nn128;ns40000;dc0.9;dcs30;mf%s' % one_plot_data['fixed'][('memory_fine', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_results = dict()\n",
    "for result in results_GL:\n",
    "    key1 = result['metadata'][model._indices['threshold']]['min']\n",
    "    key2 = result['metadata'][model._indices['memory_fine']]\n",
    "    key3 = result['metadata'][model._indices['init_bias']]\n",
    "    if key1 not in short_results.keys():\n",
    "        short_results[key1] = dict()\n",
    "        short_results[key1][key2] = dict()\n",
    "        short_results[key1][key2][key3] = result['data']['train']['percentage'][-1]\n",
    "    elif key2 not in short_results[key1].keys():\n",
    "        short_results[key1][key2] = dict()\n",
    "        short_results[key1][key2][key3] = result['data']['train']['percentage'][-1]\n",
    "    elif key3 not in short_results[key1][key2].keys():\n",
    "        short_results[key1][key2][key3] = result['data']['train']['percentage'][-1]\n",
    "    else:\n",
    "        print('Error! Skipping')\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_results.keys(): [0.5, 0.1, 0.2, 0.001, 0.3, 0.9, 0.7, 0.01]\n",
      "short_results[first].keys(): [1e-08, 0.0, 1e-06, 1e-05, 1e-07]\n",
      "short_results[first][first].keys(): [0.0, 0.5, 2.0, 5.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('short_results.keys():', short_results.keys())\n",
    "print('short_results[first].keys():', short_results[short_results.keys()[0]].keys())\n",
    "print('short_results[first][first].keys():', short_results[short_results.keys()[0]][short_results[short_results.keys()[0]].keys()[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     threshold:  0.001\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.01\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.1\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.2\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.3\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.5\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.7\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "     threshold:  0.9\n",
      "   memory fine:  1e-05\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-06\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-07\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  1e-08\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n",
      "   memory fine:  0.0\n",
      "init bias:  0.0\n",
      "init bias:  0.5\n",
      "init bias:  1.0\n",
      "init bias:  2.0\n",
      "init bias:  5.0\n"
     ]
    }
   ],
   "source": [
    "#.001, .01, .1, .2, .3, .5, .7,\n",
    "threshold_values = [.001, .01, .1, .2, .3, .5, .7, .9]\n",
    "memory_fine_values = [.00001, .000001, .0000001, .00000001, .0]\n",
    "init_bias_values = [0., .5, 1., 2., 5.]\n",
    "threshold = {'fixed': True, 'min': .2, 'max': .7, 'epochs': 10000}\n",
    "optional_feed_dict = {'self.memory_fine': 0.001}\n",
    "results_GL = list()\n",
    "for threshold_value in threshold_values:\n",
    "    print(' '*4, \"threshold: \", threshold_value)\n",
    "    threshold['min'] = threshold_value\n",
    "    for memory_fine_value in memory_fine_values:\n",
    "        print(' '*2, \"memory fine: \", memory_fine_value)\n",
    "        optional_feed_dict['self.memory_fine'] = memory_fine_value\n",
    "        for init_bias_value in init_bias_values:\n",
    "            print(\"init bias: \", init_bias_value)\n",
    "            model = adaptive_1(64,\n",
    "                             vocabulary,\n",
    "                             characters_positions_in_vocabulary,\n",
    "                             30,\n",
    "                             1,\n",
    "                             [128],\n",
    "                             init_bias_value,\n",
    "                             threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                             train_text,\n",
    "                             valid_text)\n",
    "            text_list, trigger_list = model.run_for_analitics(model.get_triggers,\n",
    "                                                            'adaptive_1_with_memory/variables/1_128_nu30_ns40k_dcs30/th%s_mf%s_ib%s' % (threshold_value, memory_fine_value, init_bias_value),\n",
    "                                                            [300, 75, None])\n",
    "            triggers = list()\n",
    "            for text_number, text in enumerate(text_list):\n",
    "                trig = list()\n",
    "                text_triggers = trigger_list[text_number]\n",
    "                for text_trigger in text_triggers:\n",
    "                    trig.append(text_trigger[0, 0])\n",
    "                triggers.append(trig)\n",
    "            structure_vocabulary_plots(text_list,\n",
    "                                       triggers,\n",
    "                                       'triggers for letter position (threshold %s, memory fine %s, init_bias %s, result %.2f%%)' % (threshold_value, \n",
    "                                                                                                                                     memory_fine_value,\n",
    "                                                                                                                                     init_bias_value,\n",
    "                                                                                                                                     short_results[threshold_value][memory_fine_value][init_bias_value]),\n",
    "                                       'mean trigger',\n",
    "                                       ['adaptive_1_with_trigger',\n",
    "                                        'triggers',\n",
    "                                        'init_bias_%s' % init_bias_value,\n",
    "                                        'memory_fine_%s' % memory_fine_value,\n",
    "                                        'threshold_%s_pcnt %.2f' % (threshold_value, short_results[threshold_value][memory_fine_value][init_bias_value])],\n",
    "                                       'mean_triggers128_ib%s_th%s_mf%s' % (init_bias_value, threshold_value, memory_fine_value),\n",
    "                                       ylims=[0., 1.],\n",
    "                                       ylims_fixed=True,\n",
    "                                       threshold=threshold_value,\n",
    "                                       show=False)\n",
    "            for i in range(50):\n",
    "                text_plot(text_list[i],\n",
    "                          triggers[i],\n",
    "                          'trigger',\n",
    "                          'mean trigger values (threshold %s, memory fine %s, init_bias %s, result %.2f%%)' % (threshold_value, \n",
    "                                                                                                               memory_fine_value,\n",
    "                                                                                                               init_bias_value,\n",
    "                                                                                                               short_results[threshold_value][memory_fine_value][init_bias_value]),\n",
    "                          ['adaptive_1_with_trigger',\n",
    "                           'triggers',\n",
    "                           'init_bias_%s' % init_bias_value,\n",
    "                           'memory_fine_%s' % memory_fine_value,\n",
    "                           'threshold_%s_pcnt %.2f' % (threshold_value, short_results[threshold_value][memory_fine_value][init_bias_value]),\n",
    "                           'text_plots'],\n",
    "                          'triggers128_ib%s_th%s_mf%s#%s' % (init_bias_value, threshold_value, memory_fine_value, i),\n",
    "                          threshold=threshold_value,\n",
    "                          show=False)\n",
    "            model.destroy()\n",
    "            del model\n",
    "            gc.collect()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
