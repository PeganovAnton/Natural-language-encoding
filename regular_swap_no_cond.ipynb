{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import _linear\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from plot_module import text_plot\n",
    "from plot_module import structure_vocabulary_plots\n",
    "from plot_module import ComparePlots\n",
    "\n",
    "from model_module import maybe_download\n",
    "from model_module import read_data\n",
    "from model_module import check_not_one_byte\n",
    "from model_module import id2char\n",
    "from model_module import char2id\n",
    "from model_module import BatchGenerator\n",
    "from model_module import characters\n",
    "from model_module import batches2string\n",
    "from model_module import logprob\n",
    "from model_module import sample_distribution\n",
    "from model_module import MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of not one byte characters:  0\n",
      "min order index:  9\n",
      "max order index:  255\n",
      "total number of characters:  196\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('enwik8_filtered'):\n",
    "    if not os.path.exists('enwik8'):\n",
    "        filename = maybe_download('enwik8.zip', 36445475)\n",
    "    full_text = read_data(filename)\n",
    "    new_text = u\"\"\n",
    "    new_text_list = list()\n",
    "    for i in range(len(full_text)):\n",
    "        if (i+1) % 10000000 == 0:\n",
    "            print(\"%s characters are filtered\" % i)\n",
    "        if ord(full_text[i]) < 256:\n",
    "            new_text_list.append(full_text[i])\n",
    "    text = new_text.join(new_text_list)\n",
    "    del new_text_list\n",
    "    del new_text\n",
    "    del full_text\n",
    "\n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)\n",
    "    \n",
    "    f = open('enwik8_filtered', 'w')\n",
    "    f.write(text.encode('utf8'))\n",
    "    f.close()\n",
    "    \n",
    "else:\n",
    "    f = open('enwik8_filtered', 'r')\n",
    "    text = f.read().decode('utf8')\n",
    "    f.close() \n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99350000 n in the February 1934 riots, anarchists divided over a 'united \n",
      "10000 ture in Mutual Aid: A Factor of Evolution (1897). Subsequent ana\n"
     ]
    }
   ],
   "source": [
    "#different\n",
    "offset = 20000\n",
    "valid_size = 10000\n",
    "valid_text = text[offset:offset+valid_size]\n",
    "train_text = text[offset+valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  \t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\n",
      "char2id(u'a') = 67,  char2id(u'z') = 92,  char2id(u' ') = 2\n",
      "id2char(78) = l,  id2char(156) = Ø,  id2char(140) = È\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = number_of_characters\n",
    "vocabulary = list()\n",
    "characters_positions_in_vocabulary = list()\n",
    "\n",
    "character_position_in_vocabulary = 0\n",
    "for i in range(256):\n",
    "    if present_characters_indices[i]:\n",
    "        vocabulary.append(unichr(i))\n",
    "        characters_positions_in_vocabulary.append(character_position_in_vocabulary)\n",
    "        character_position_in_vocabulary += 1\n",
    "    else:\n",
    "        characters_positions_in_vocabulary.append(-1)\n",
    "\n",
    "\n",
    "string_vocabulary = u\"\"\n",
    "for i in range(vocabulary_size):\n",
    "    string_vocabulary += vocabulary[i]\n",
    "print(\"Vocabulary: \", string_vocabulary)\n",
    "print(\"char2id(u'a') = %s,  char2id(u'z') = %s,  char2id(u' ') = %s\" % (char2id(u'a', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u'z', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u' ', characters_positions_in_vocabulary)))\n",
    "print(\"id2char(78) = %s,  id2char(156) = %s,  id2char(140) = %s\" % (id2char(78,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(156,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(140,\n",
    "                                                                            vocabulary)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'n in the Fe', u\".\\n* ''[[Con\", u\"oldier's so\", u'\\xf6hm-Bawerk ', u'tification,', u' warrior, a', u'uot; would ', u' 115       ', u'orbata acid', u'>\\n      <co', u'ate, the co', u'other natio', u'ing the his', u'et bromine;', u' Christ&quo', u' average]] ', u' their home', u'ks and a ri', u'on]]/[[Joel', u' new era fo', u'aph that th', u' known as t', u's from the ', u'ast majorit', u'trips, thou', u'ent of regi', u'metric aspe', u'd named by ', u'Z</timestam', u'tude of 1 c', u'!&quot; [ht', u'o ==\\n\\n* [[D', u'[[Belarusia', u'iton]], Rus', u'ccessful si', u'es his theo', u' explain th', u' the South.', u'sing with a', u'd ball is h', u'e could des', u'[Friedrich ', u'th virtuall', u' foreign ac', u'variant in ', u'd and watch', u\"t; ''[[Foot\", u' became Lea', u'stern Europ', u' </contribu', u'ese terms n', u'arting in t', u'gence of th', u'of the cons', u'uickly swit', u', thus star', u'lly develop', u'g the offic', u'esult, the ', u'red HMMWV. ', u'ament is de', u'University ', u'&quot;&gt;1', u'solely deco']\n",
      "[u'ebruary 193', u'ncentrate (', u'ong.\\n\\n==Com', u' wrote exte', u', when used', u'and elder h', u' have had o', u'        Sas', u'do]]\\n[[fa: ', u'omment>fix<', u'ombined sal', u'ons who fol', u'story of th', u'; however, ', u'ot; (Mosiah', u' of .847 wa', u'e field [[O', u'idge of fur', u'l Schumache', u'or Battle.n', u'he animator', u'the [[Pacif', u' local [[co', u'ty of execu', u'ugh several', u'istrars, de', u'ects will b', u' [[Bede]] i', u'mp>\\n      <', u'centimetre.', u'ttp://www.e', u'Derivative ', u'an language', u'ssian physi', u'ingles to d', u'ory (ISBN 0', u'he ability ', u'. He was of', u'a synthesiz', u'his last co', u'scribe as e', u' von Wieser', u'ly no-one t', u'ctors or th', u' the first ', u'hed it grow', u'tball World', u'ader of the', u'pe, many of', u'utor>\\n     ', u'not only de', u'the mid-198', u'his scene (', u'spirators]]', u'tched from ', u'rting the S', u'ped than Ma', u'ces of [[Ea', u' leaders of', u' The M1114 ', u'eemed incom', u' System]]\\n*', u'14,772&lt;/', u'orative. Th']\n",
      "[u'tu']\n",
      "[u'ur']\n"
     ]
    }
   ],
   "source": [
    "batch_size_test=64\n",
    "num_unrollings_test=10\n",
    "\n",
    "train_batches_test = BatchGenerator(train_text,\n",
    "                                    batch_size_test,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    num_unrollings_test)\n",
    "valid_batches_test = BatchGenerator(valid_text,\n",
    "                                    1,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    1)\n",
    "\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class regular_swap(MODEL):\n",
    "    def layer(self, \n",
    "              inp_t,\n",
    "              state_t_minus_1,\n",
    "              memory_t_minus_1):\n",
    "        X_t = tf.concat(1, [inp_t,\n",
    "                            state_t_minus_1,\n",
    "                            memory_t_minus_1])\n",
    "        RES = tf.matmul(X_t, self.Matrix) + self.Bias\n",
    "        state_t = tf.tanh(RES)\n",
    "        return state_t\n",
    "\n",
    "    \n",
    "    def swap_iteration(self, inp, state, counter, compare):\n",
    "        new_counter = counter + 1\n",
    "        swap = tf.equal(new_counter, tf.constant(self._swap_frequency)) \n",
    "        output_coef = tf.to_float(swap)\n",
    "        memory_coef = tf.constant(1.) - output_coef\n",
    "        memory = output_coef * state[0] + memory_coef * state[1]\n",
    "        new_counter = tf.mod(new_counter, self._swap_frequency)\n",
    "        counter_update = tf.assign(counter, new_counter)\n",
    "        compare = tf.equal(memory, state[0])\n",
    "        with tf.control_dependencies([counter_update]):\n",
    "            output = self.layer(inp,\n",
    "                                    state[0],\n",
    "                                    memory)\n",
    "        return output, [output, memory], swap, [counter_update], compare\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 num_unrollings,\n",
    "                 num_layers,\n",
    "                 num_nodes,\n",
    "                 swap_frequency,\n",
    "                 train_text,\n",
    "                 valid_text,\n",
    "                 seed=None,\n",
    "                 mean=0.,\n",
    "                 stddev='default',\n",
    "                 shift=0.,\n",
    "                 init_learning_rate=1.):\n",
    "        self._results = list()\n",
    "        self._batch_size = batch_size\n",
    "        self._vocabulary = vocabulary\n",
    "        self._vocabulary_size = len(vocabulary)\n",
    "        self._characters_positions_in_vocabulary = characters_positions_in_vocabulary\n",
    "        self._num_unrollings = num_unrollings\n",
    "        self._num_layers = num_layers\n",
    "        self._num_nodes = num_nodes\n",
    "        self._swap_frequency = swap_frequency\n",
    "        self._train_text = train_text\n",
    "        self._valid_text = valid_text\n",
    "        self._valid_size = len(valid_text)\n",
    "        \n",
    "        self._mean = mean\n",
    "        \n",
    "        self._stddev = list()\n",
    "        if stddev == 'default':\n",
    "            self._stddev = 1.0 * np.sqrt(1./(2*num_nodes[0] + vocabulary_size))\n",
    "        else:\n",
    "            self._stddev = stddev \n",
    "        self._shift = shift\n",
    "        self._init_learning_rate = init_learning_rate\n",
    "        \n",
    "        self._indices = {\"batch_size\": 0,\n",
    "                         \"num_unrollings\": 1,\n",
    "                         \"num_layers\": 2,\n",
    "                         \"num_nodes\": 3,\n",
    "                         \"half_life\": 4,\n",
    "                         \"decay\": 5,\n",
    "                         \"num_steps\": 6,\n",
    "                         \"averaging_number\": 7,\n",
    "                         \"swap_frequency\":8,\n",
    "                         \"init_mean\": 9,\n",
    "                         \"init_stddev\": 10,\n",
    "                         \"init_shift\": 11,\n",
    "                         \"init_learning_rate\": 12,\n",
    "                         \"type\": 13}\n",
    "        self._graph = tf.Graph()\n",
    "        \n",
    "        self._last_num_steps = 0\n",
    "        with self._graph.as_default(): \n",
    "            with self._graph.device('/gpu:0'): \n",
    "                if seed is not None:\n",
    "                    tf.set_random_seed(random.randint(-2*10**9, 2*10**9))\n",
    "                self.Matrix = tf.Variable(tf.truncated_normal([self._vocabulary_size + 2*self._num_nodes[0],\n",
    "                                                               self._num_nodes[0]],\n",
    "                                                              mean=self._mean,\n",
    "                                                              stddev=self._stddev))\n",
    "                self.Bias = tf.Variable([self._shift for _ in range(self._num_nodes[0])])\n",
    "\n",
    "                # classifier \n",
    "                weights = tf.Variable(tf.truncated_normal([self._num_nodes[-1], self._vocabulary_size], stddev = 0.1))\n",
    "                bias = tf.Variable(tf.zeros([self._vocabulary_size]))\n",
    "                \n",
    "                \"\"\"swap frequency\"\"\" \n",
    "                self._freq = tf.constant(self._swap_frequency, dtype=tf.int32)\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS train data\"\"\"\n",
    "                self._train_data = list()\n",
    "                for i in range(self._num_unrollings + 1):\n",
    "                    self._train_data.append(\n",
    "                        tf.placeholder(tf.float32, shape=[self._batch_size, self._vocabulary_size], name=('inp_%s'%i)))\n",
    "                train_inputs = self._train_data[: self._num_unrollings]\n",
    "                train_labels = self._train_data[1:]  # labels are inputs shifted by one time step.\n",
    "                # Unrolled LSTM loop.\n",
    "\n",
    "                saved_state = [tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False),\n",
    "                               tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False)]\n",
    "                \n",
    "                \"\"\"global step\"\"\"\n",
    "                self._global_step = tf.Variable(0)\n",
    "                \n",
    "                self.compare_memory_and_outputs = 0\n",
    "\n",
    "                outputs = list()\n",
    "                swaps = list()\n",
    "                state = saved_state\n",
    "                \"\"\"counter after swap\"\"\"\n",
    "                self.counter = tf.Variable(0, trainable=True)\n",
    "                counter_update = [self.counter]\n",
    "                for inp in train_inputs:\n",
    "                    with tf.control_dependencies(counter_update):\n",
    "                        output, state, swap, counter_update, self.compare_memory_and_outputs = self.swap_iteration(inp, state, self.counter, self.compare_memory_and_outputs)\n",
    "                        outputs.append(output)\n",
    "                        swaps.append(swap)\n",
    "                self.swaps = tf.pack(swaps)\n",
    "                self.swaps = tf.to_float(self.swaps)\n",
    "\n",
    "                save_list = list()\n",
    "                save_list.append(saved_state[0].assign(state[0]))\n",
    "                save_list.append(saved_state[1].assign(state[1]))\n",
    "                \n",
    "                \"\"\"skip operation\"\"\"\n",
    "                self._skip_operation = tf.group(*save_list)\n",
    "\n",
    "                with tf.control_dependencies(save_list):\n",
    "                        # Classifier.\n",
    "                    logits = tf.nn.xw_plus_b(tf.concat(0, outputs), weights, bias)\n",
    "                    \"\"\"loss\"\"\"\n",
    "                    self._loss = tf.reduce_mean(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                            logits, tf.concat(0, train_labels)))\n",
    "                # Optimizer.\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS half life and decay\"\"\"\n",
    "                self._half_life = tf.placeholder(tf.int32, name='half_life')\n",
    "                self._decay = tf.placeholder(tf.float32, name='decay')\n",
    "                \"\"\"learning rate\"\"\"\n",
    "                self._learning_rate = tf.train.exponential_decay(self._init_learning_rate,\n",
    "                                                                 self._global_step,\n",
    "                                                                 self._half_life,\n",
    "                                                                 self._decay,\n",
    "                                                                 staircase=True)\n",
    "                optimizer = tf.train.GradientDescentOptimizer(self._learning_rate)\n",
    "                gradients, v = zip(*optimizer.compute_gradients(self._loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "                \"\"\"optimizer\"\"\"\n",
    "                self._optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=self._global_step)\n",
    "                \"\"\"train prediction\"\"\"\n",
    "                self._train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "                # Sampling and validation eval: batch 1, no unrolling.\n",
    "                saved_sample_state = list()\n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                \"\"\"PLACEHOLDER sample input\"\"\"\n",
    "                self._sample_input = tf.placeholder(tf.float32, shape=[1, self._vocabulary_size], name='sample_input')\n",
    "                \n",
    "                \"\"\"counter after swap\"\"\"\n",
    "                sample_counter = tf.Variable(0, trainable=True)\n",
    "                counter_update = [sample_counter]\n",
    "                \n",
    "                reset_list = list()\n",
    "                reset_list.append(saved_sample_state[0].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "                reset_list.append(saved_sample_state[1].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "                reset_list.append(sample_counter.assign(tf.constant(0, dtype=tf.int32)))\n",
    "\n",
    "                \"\"\"reset sample state\"\"\"\n",
    "                self._reset_sample_state = tf.group(*reset_list)\n",
    "                \n",
    "                \"\"\"counter after swap\"\"\"\n",
    "                sample_counter = tf.Variable(0, trainable=True)\n",
    "                sample_counter_update = [sample_counter]\n",
    "                \n",
    "                with tf.control_dependencies(sample_counter_update):\n",
    "                    sample_output, sample_state, _, sample_counter_update, _ = self.swap_iteration(self._sample_input, saved_sample_state, sample_counter, self.compare_memory_and_outputs)\n",
    "\n",
    "\n",
    "                sample_save_list = list()\n",
    "                sample_save_list.append(saved_sample_state[0].assign(sample_state[0]))\n",
    "                sample_save_list.append(saved_sample_state[1].assign(sample_state[1]))\n",
    "\n",
    "                with tf.control_dependencies(sample_save_list):\n",
    "                    \"\"\"sample prediction\"\"\"\n",
    "                    self._sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, weights, bias)) \n",
    "                \n",
    "                \n",
    "                \"\"\"saver\"\"\"\n",
    "                self.saver = tf.train.Saver(max_to_keep=None)\n",
    "                            \n",
    "                        \n",
    "    \n",
    "    def _generate_metadata(self, half_life, decay, num_averaging_iterations):\n",
    "        metadata = list()\n",
    "        metadata.append(self._batch_size)\n",
    "        metadata.append(self._num_unrollings)\n",
    "        metadata.append(self._num_layers)\n",
    "        metadata.append(self._num_nodes)\n",
    "        metadata.append(half_life)\n",
    "        metadata.append(decay)\n",
    "        metadata.append(self._last_num_steps)\n",
    "        metadata.append(num_averaging_iterations)\n",
    "        metadata.append(self._swap_frequency)\n",
    "        metadata.append(self._mean)\n",
    "        metadata.append(self._stddev)\n",
    "        metadata.append(self._shift)\n",
    "        metadata.append(self._init_learning_rate)\n",
    "        metadata.append('regular_swap')\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = regular_swap(64,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 29,\n",
    "                 1,\n",
    "                 [128],\n",
    "                 2,\n",
    "                 train_text,\n",
    "                 valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "Average loss at step 0: 5.284577 learning rate: 1.000000\n",
      "Percentage_of correct: 0.00%\n",
      "\n",
      "random:\n",
      "================================================================================\n",
      " ï,Ü7_°«v´¬f5köù ²×d¾©s¸åFöÔ^<>·®+]~X¡È³Ôïª½nuS¦sk´à$­°¨\tf¹3UW'À0?ºi¥uaÒ­¢K4\n",
      "«V¼ß¢÷vjldá:å:¨2Õü¡7ÈñBSí8ÂÉræ¨^bUÛËV¶ycëÿw)aË\n",
      "pS0öÕé§Ìjö­Y_×!cr\n",
      "ÄMe¾·0¥ÞäA¼Ü¾\n",
      "ÿ^ÌÊÚ¢À>'þî'Q¶^×\n",
      "({éEdQøÏlYô«Ð{!1z|L$3J[ÙÜÙ5§D¿· og#ª;k°àLÀ^B&DQHp\\ÅuxrXdx/;C¶(\n",
      "âËÒ¦!äkÊ¶ÔÓë®ºCI25u*^$º¨­åw&ugÝBèh9§ÝôVñKí#cUJuOñcÄ¨/EÝ5Ç ëGä,iBCÃ¾týC^,KY¿íâkÊ\n",
      "ëê8å7»ð>¸#oTÒ\tfaîGRwÂ`øï^ÚÀTìÌ4rA±j0ÑðB­P8Õ·TvÈ\t7!9\tÓsµÑ+5ógm«&uhß$¸víóDm:ßï×:ÅÝ\n",
      "================================================================================\n",
      "\n",
      "from fuse:\n",
      "================================================================================\n",
      "0. fuse: my name is\n",
      "my name is±º×Ç\tzêS@)ÐWnhÉà^X³ùF¤:AÄý/Ué\"ÃfÝñjÐg»òçúêmÃÌê7²1)ä ÝÝÞìÛxïàÁU=\"´fëØ@3?úìÉÄxS\n",
      "1. fuse: december elegy\n",
      "december elegyÕ\n",
      "Û}v0½ùÔÂu\n",
      "¹ñ8IÔ-*G'»½«è½XòôXõêO.d·ÏåÜ¶Å/ÁÐïø&1¤ï¿3nÚú=ÚÜØ¸ójÍ°»7|)VU\tÏdUMí©]7\n",
      "2. fuse: they have done\n",
      "they have doneQaWKêàX¸ZG¾~nà©I3°`p¡SoLÙ§h\\j¹»]Äe\t\\Þz/'Ngáì}LPñÏb±úÃÜ¯Á; µjåßãy\\Vâ¡]¼fD}fî¸Åy\n",
      "================================================================================\n",
      "Validation percentage of correct: 12.48%\n",
      "\n",
      "1   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "2   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "3   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "4   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "5   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "6   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "7   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "8   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "9   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "10   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "11   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "12   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "13   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "14   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "15   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "16   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "17   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "18   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "19   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "20   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "21   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "22   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "23   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "24   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "25   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "26   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "27   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "28   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "29   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "30   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "31   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "32   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "33   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "34   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n",
      "35   self.compare_memory_and_outputs = [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "36   self.compare_memory_and_outputs = [[False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " ..., \n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]\n",
      " [False False False ..., False False False]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a853631da8dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint_intermediate_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mfuse_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuse_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           add_operation = 'self.compare_memory_and_outputs')\n\u001b[0m",
      "\u001b[0;32m/home/rumpelschtizhen/WIKI/model_module.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_stairs, decay, train_frequency, min_num_points, stop_percent, num_train_points_per_1_validation_point, averaging_number, optional_feed_dict, print_intermediate_results, half_life_fixed, add_operation, print_steps, fuse_texts)\u001b[0m\n\u001b[1;32m    441\u001b[0m                                                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                                                             \t       additional_operation],\n\u001b[0;32m--> 443\u001b[0;31m                                                             \t       feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    444\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mprint_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprint_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fuse_texts = [u'my name is', u'december elegy', u'they have done']\n",
    "model.run(30,\n",
    "          0.9,\n",
    "            200,\n",
    "            50,\n",
    "            3,\n",
    "            1,\n",
    "            20,\n",
    "            print_intermediate_results = True,\n",
    "          fuse_texts=fuse_texts,\n",
    "          add_operation = 'self.compare_memory_and_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swap:  1\n",
      "Number of steps = 20000     Percentage = 47.56%     Time = 730s     Learning rate = 0.0424\n",
      "swap:  2\n",
      "Number of steps = 20000     Percentage = 47.24%     Time = 732s     Learning rate = 0.0424\n",
      "swap:  3\n",
      "Number of steps = 20000     Percentage = 47.11%     Time = 722s     Learning rate = 0.0424\n",
      "swap:  5\n",
      "Number of steps = 20000     Percentage = 47.39%     Time = 722s     Learning rate = 0.0424\n",
      "swap:  7\n",
      "Number of steps = 20000     Percentage = 47.16%     Time = 723s     Learning rate = 0.0424\n",
      "swap:  10\n",
      "Number of steps = 20000     Percentage = 47.25%     Time = 723s     Learning rate = 0.0424\n",
      "swap:  12\n",
      "Number of steps = 20000     Percentage = 47.15%     Time = 723s     Learning rate = 0.0424\n",
      "swap:  15\n",
      "Number of steps = 20000     Percentage = 47.20%     Time = 721s     Learning rate = 0.0424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "swap_values = [1, 2, 3, 5, 7, 10, 12, 15]\n",
    "iter_num = 5\n",
    "results_GL = list()\n",
    "counter = 0    \n",
    "for swap_value in swap_values:\n",
    "    print(\"swap: \", swap_value)\n",
    "    model = regular_swap(64,\n",
    "                             vocabulary,\n",
    "                             characters_positions_in_vocabulary,\n",
    "                             30,\n",
    "                             1,\n",
    "                             [128],\n",
    "                             swap_value,\n",
    "                             train_text,\n",
    "                             valid_text)\n",
    "    model.simple_run(200,\n",
    "                         'regular_swap/variables/1_128_ns20000_stairs_30_ilr_1._nu_30sw%s' % (swap_value),\n",
    "                            20000,\n",
    "                               4000,\n",
    "                               5000,        #learning has a chance to be stopped after every block of steps\n",
    "                               30,\n",
    "                               0.9,\n",
    "                               3,\n",
    "                    fixed_num_steps=True)\n",
    "    results_GL.extend(model._results)\n",
    "    model.destroy()\n",
    "    del model\n",
    "    counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
