{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import _linear\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "from plot_module import text_plot\n",
    "from plot_module import structure_vocabulary_plots\n",
    "from plot_module import ComparePlots\n",
    "\n",
    "from model_module import maybe_download\n",
    "from model_module import read_data\n",
    "from model_module import check_not_one_byte\n",
    "from model_module import id2char\n",
    "from model_module import char2id\n",
    "from model_module import BatchGenerator\n",
    "from model_module import characters\n",
    "from model_module import batches2string\n",
    "from model_module import logprob\n",
    "from model_module import sample_distribution\n",
    "from model_module import MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of not one byte characters:  0\n",
      "min order index:  9\n",
      "max order index:  255\n",
      "total number of characters:  196\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('enwik8_filtered'):\n",
    "    if not os.path.exists('enwik8'):\n",
    "        filename = maybe_download('enwik8.zip', 36445475)\n",
    "    full_text = read_data(filename)\n",
    "    new_text = u\"\"\n",
    "    new_text_list = list()\n",
    "    for i in range(len(full_text)):\n",
    "        if (i+1) % 10000000 == 0:\n",
    "            print(\"%s characters are filtered\" % i)\n",
    "        if ord(full_text[i]) < 256:\n",
    "            new_text_list.append(full_text[i])\n",
    "    text = new_text.join(new_text_list)\n",
    "    del new_text_list\n",
    "    del new_text\n",
    "    del full_text\n",
    "\n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)\n",
    "    \n",
    "    f = open('enwik8_filtered', 'w')\n",
    "    f.write(text.encode('utf8'))\n",
    "    f.close()\n",
    "    \n",
    "else:\n",
    "    f = open('enwik8_filtered', 'r')\n",
    "    text = f.read().decode('utf8')\n",
    "    f.close() \n",
    "    (not_one_byte_counter, min_character_order_index, max_character_order_index, number_of_characters, present_characters_indices) = check_not_one_byte(text)\n",
    "\n",
    "    print(\"number of not one byte characters: \", not_one_byte_counter) \n",
    "    print(\"min order index: \", min_character_order_index)\n",
    "    print(\"max order index: \", max_character_order_index)\n",
    "    print(\"total number of characters: \", number_of_characters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99350000 n in the February 1934 riots, anarchists divided over a 'united \n",
      "10000 ture in Mutual Aid: A Factor of Evolution (1897). Subsequent ana\n"
     ]
    }
   ],
   "source": [
    "#different\n",
    "offset = 20000\n",
    "valid_size = 10000\n",
    "valid_text = text[offset:offset+valid_size]\n",
    "train_text = text[offset+valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  \t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¤¥¦§¨©ª«¬­®¯°±²³´µ¶·¸¹º»¼½¾¿ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõö÷øùúûüýþÿ\n",
      "char2id(u'a') = 67,  char2id(u'z') = 92,  char2id(u' ') = 2\n",
      "id2char(78) = l,  id2char(156) = Ø,  id2char(140) = È\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = number_of_characters\n",
    "vocabulary = list()\n",
    "characters_positions_in_vocabulary = list()\n",
    "\n",
    "character_position_in_vocabulary = 0\n",
    "for i in range(256):\n",
    "    if present_characters_indices[i]:\n",
    "        vocabulary.append(unichr(i))\n",
    "        characters_positions_in_vocabulary.append(character_position_in_vocabulary)\n",
    "        character_position_in_vocabulary += 1\n",
    "    else:\n",
    "        characters_positions_in_vocabulary.append(-1)\n",
    "\n",
    "\n",
    "string_vocabulary = u\"\"\n",
    "for i in range(vocabulary_size):\n",
    "    string_vocabulary += vocabulary[i]\n",
    "print(\"Vocabulary: \", string_vocabulary)\n",
    "print(\"char2id(u'a') = %s,  char2id(u'z') = %s,  char2id(u' ') = %s\" % (char2id(u'a', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u'z', characters_positions_in_vocabulary),\n",
    "                                                                        char2id(u' ', characters_positions_in_vocabulary)))\n",
    "print(\"id2char(78) = %s,  id2char(156) = %s,  id2char(140) = %s\" % (id2char(78,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(156,\n",
    "                                                                            vocabulary),\n",
    "                                                                    id2char(140,\n",
    "                                                                            vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'n in the Fe', u\".\\n* ''[[Con\", u\"oldier's so\", u'\\xf6hm-Bawerk ', u'tification,', u' warrior, a', u'uot; would ', u' 115       ', u'orbata acid', u'>\\n      <co', u'ate, the co', u'other natio', u'ing the his', u'et bromine;', u' Christ&quo', u' average]] ', u' their home', u'ks and a ri', u'on]]/[[Joel', u' new era fo', u'aph that th', u' known as t', u's from the ', u'ast majorit', u'trips, thou', u'ent of regi', u'metric aspe', u'd named by ', u'Z</timestam', u'tude of 1 c', u'!&quot; [ht', u'o ==\\n\\n* [[D', u'[[Belarusia', u'iton]], Rus', u'ccessful si', u'es his theo', u' explain th', u' the South.', u'sing with a', u'd ball is h', u'e could des', u'[Friedrich ', u'th virtuall', u' foreign ac', u'variant in ', u'd and watch', u\"t; ''[[Foot\", u' became Lea', u'stern Europ', u' </contribu', u'ese terms n', u'arting in t', u'gence of th', u'of the cons', u'uickly swit', u', thus star', u'lly develop', u'g the offic', u'esult, the ', u'red HMMWV. ', u'ament is de', u'University ', u'&quot;&gt;1', u'solely deco']\n",
      "[u'ebruary 193', u'ncentrate (', u'ong.\\n\\n==Com', u' wrote exte', u', when used', u'and elder h', u' have had o', u'        Sas', u'do]]\\n[[fa: ', u'omment>fix<', u'ombined sal', u'ons who fol', u'story of th', u'; however, ', u'ot; (Mosiah', u' of .847 wa', u'e field [[O', u'idge of fur', u'l Schumache', u'or Battle.n', u'he animator', u'the [[Pacif', u' local [[co', u'ty of execu', u'ugh several', u'istrars, de', u'ects will b', u' [[Bede]] i', u'mp>\\n      <', u'centimetre.', u'ttp://www.e', u'Derivative ', u'an language', u'ssian physi', u'ingles to d', u'ory (ISBN 0', u'he ability ', u'. He was of', u'a synthesiz', u'his last co', u'scribe as e', u' von Wieser', u'ly no-one t', u'ctors or th', u' the first ', u'hed it grow', u'tball World', u'ader of the', u'pe, many of', u'utor>\\n     ', u'not only de', u'the mid-198', u'his scene (', u'spirators]]', u'tched from ', u'rting the S', u'ped than Ma', u'ces of [[Ea', u' leaders of', u' The M1114 ', u'eemed incom', u' System]]\\n*', u'14,772&lt;/', u'orative. Th']\n",
      "[u'tu']\n",
      "[u'ur']\n"
     ]
    }
   ],
   "source": [
    "batch_size_test=64\n",
    "num_unrollings_test=10\n",
    "\n",
    "train_batches_test = BatchGenerator(train_text,\n",
    "                                    batch_size_test,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    num_unrollings_test)\n",
    "valid_batches_test = BatchGenerator(valid_text,\n",
    "                                    1,\n",
    "                                    vocabulary_size,\n",
    "                                    characters_positions_in_vocabulary,\n",
    "                                    1)\n",
    "\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(train_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))\n",
    "print(batches2string(valid_batches_test.next(), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class adaptive_random(MODEL):\n",
    "    def layer(self, \n",
    "              inp_t,\n",
    "              state_t_minus_1,\n",
    "              memory_t_minus_1):\n",
    "        X_t = tf.concat(1, [inp_t,\n",
    "                            state_t_minus_1,\n",
    "                            memory_t_minus_1])\n",
    "        RES = tf.matmul(X_t, self.Matrix) + self.Bias\n",
    "        state_t = tf.tanh(RES)\n",
    "        return state_t\n",
    "\n",
    "    \n",
    "    def iteration(self, inp, state):\n",
    "        output = self.layer(inp,\n",
    "                            state[0],\n",
    "                            state[1])\n",
    "        trigger = tf.sigmoid(tf.matmul(tf.concat(1, [inp, output]), self.trigger_matrix) + self.trigger_bias)\n",
    "        trigger = tf.reshape(trigger, [-1])\n",
    "        memory_list = list()\n",
    "        current_batch_size = trigger.get_shape().as_list()[0]\n",
    "        swap = tf.greater(trigger, self.thresh)\n",
    "        output_coef = tf.to_float(swap)\n",
    "        memory_coef = tf.constant(1., shape=[current_batch_size])\n",
    "        memory_coef = memory_coef - output_coef\n",
    "        memory = tf.transpose(output_coef * trigger * tf.transpose(output) + memory_coef * tf.transpose(state[1])) \n",
    "        return output, [output, memory], trigger\n",
    "    \n",
    "    def swap_iteration(self, inp, state):\n",
    "        output = self.layer(inp,\n",
    "                            state[0],\n",
    "                            state[1])\n",
    "        trigger = tf.sigmoid(tf.matmul(tf.concat(1, [inp, output]), self.trigger_matrix) + self.trigger_bias)\n",
    "        trigger = tf.reshape(trigger, [-1])\n",
    "        swap_prob = tf.constant(self._swap_prob) \n",
    "        swap = tf.less(tf.random_uniform([1])[0], swap_prob)\n",
    "        coef_output = tf.to_float(swap)\n",
    "        coef_memory = tf.constant(1.) - coef_output\n",
    "        memory = coef_output * tf.transpose(trigger * tf.transpose(output)) + coef_memory * state[1]  \n",
    "        return output, [output, memory], trigger\n",
    "    \n",
    "    def unrollings(self, train_inputs, saved_state):\n",
    "        outputs = list()\n",
    "        state = saved_state\n",
    "        triggers = list()\n",
    "        for inp in train_inputs:\n",
    "            output, state, current_trigger = self.iteration(inp, state)\n",
    "            outputs.append(output)  \n",
    "            triggers.append(current_trigger)\n",
    "        return [tf.concat(0, outputs), tf.concat(0, state), tf.concat(0, triggers)]\n",
    "    \n",
    "    def swap_unrollings(self, train_inputs, saved_state):\n",
    "        outputs = list()\n",
    "        state = saved_state\n",
    "        triggers = list()\n",
    "        for inp in train_inputs:\n",
    "            output, state, current_trigger = self.swap_iteration(inp, state)\n",
    "            outputs.append(output) \n",
    "            triggers.append(current_trigger)\n",
    "        return [tf.concat(0, outputs), tf.concat(0, state), tf.concat(0, triggers)]\n",
    "\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 num_unrollings,\n",
    "                 num_layers,\n",
    "                 num_nodes,\n",
    "                 init_bias,\n",
    "                 threshhold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                 normal_run_prob,\n",
    "                 swap_prob,\n",
    "                 train_text,\n",
    "                 valid_text,\n",
    "                 mean=0.,\n",
    "                 stddev='default',\n",
    "                 shift=0.,\n",
    "                 init_learning_rate=1.):\n",
    "        self._results = list()\n",
    "        self._batch_size = batch_size\n",
    "        self._vocabulary = vocabulary\n",
    "        self._vocabulary_size = len(vocabulary)\n",
    "        self._characters_positions_in_vocabulary = characters_positions_in_vocabulary\n",
    "        self._num_unrollings = num_unrollings\n",
    "        self._num_layers = num_layers\n",
    "        self._num_nodes = num_nodes\n",
    "        self._init_bias = init_bias\n",
    "        self._threshold = threshold\n",
    "        self._normal_run_prob = normal_run_prob\n",
    "        self._swap_prob = swap_prob\n",
    "        self._train_text = train_text\n",
    "        self._valid_text = valid_text\n",
    "        self._valid_size = len(valid_text)\n",
    "        \n",
    "        \n",
    "        self._mean = mean\n",
    "        \n",
    "        self._stddev = list()\n",
    "        if stddev == 'default':\n",
    "            self._stddev = 1.0 * np.sqrt(1.3/(2*num_nodes[0] + vocabulary_size))\n",
    "        else:\n",
    "            self._stddev = stddev\n",
    "            \n",
    "        self._shift = shift\n",
    "        self._init_learning_rate = init_learning_rate\n",
    "        \n",
    "        self._indices = {\"batch_size\": 0,\n",
    "                         \"num_unrollings\": 1,\n",
    "                         \"num_layers\": 2,\n",
    "                         \"num_nodes\": 3,\n",
    "                         \"half_life\": 4,\n",
    "                         \"decay\": 5,\n",
    "                         \"num_steps\": 6,\n",
    "                         \"averaging_number\": 7,\n",
    "                         \"init_bias\": 8,\n",
    "                         \"threshold\": 9,\n",
    "                         \"normal_run_prob\": 10,\n",
    "                         \"swap_prob\": 11,\n",
    "                         \"memory_fine\":12,\n",
    "                         \"init_mean\": 13,\n",
    "                         \"init_stddev\": 14,\n",
    "                         \"init_shift\": 15,\n",
    "                         \"init_learning_rate\": 16,\n",
    "                         \"type\": 17}\n",
    "        self._graph = tf.Graph()\n",
    "        \n",
    "        self._last_num_steps = 0\n",
    "        with self._graph.as_default(): \n",
    "            with self._graph.device('/gpu:0'): \n",
    "                self.Matrix = tf.Variable(tf.truncated_normal([self._vocabulary_size + 2*self._num_nodes[0],\n",
    "                                                               self._num_nodes[0]],\n",
    "                                                              mean=self._mean, stddev=self._stddev))\n",
    "                self.Bias = tf.Variable([self._shift for _ in range(self._num_nodes[0])])\n",
    "\n",
    "                # classifier \n",
    "                weights = tf.Variable(tf.truncated_normal([self._num_nodes[-1], self._vocabulary_size], stddev = 0.1))\n",
    "                bias = tf.Variable(tf.zeros([self._vocabulary_size]))\n",
    "                \n",
    "                self.trigger_matrix = tf.Variable(tf.truncated_normal([self._vocabulary_size + self._num_nodes[0], 1], stddev = 0.1))\n",
    "                self.trigger_bias = tf.Variable([self._init_bias])\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS train data\"\"\"\n",
    "                self._train_data = list()\n",
    "                for _ in range(self._num_unrollings + 1):\n",
    "                    self._train_data.append(\n",
    "                        tf.placeholder(tf.float32, shape=[self._batch_size, self._vocabulary_size]))\n",
    "                train_inputs = self._train_data[: self._num_unrollings]\n",
    "                train_labels = self._train_data[1:]  # labels are inputs shifted by one time step.\n",
    "                # Unrolled LSTM loop.\n",
    "\n",
    "                saved_state = [tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False),\n",
    "                               tf.Variable(tf.zeros([self._batch_size, self._num_nodes[0]]), trainable=False)]\n",
    "                \n",
    "                \"\"\"global step\"\"\"\n",
    "                self._global_step = tf.Variable(0)\n",
    "                \n",
    "                normal_prob = tf.minimum(\n",
    "                    tf.constant(self._normal_run_prob['init']) + tf.to_float(self._global_step) / self._normal_run_prob['epochs'] * tf.constant(1. - self._normal_run_prob['init']),\n",
    "                    tf.constant(1.))\n",
    "                \"\"\"swap\"\"\"\n",
    "                swap = tf.greater(tf.random_uniform([1])[0], normal_prob) \n",
    "                \"\"\"self.thresh\"\"\"\n",
    "                if self._threshold['fixed']:\n",
    "                    self.thresh = tf.constant(self._threshold['min'])\n",
    "                else:\n",
    "                    thresh_range = self._threshold['max'] - self._threshold['min']\n",
    "                    self.thresh = tf.minimum(tf.constant(self._threshold['min']) + tf.to_float(self._global_step) / self._threshold['epochs'] * tf.constant(thresh_range), tf.constant(self._threshold['max']))\n",
    "                outputs = list()\n",
    "                state = saved_state\n",
    "                [outputs, state, current_trigger] = tf.cond(swap,\n",
    "                                                            lambda: self.swap_unrollings(train_inputs, state),\n",
    "                                                            lambda: self.unrollings(train_inputs, state))\n",
    "\n",
    "                state = tf.split(0, 2, state)\n",
    "                save_list = list()\n",
    "                \n",
    "                save_list.append(saved_state[0].assign(state[0]))\n",
    "                save_list.append(saved_state[1].assign(state[1]))\n",
    "                \n",
    "                \"\"\"skip operation\"\"\"\n",
    "                self._skip_operation = tf.group(*save_list)\n",
    "                \n",
    "                self.memory_fine = tf.placeholder(tf.float32)\n",
    "                mf = tf.minimum(tf.to_float(swap), self.memory_fine)\n",
    "                with tf.control_dependencies(save_list):\n",
    "                        # Classifier.\n",
    "                    logits = tf.nn.xw_plus_b(outputs, weights, bias)\n",
    "                    \"\"\"loss\"\"\"\n",
    "                    self._loss = tf.reduce_mean(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits, tf.concat(0, train_labels)))\n",
    "                    fact_loss = tf.reduce_mean(\n",
    "                                                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                                                logits, tf.concat(0, train_labels))) + mf * tf.reduce_sum(current_trigger)\n",
    "\n",
    "                # Optimizer.\n",
    "                \n",
    "                \"\"\"PLACEHOLDERS half life and decay\"\"\"\n",
    "                self._half_life = tf.placeholder(tf.int32)\n",
    "                self._decay = tf.placeholder(tf.float32)\n",
    "                \"\"\"learning rate\"\"\"\n",
    "                self._learning_rate = tf.train.exponential_decay(self._init_learning_rate,\n",
    "                                                                 self._global_step,\n",
    "                                                                 self._half_life,\n",
    "                                                                 self._decay,\n",
    "                                                                 staircase=True)\n",
    "                optimizer = tf.train.GradientDescentOptimizer(self._learning_rate)\n",
    "                gradients, v = zip(*optimizer.compute_gradients(fact_loss))\n",
    "                gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "                \"\"\"optimizer\"\"\"\n",
    "                self._optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=self._global_step)\n",
    "                \"\"\"train prediction\"\"\"\n",
    "                self._train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "                # Sampling and validation eval: batch 1, no unrolling.\n",
    "                saved_sample_state = list()\n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                saved_sample_state.append(tf.Variable(tf.zeros([1, self._num_nodes[0]]), trainable=False)) \n",
    "                \"\"\"PLACEHOLDER sample input\"\"\"\n",
    "                self._sample_input = tf.placeholder(tf.float32, shape=[1, self._vocabulary_size])\n",
    "\n",
    "                reset_list = list()\n",
    "                reset_list.append(saved_sample_state[0].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "                reset_list.append(saved_sample_state[1].assign(tf.zeros([1, self._num_nodes[0]])))\n",
    "\n",
    "                \"\"\"reset sample state\"\"\"\n",
    "                self._reset_sample_state = tf.group(*reset_list)\n",
    "                \n",
    "                \"\"\"trigger\"\"\"\n",
    "                sample_output, sample_state, self.trigger = self.iteration(self._sample_input, saved_sample_state)\n",
    "                \n",
    "                self.trigger = tf.reshape(self.trigger, [1, 1])\n",
    "\n",
    "                sample_save_list = list()\n",
    "                sample_save_list.append(saved_sample_state[0].assign(sample_state[0]))\n",
    "                sample_save_list.append(saved_sample_state[1].assign(sample_state[1]))\n",
    "\n",
    "                with tf.control_dependencies(sample_save_list):\n",
    "                    \"\"\"sample prediction\"\"\"\n",
    "                    self._sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, weights, bias)) \n",
    "                \n",
    "                \n",
    "                \"\"\"saver\"\"\"\n",
    "                self.saver = tf.train.Saver(max_to_keep=None)\n",
    "                            \n",
    "                        \n",
    "    \n",
    "    def _generate_metadata(self, half_life, decay, num_averaging_iterations, memory_fine):\n",
    "        metadata = list()\n",
    "        metadata.append(self._batch_size)\n",
    "        metadata.append(self._num_unrollings)\n",
    "        metadata.append(self._num_layers)\n",
    "        metadata.append(self._num_nodes)\n",
    "        metadata.append(half_life)\n",
    "        metadata.append(decay)\n",
    "        metadata.append(self._last_num_steps)\n",
    "        metadata.append(num_averaging_iterations)\n",
    "        metadata.append(self._init_bias)\n",
    "        metadata.append(dict(self._threshold))\n",
    "        metadata.append(self._normal_run_prob)\n",
    "        metadata.append(self._swap_prob)\n",
    "        metadata.append(memory_fine)\n",
    "        metadata.append(self._mean)\n",
    "        metadata.append(self._stddev)\n",
    "        metadata.append(self._shift)\n",
    "        metadata.append(self._init_learning_rate)\n",
    "        metadata.append('adaptive_random')\n",
    "        return metadata\n",
    "  \n",
    "    def get_triggers(self, session, num_strings=10, length=75, start_positions=None):\n",
    "        self._reset_sample_state.run()\n",
    "        self._valid_batches = BatchGenerator(self._valid_text,\n",
    "                                             1,\n",
    "                                             self._vocabulary_size,\n",
    "                                             self._characters_positions_in_vocabulary,\n",
    "                                             1)\n",
    "        if start_positions is None:\n",
    "            start_positions = list()\n",
    "            if self._valid_size / num_strings < length:\n",
    "                num_strings = self._valid_size / length\n",
    "            for i in range(num_strings):\n",
    "                start_positions.append(i* (self._valid_size / num_strings) + self._valid_size / num_strings / 2)\n",
    "            while self._valid_size - start_positions[-1] < length:\n",
    "                del start_positions[-1]\n",
    "        text_list = list()\n",
    "        trigger_list = list()\n",
    "        collect_triggers = False\n",
    "        letters_parsed = -1\n",
    "        for idx in range(self._valid_size):\n",
    "            b = self._valid_batches.next()\n",
    "            \n",
    "            if idx in start_positions or collect_triggers: \n",
    "                if letters_parsed == -1:\n",
    "                    letters_parsed = 0\n",
    "                    text = u\"\"\n",
    "                    t_list = list()\n",
    "                    collect_triggers = True\n",
    "                text += characters(b[0], self._vocabulary)[0]\n",
    "                t_list.append(self.trigger.eval({self._sample_input: b[0]}))\n",
    "                letters_parsed += 1\n",
    "                if letters_parsed >= length:\n",
    "                    collect_triggers = False\n",
    "                    trigger_list.append(t_list)\n",
    "                    text_list.append(text)\n",
    "                    letters_parsed = -1\n",
    "                    \n",
    "            _ = self._sample_prediction.eval({self._sample_input: b[0]})\n",
    "        return text_list, trigger_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = {'fixed': True, 'min': 0.5, 'max': 0.7, 'epochs': 10000}\n",
    "normal_run_prob = {'init': 0.1, 'epochs': 10000}\n",
    "\n",
    "model = adaptive_random(64,\n",
    "                 vocabulary,\n",
    "                 characters_positions_in_vocabulary,\n",
    "                 30,\n",
    "                 1,\n",
    "                 [128],\n",
    "                 0.,\n",
    "                 threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                 normal_run_prob,\n",
    "                        0.1,\n",
    "                 train_text,\n",
    "                 valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3eb48060d638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0moptional_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptional_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             print_intermediate_results = True)\n\u001b[0m",
      "\u001b[0;32m/home/rumpelschtizhen/WIKI/model_module.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_stairs, decay, train_frequency, min_num_points, stop_percent, num_train_points_per_1_validation_point, averaging_number, optional_feed_dict, print_intermediate_results, half_life_fixed, add_operation, print_steps, fuse_texts)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_soft_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_intermediate_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \"\"\"\n\u001b[0;32m-> 1553\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3682\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3683\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3684\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 run_metadata):\n\u001b[1;32m    707\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m--> 757\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializeToString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[1;32m   1063\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalSerialize\u001b[0;34m(self, write_bytes)\u001b[0m\n\u001b[1;32m   1077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mInternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m       \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mEncodeRepeatedField\u001b[0;34m(write, value)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEncodeRepeatedField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalSerialize\u001b[0;34m(self, write_bytes)\u001b[0m\n\u001b[1;32m   1077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mInternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m       \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rumpelschtizhen/.local/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mEncodeField\u001b[0;34m(write, value)\u001b[0m\n\u001b[1;32m    818\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m       \u001b[0mentry_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m       \u001b[0mencode_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optional_feed_dict = {'self.memory_fine': 0.0000001}\n",
    "model.run(30,\n",
    "          0.9,\n",
    "            200,\n",
    "            50,\n",
    "            3,\n",
    "            1,\n",
    "            20,\n",
    "          optional_feed_dict=optional_feed_dict,\n",
    "            print_intermediate_results = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       threshold:  0.5\n",
      "memory fine:  1e-07\n",
      "Number of steps = 80001     Percentage = 50.59%     Time = 4607s     Learning rate = 0.0424\n",
      "memory fine:  5e-08\n",
      "Number of steps = 80001     Percentage = 50.66%     Time = 4655s     Learning rate = 0.0424\n",
      "memory fine:  2.5e-08\n",
      "Number of steps = 80001     Percentage = 50.45%     Time = 4654s     Learning rate = 0.0424\n",
      "memory fine:  1.25e-08\n",
      "Number of steps = 80001     Percentage = 50.37%     Time = 4717s     Learning rate = 0.0424\n",
      "memory fine:  6.25e-09\n",
      "Number of steps = 80001     Percentage = 50.65%     Time = 4764s     Learning rate = 0.0424\n",
      "memory fine:  3.125e-09\n",
      "Number of steps = 80001     Percentage = 50.47%     Time = 4643s     Learning rate = 0.0424\n",
      "memory fine:  1.5625e-09\n",
      "Number of steps = 80001     Percentage = 50.43%     Time = 4655s     Learning rate = 0.0424\n",
      "memory fine:  7.8125e-10\n",
      "Number of steps = 80001     Percentage = 50.38%     Time = 4734s     Learning rate = 0.0424\n"
     ]
    }
   ],
   "source": [
    "normal_run_prob = {'init': 0.1, 'epochs': 79000}\n",
    "\n",
    "threshold_values = [0.5]\n",
    "reduce_coef = 2.\n",
    "num_iter = 8\n",
    "memory_fine_value = 0.0000001\n",
    "threshold = {'fixed': True, 'min': 0.2, 'max': 0.7, 'epochs': 10000}\n",
    "optional_feed_dict = {'self.memory_fine': 0.001}\n",
    "results_GL = list()\n",
    "for threshold_value in threshold_values:\n",
    "    print(\"\\n\", ' '*5, \"threshold: \", threshold_value)\n",
    "    threshold['min'] = threshold_value\n",
    "    for _ in range(num_iter):\n",
    "        print(\"memory fine: \", memory_fine_value)\n",
    "        optional_feed_dict['self.memory_fine'] = memory_fine_value\n",
    "        model = adaptive_random(64,\n",
    "                         vocabulary,\n",
    "                         characters_positions_in_vocabulary,\n",
    "                         30,\n",
    "                         1,\n",
    "                         [128],\n",
    "                         0.,\n",
    "                         threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                                normal_run_prob,\n",
    "                                0.1,\n",
    "                         train_text,\n",
    "                         valid_text)\n",
    "        model.simple_run(100,\n",
    "                       'adaptive_random/new/variables/swpr0.1_th%s_mf%s' % (threshold_value, memory_fine_value),\n",
    "                       80000,\n",
    "                       4000,\n",
    "                       5000,        #learning has a chance to be stopped after every block of steps\n",
    "                       30,\n",
    "                       0.9,\n",
    "                       3,\n",
    "                       optional_feed_dict=optional_feed_dict)\n",
    "        results_GL.extend(model._results)\n",
    "        model.destroy()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        memory_fine_value /= reduce_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling adaptive_random/adaptive_random_ns_80000_hl_2667_dc_0.9_ib0_ilr1._th0.5_mf1e-7_7.8e-10_ni7.pickle.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'adaptive_random'\n",
    "file_name = 'adaptive_random_ns_80000_hl_2667_dc_0.9_ib0_ilr1._th0.5_mf1e-7_7.8e-10_ni7.pickle'\n",
    "force = True\n",
    "pickle_dump = {'results_GL': results_GL}\n",
    "if not os.path.exists(folder_name):\n",
    "    try:\n",
    "        os.makedirs(folder_name)\n",
    "    except Exception as e:\n",
    "        print(\"Unable create folder '%s'\" % folder_name, ':', e)    \n",
    "print('Pickling %s.' % (folder_name + '/' + file_name))\n",
    "try:\n",
    "    with open(folder_name + '/' + file_name, 'wb') as f:\n",
    "        pickle.dump(pickle_dump, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', file_name, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'adaptive_random'\n",
    "pickle_file = 'adaptive_random_ns_80000_hl_2667_dc_0.9_ib0_ilr1._th0.5_mf1e-6_1.6e-8_ni7.pickle'\n",
    "\n",
    "with open(folder_name + '/' + pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  results_GL = save['results_GL']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = 'adaptive_random'\n",
    "pickle_file = 'adaptive_random_ns_80000_hl_2667_dc_0.9_ib0_ilr1._th0.5_mf1e-7_7.8e-10_ni7.pickle'\n",
    "\n",
    "with open(folder_name + '/' + pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  results_GL = save['results_GL']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot_module import ComparePlots\n",
    "\n",
    "adaptive_random_plots = ComparePlots('adaptive_random')\n",
    "adaptive_random_plots.add_network(results_GL, model._indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:1288: UserWarning: findfont: Font family [u'normal'] not found. Falling back to Bitstream Vera Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAEkCAYAAAAFJ8pjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXmYVMX1sN8DCCKLIAiobC6ICMIAg4IoyGIUN0RiRIIs\nbpgQl6jJT+Ou0aifxDUuRFAxIhoFMWiI6MygKIIgoLKpbKKCIKvsMHO+P6oamqZ75vbQ2/Sc93nu\nc7v2c2919z236tQpUVUMwzAMwzAyiQrpFsAwDMMwDCMSU1AMwzAMw8g4TEExDMMwDCPjMAXFMAzD\nMIyMwxQUwzAMwzAyDlNQDMMwDMPIOExBMfZBRLqKyJcislNE8kSkiYgUicip6ZYthIhcKyIrRGS3\niNzp4y4WkW9FZJeIjEqTXE+KyBNh4XwRGZGAeverR0QeEJFVIlIoIgNjlFsqIn850HrKOyJyl4h8\nk245Mg0ROc1/xyqnWxYjOzEFxYjkGWAm0BS4CPgOaABMT6NMexCRI4BHgfuBI4FHRKQCMBIYCzQC\nrk9QW/8UkbyAeZsDg4D7EtF2CW2dDNwCXInrm9cCFu0D3JiAeoLIeJqIvOEVya0i8rV/0O/3MBOR\nC0XkUxHZIiIbRKRARA6JyNNFRD4QkV/8MV1Emvi0kBJd6M/hx5MJuqQy6zBKRGqKyEgRWSsim0Vk\noog0DVDuahH5wvfLUhG5PTxdVacCi4AbkiO5Ud6plG4BjMQjIpVUdXcpizcD7lfVH8PiVidArERx\nLCDAf1R1NYCINASqA/9V1VVpkuta4F1VXZOCto4HClV1YjyFVHVDIuoJSGfgW+AxYAXQFngOqAcM\nC2USkSuAvwN/ASb76JOAwrA8ZwNvAH8DrgO2AS2ArT5LSIkO53TgdeDVBF5TWWUMrq8vBH4BHgYm\ni0hLVd0ZrYCI/A54BLga+BjXJ8+LSEVVvScs60jg7yLyiKoWJfMijHKIqtrhDyAfeB73FvwTsN5/\nFuBOYBXuYf3XiHIVgbuBJbg/zy+BqyPyFAF/wL3lbwaWA32BmsC/gE3AYuCiiHLHA+/g/lh+Ad4G\njg1LHwTsAs4APge2A7/H/cF3jKirK7AbaBTl2rt6GQvDzgOBJj58qs8XCl/sZdni5R4UUV814HHg\ne59nFtAnQB+cCUzFPXy+B0YBh/m0u6LIOChKXBefvz3wP3/fVgNvAo0j2usJfOhl3OC/A0fHaGtg\nDJkFWAv0i/J9GgHcDqz0eV4CDgnL0xZ413/ffgFmAGdFq8d/fiFSrmLu5VLgL/HWA/QDZuO+y0uB\n4eEyH8Dv64/AmrBwDWAjcGUxZcR/v/4aZ1uvAF+WQsbKuFHEDb6/ngYeAL6OyFfiPcIpYvNwv8mf\ngNfD0i4FPvXtrAEmAs3C0guA56LItzi8TwNcTwvfv13D4uoAO4H+xZSbBjwREXez768qYXFVfV3d\nD/T7YYcdkUfaBcikw/+Br8e9qR0HDPY/7neAB33cQB93Vli5F4E5QA/cA/xiYB0wJCxPEfAjMAA4\nBngK91B8x9d5DPAETnmp7cscjFNkJgM5uIdZHvA1UMnnGeQfMtNxSkZToC7wX2BkxPWNBt6Jce2V\ncG+3RcA1/nMVfz2F7K+gfItTsI7BTbfsAo6LuJd5QCcv05X+j7pbMfe/u78nv/f1tgc+AAp8+iG4\naYpCoLWXsSqQ62U618dVAk7EPfDvxI0KtcRNYSwCKvv6euIUtuG4N8TjgSH+fAhOcZwKHB66HzHk\nbu1lOibG92m4r7Mn7qF3T1ierr7/T8B9v+719ynyXoYUixq4UYSdIbmKuZ/FKShR68F959cC/X1f\nn4b7br8UVs9gf78bx2o7hjz3AsvCwn39fbsM+Az3ApAPnBaWp71v6/fAFNyDfhpwYTHt1MEpDsNK\n8R/wqJfjPN9n/w/3UP46LE+Qe3QP7qXjd75fcyL6YhDu+9oUaAO8xb6/636+3XBltofvrwZh4T0v\nDzGu50pgS5T4T4Cniyk3G3g4Iu4Pvr86RcTPAu4rzX+uHXYUd6RdgEw6/J/j5xFxXwFzI+LmhH68\nuLftQuD4iDx3ALPDwkXA8LBwXR/3WFhcLR93jg9fQZjC4uPq4UYXBvhwSEE5NaL9PrgHdA0fPhT3\n8L+ghHtQRNibFbFHUK4Py1PB/xlf5cNneBlrRNQ9EhhXwv1/ICKusW+vtQ939dd7ZCwZfdwLwJiI\nuqqE3wPcyMmEYuT5J5AX4HvT28tUJcr1zImIexr4uIT65gC3RtQzIiw8CNgZQK6YCkqsenyZyNG/\n0/39PdSHLwTmA0fE8dtqgXvg/i4s7s++3u9wSn0OTknfAbTweX7j86z1v4fWwG3+fveI0dbNuN/N\noUHl8+UOwSk2l0fEf8a+Ckqx98jXsxX4YxxtH+bLd/Lhg3CjfpeH5RkDjA8Ld/T9kFNMvXcQphSG\nxY8LrytK+gO+/Y4+3BKnQBUCfSPyTgBeiede22FHkMOMZPdnbkR4FfBFlLh6/nN73DD0zDADvl9w\nc+rHRpTbU4+q/oz7sX8ZFrcB94YUqvtEYL6qrg/Lsxo3CtAyou6ZEeG3cUpDfx++DDecnCh7gz33\nSd3c82qgvo/KxSkDP0bck9/i3iZj0QG4IaLMPJyBYrM45esA9Imo62cvV6iu9uy1ezgQqgKo6o4o\naXMiwj+y9z4hInVF5GkRWSAi672cJ+KUrpQiInV9u3+PuG//xfXBcQCq+paqnqiqKwPW2ww31TZG\nVZ8JS6ro631AVf+tqnNU9Trc93toWB6Af6rqSFX9QlXvx02LXRujyauA11R1Y9Br9xyLm+KZFhE/\nNexairtHRbh71BL3PYv53RKRHBEZJyJLRGQTbqRUfd2o6i7cyOxVPn8d3EvHnlVYqvqp74fI71hQ\ntJi0e4DxQIGI7MKNho72aYURebfjfwOGkUjMSHZ/dkWENUZcSLmr4MOdcG9fkfmKqztWexUiwpFI\nRHyhRhi7qWqhiIzE/cE9h3v7HKWJM2SLNK6LvCcbcIqKlFAunArAQ8DLUdLiNX6t4Ov5WxQZ1oZ9\nLu5POihrAESkdrgy6SnuPoGzSWmIe+tfhvsOvYZ7UKaakFzX4WwgIvk+3gpFpBXwHu5tfVhEcsgQ\ne35E/Hz2Kmix8swDzorSXg+ckjAgXllx35PI31YkQe5RG/85aj0iUhWnsH2Emy76ySfNZ99+fw64\n0d/DnriXgEklXEMkK3FTeJHUZ/+XsT14ZXuoN5ZtgPv9neuTF0dkPwxnf2cYCcUUlANnlj83UdV3\nE1z3PNyfxGGqug5AROrj5sYfDlD+n8CtIjIUZ2PRJ8HyxWImbrqqqqpGPlhKKtdSVRPxZzcTNy20\ntJg8s3APuX/ESN/J3jf44pjtzy0Je9sOyOnAn1T1HQARqYazv/my2FJJQFVXi8gK4ARVPWBfMiLS\nATeyMFpVb4yS5SOcQnACbrotRHP2Pvxn4pS2EyLKNscpdJEMBb5Q1c9KIfK3uD7vDCwMi9/jAyjI\nPRKR+bhpqrNwv+FIWuCmeG9T1UW+zKlEKNKqutgvc78a6IazKYtXof4YOFhEuqrqFN9WHdzLw1Ml\nFfYvND/6cr8FvlXVyO9mK9yKKcNIKDbFc4Co6mKcvcM/RWSAiBwrIq1FZIiI/PkAqx+Dm5Z4TUTa\nikh73CqgFQT4Q1DVFbg3tceB91V12QHKEwhVzQPeB8aJSG8ROVpE2onIH/yy0ljcCfQWkeEi0kZE\njhGRs0XkeRGpEpYvckQkGg8ALUTkXyLSQUSaikg3EXkszAfEfUAvEXlURE4SkeNFZJCfkgBna3CC\niJwoInWi+fDw17sOt/qmawC5IlkE/FZEWolIDq7P0/m7vA24TkT+IiIt/T25UESeDWXw4QXifNJE\nRUS64L4DbwEPiUj90BHK4xXR14G7ROQcETlORP6GUz6e9Xm2AE8Cw0TkUv/7ugFnxPpYRJv1cPZA\nz1IKVHWrL/tXETnfX/tD7K8cFXuPvMzDgbtF5Pci0sx/n2/x5ZfjFJjr/He8h7+WaKObI3AKygm4\nFW3h19vR90NOMde0ADcd9pyInC4ibXHfsWW4VW2hul7xI66hcDMRucyfc0XkOZzt0TURMoSUrXhH\ndgyjRExB2ZfSDvdfhbP+/wvujel93MqM8KHQaHUXG6eq23HLbnfgVjDk4+xKemlwPycjcAZ3QT2a\nBpEzSJ4LcIZ4fwcW4GxfzmH/4eG9FagW4FbynIR7o56L+6PfxL5TYSW2r6oLcW++1XB/nvNwQ+YH\n46afUNXJXqaTcUs+p+P6LdTWSJyB5Ce44fV+sWTHLU29rDiZYjAY9zucjrtf//VtxltPNIL0274Z\nVP+FM0w918s0A6c4hk/vHIobxTuomKqG4HzTDMG9gf+Im274MSLfYNyDchRuROtU3JLVRWF5bsX9\nvh7C2fT0x63imRKlzR24Jcb7ISJ3i0hJU5y34JSq0bjrP5SIkYYg90hV78ApMtfiRsMm4Vbhoapr\ncVNQPXFG+A8DNxFdQXkLZ1z8X1WNnGKrxt4VZ8XRHzey9xZu1GonbhVi+PRjY9xUY4iKOIeHn+Ps\nT47BrcDLj6h7ADDJvwwZRkKR+EcMjbKEiPweZ8nfKA6lxogTEamEU6huVdW30y2PsT8i8hJuOXWv\ndMsSFD8dswL4jSbHoV6pEZHquBeOXqr6ebrlMbIPs0HJUrwtQyPgT8BTppwkF1XdLSKDiH+1kZEC\nRERwo3NnpFmUQHiFty7OAeT3maaceI4B/s+UEyNZ2AhKliIiL+C8Vb4HXBxjCaxhGBmIiHTFTeku\nwfk8+jTNIhlGyjEFxTAMwzCMjMOmeMIQEdPWDMMwSoGqBlldZxiBsVU8EaTbta+qctddd6W9rnjK\nBclbUp5Y6fHEJ/K+ZULflZX+izctU/uuLPZfpvz2DCMZpFRBEZECESmKOL4ISx8mIt+KyHYRWSgi\nA0uoL7Ku0DEqLE9rEckXka0i8rOIjPDW5xnLGWeckfa64ikXJG9JeWKlxxO/bNmyEuVINonsuwOp\nL5X9F29apvYdlL3+y5TfnmEkg5TaoIhIPtAF55QoNBz4o6o+IiL9cA6EVuMcC/XGeSM9W52/imj1\n/T0iaghQE7hdVf/mFZEluN1N38Rt7NceeFVVfxulPrW3gbLL4MGDefHFF9MthlEKrO/KNiKC2hSP\nkWDSoqCo6n7uw0VkDs5BV19VfUtELgeeBwpUtXuAulvhNuPbjtsG/mcRuR7n4OltVb3QL71dg3Mw\n1UwjPKuaglK2KSgosLe7Mor1XdnGFBQjGaTFBkVE1vnjfe9GuSJ7d+cN7W0T2p03phvnCP7oz/9S\nt1MwOM+NGqpTnQvqhbjrbn0g12BkHvaAK7tY3xmGEUmqFZRNOJfnY3H7UXTHuYCuy95N2Tb78xZ/\nPjTWHighxG2BfilOGXk8LCm078fmsLhQvQ1KIb+RwRQUFKRbBKOUWN8ZhhFJSpcZq2rv0GfvKfEb\n3B4QZwKFOIWpOrDenwE26r57RkTjd7g9Vt5X1fDdQ0PbmIcbxYY+r4pW0eDBg2natCkAtWrVIicn\nZ8/bXehP1MKZGZ4zZ05GyWNhC2druKCgYI/NUOj/0jASTcpsUESkKlBLVVf6cGXcTq6NgUuA23E2\nKL9R1TdF5Crc5m4FqtrdKzTHAmjYRmI+fjluROQ8Vf1vWNoNuM3q3lHV80WkBs4IN2SDsjRCRrNB\nMQzDiBOzQTGSQSoVlCY4hSQPp1B0wtmBrMQpJmfhdiFdw95VPIfiNqJ6z5dfipvGqa2qm3y9lwEv\nAYtUtUVEm9V9mcOA8bhVPDnAa6raP4qMpqAYhmHEiSkoRjJIpQ3KWpwi0Qy3pX093PbyPVV1naq+\nClwH/IKzJ1kNXK6q74XVoey/Zfx1Pu6JyAZVdTNuS/MpQC+gCTASuDpxl2VkCqEhaKPsYX1nGEYk\nKbNB8crC0BLyPAU8FSNtOXsNacPjO5RQ51ycMa5hGIZhGGUE2ywwDJviMQzDiB+b4jGSge3FYxiG\nYRhGxmEKipE1mB1D2cX6zjCMSExBMQzDMAwj4zAblDDMBsUwDCN+zAbFSAY2gmIYhmEYRsZhCoqR\nNZgdQ9nF+s4wjEhMQTEMwzAMI+MwG5QwzAbFMAwjfswGxUgGNoJiGIZhGEbGYQqKkTWYHUPZxfrO\nMIxITEExDMMwDCPjMBuUMMwGxTAMI37MBsVIBjaCYhiGYRhGxmEKipE1mB1D2cX6zjCMSExBMQzD\nMAwj4zAblDDMBsUwjLJCYWEhL7/8MoMGDUIkveYfZoNiJAMbQTEMwyiDjBkzhiFDhvDoo4+mWxTD\nSAqmoBhZg9kxlF2s7+JnxYoVtG/fngcffJDly5enWxzDSDiV0i2AYRiGET8FBQXcddddLFiwgP79\n+zNlyhQqVbK/dCN7SOkIiogUiEhRxPFFWPowEflWRLaLyEIRGRigzlYi8o6IbBSRLSLypYic6tOa\nRGmvSERuTOZ1GunhjDPOSLcIRimxvouPHTt28Omnn9KlSxduvvlmqlevzt13351usQwjoaRa3VZ/\nPAaEDKp+BBCRfsCTwGpgDNAbeEFEVqrq5GiViUgz4BOgGjAZWAI0BxpGZJ0P/C+szVkJuh7DMIyU\nM336dFq0aMGhhx4KwOjRo2nbti3dunWjR48eaZbOMBJDWsYDVfWmKNG34JSXa1T1LRG5HHgeuBWn\nfETjTpxyco+q3ltMkzNitGlkEQUFBfYmXkaxvouPvLw8unfvvidcv359Ro8ezcCBA5k9ezb16tVL\no3SGkRjSYiQrIuv88b6I5IpIRaClTw6Nbsz055xiqgr9Qk8WkZ9FZKWIPCEiVSPyXSwi20RkuU+v\nkaBLMQzDSDmRCgpAz549GTRoEIMGDaKoqChNkhlG4kipHxQRmeA//gB0AtoA63DKyUrcCEpdVV0v\nIscC3/i4qqq6M0p9O3CjQBuAN4BeuOmdx1T1RhFpAryPmwbaDfQBagFjVHVAlPrMD4phGBnNli1b\naNCgAT/99BOHHHLIPmm7du2ia9euXHTRRdx8880pk8n8oBjJIKVTPKraO/RZRCrhFJDGwJlAIW5E\npzqw3p8BNkZTTjxrgCOA+1X17yLya+B14ALgRlVdDjQLa/M1YBJwYSwZBw8eTNOmTQGoVasWOTk5\ne4aeQ0shLWxhC1s4XeGdO3fSrl07ZsyYETV9zJgxnHzyyVSrVo0WLVokRZ6CggJefPFFgD3/l4aR\naFI2guKnXWqp6kofrgwswikolwC3AycBv1HVN0XkKuA5oEBVu3uF5lgAVV3k63gXOAv4s6oOF5Hf\nAGOBL1Q1R0QaAz+q6m6f/yzgv8BmVa0ZRUYbQSnDFJgdQ1IpKiriiy++oE2bNgn3XGp9F5xbbrmF\nqlWrctddd8XM8+abb/KnP/2J2bNn7zGkTSY2gmIkg1TaoNQDlorIuyLyDDADaAKsAvKAh3CrbJ4W\nkRd8WIEHffmjgAXAfBEJKRcP+zK3isgI4BFf5kWfPsS3+YqIjMIpLwq8mswLNYxso7CwkIYNG3LB\nBRcwd+7cdItTrolmfxJJ3759Ofvss7n66quxly6jrJJKBWUt8BJuymUgTmEZB/RU1XWq+ipwHfAL\ncCluufHlqvpeWB2hZcouoFoADPB5BwBbgZtV9TGfJQ/4EugB9PP57vPtGFmGvYEnj48//piVK1cy\nbNgw2rRpk/D6re+CsWHDBhYuXMgpp5xSYt7hw4ezYMECRo4cmQLJDCPxpMwGRVU3A0NLyPMU8FSM\ntOVAxSjxY3B+U6KV+Qj4KG5hDcPYh3HjxlG3bl1+/vnntG9MV5758MMP6dSpE5UrVy4xb9WqVXnt\ntdfo0qULnTp1omXLliWWMYxMwvbiMbKGkBGfkVhUlXHjxvGXv/yFmTNnllygFFjfBSMvL49u3boF\nzt+iRQseeughLrnkErZt25ZEyQwj8ZiCYhhGscyaNYuqVasycOBAPv/8c/OxkUaC2J9EMmTIEFq3\nbs0f//jHJEllGMnBFBQjazA7huQwbtw4LrroIurUqUOdOnX45ptvEt6G9V3JrF69mu+++4527drF\nVU5EePbZZ3n//ff597//nSTpDCPxmIJiGEZMVJU333yTiy66CIDc3NykTfMYxVNQUECXLl1KtWNx\nzZo1GTt2LMOGDWPp0qVJkM4wEo8pKEbWYHYMiWfBggVs3bqV3NxcIHkKivVdyZRmeiec3Nxcbrnl\nFi699FJ27dqVQMkMIzmYgmIYRkxC0zuhlTvt27e3EZQ0caAKCsANN9xAnTp1uOOOOxIklWEkj0Ce\nZEWkgaquChpfVjFPsoaxL+3atePRRx+la9euAKxfv57GjRuzYcMGKlbcb9W/kSRWrFhBu3bt+Omn\nn6hQ4cDeK9esWUPbtm0ZNWoUv/rVrxIin3mSNZJB0G/61zHi5ydKEMMwMoulS5fy/fffc9ppp+2J\nq127Ng0aNGDRokVplKz8kZ+fT7du3Q5YOQE4/PDDefnllxk8eDCrVmXN+6WRhQT9tu+nGXt387be\n0MgYzI4hsbz11lv07t17v5GSZNihWN8VTyKmd8Lp1q0bV155JZdddpktGzcylmIVFBFZISLfAVVF\n5LvwA1gJvJUSKQ3DSDkh+5NIbCVPalHVhCsoAHfeeSfbt2/n4YcfTmi9hpEoirVBEZGuuNGTd4Fe\nYUkK/BTaVThbMBsUw3CsWrWKFi1asGrVKqpUqbJP2pQpU7j11lv55JNP0iRd+eLbb7/ljDPOYMWK\nFQnfZmDFihXk5uby1ltv0alTp1LXYzYoRjIodkG9qk4BEJG6qro1NSIZhpFuJkyYQK9evfZTTgDa\ntm3L3Llz2b17d6l8chjxERo9ScYeSI0aNWLEiBFceumlzJkzh1q1aiW8DcMoLUFtUP4lIqeHR4jI\n6SLyRhJkMoxSYXYMiSPW9A44p1+NGzdm/vzE2chb38UmGdM74fTu3ZsLLriAK6+8EhtBNjKJoApK\nVyByPHcaEHzXKsMwygTr169n2rRpnH322THzmB1KagjZn8SzQWBpePjhh1m8eDEjRoxIajuGEQ9B\nFZTtQLWIuOqAuSM0MgbbzyUxTJw4ke7du1O9evWYeRLtsM36Ljrz5s2jZs2aNGnSJKntHHzwwYwd\nO5bbb7+dL7/8MqltGUZQgioo/wOe80uLQ0uMnwImJUswwzDSQ3HTOyFyc3OZNWtWiiQqvyR7eiec\n5s2bM3z4cC655BK2bNmSkjYNoziCKig3ATWB9SKyGlgHHArckCzBDCNezI7hwNmyZQsffPAB5513\nXrH5cnJy+Oqrr9i5c2dC2rW+i04qFRSAgQMHkpubyw032F+7kX4CKSiqul5VzwWOAs4FGqrq+aq6\nIanSGYaRUiZNmkTHjh057LDDis1XvXp1jj76aObNm5ciycofhYWFTJkyJen2J5H84x//YMqUKYwd\nOzal7RpGJIH9JotIHeBMoJuqrhKRI0WkYfJEM4z4MDuGAyfI9E6IRBrKWt/tz+zZsznqqKOoX79+\nStutUaMGY8eO5brrrmPJkiUpbdswwgmkoHiHbYuA3wKhbTCbAc8kSS7DMFLMjh07ePfdd+ndu3eg\n/LaSJ7mkenonnHbt2nH77bfTr1+/hE3jGUa8BB1BeQy4RFXPBnb7uOnAyfE0JiIFIlIUcXwRlj5M\nRL4Vke0islBEBgaos5WIvCMiG0Vki4h8KSKnhqW3FpF8EdkqIj+LyAgRib08wSizmB3DgZGXl0fL\nli054ogjAuVPpIJifbc/6VRQAK699loaNGjAbbfdljYZjPJNUDeQTVX1A/855MlnZxzlQ6g/HmPv\nBoQ/AohIP+BJYDUwBugNvCAiK1V1crTKRKQZzj9LNWAysARoDjT06dWB94E6wJvA0cCVPv9v45Td\nMLKaeKZ3ANq0acOCBQvYvn07Bx98cBIlK3/s3LmTTz75hFdffTVtMogIL7zwAm3btqV79+706tWr\n5EKGkUhUtcQD+Bg4y39e58+/AgqClA+rJx8ojJE2BygELvThy3G7JecVU9/LvsydMdKv93W85cPV\ngK04/y1No+RXwyiP7N69Ww8//HBdsmRJXOVat26tM2bMSJJU5ZePPvpI27dvn24xVFV1ypQp2qBB\nA/3hhx9i5vH/nYGfBXbYEeSIZ5nxKyLyEm5n4+eAF4E/lUYpEpF1/nhfRHJFpCLQ0ieHnCuExo5z\niqkqNP55sp++WSkiT4hI6HWuLW7EZhaAqm4BFuKmtlqXRnbDyEY+/vhjGjZsyNFHHx1XOfOHkhzS\nPb0TTpcuXfjd737HZZddRmFhYbrFMcoRQZcZf4p7oM8DRgFLgZNV9bM429sETATGAstxCsYkoC5Q\n0efZ7M8hT0GHikjlGPXV9edOuCmcXcAfgAd8fMj8fXNYmVC9DeKU3chwzI6h9MQ7vRMiUXYo1nf7\nkkkKCsBtt91GYWEhDz74YLpFMcoRJdqQ+NGND3BTPA8fSGOqumd5gIhUAr4BGuOWLxfiFKbqwHp/\nBtioqrHMyNcARwD3q+rfReTXwOvABcCNwE8+X7hRbOjzqmgVDh48mKZNmwJQq1YtcnJy9iyBDP2J\nWjgzw3PmzMkoecpKuGvXrowbN457772XgoKCuMqLyB4FJVOup6yHTz75ZGbOnImqxt0fyQpXrFiR\nYcOGMXToULp27cru3bt58cUXAfb8XxpGwgkyD4Qb7ah6IHNJQFXgiLBwZdxITCHwa/baoPT16VcR\nZoOCU6aaA83D6njXl7nJh3/jy8z24Rt8+D8+XAPYhluJdHQUGdUwyhufffaZNm/eXIuKiuIuu337\ndq1atapu3bo1CZKVTyZPnqydO3dOtxhRmThxojZu3FjXrl27Tzxmg2JHEo6gNij3AM+ISBMRqSgi\nFUJHHLpQPWCpiLwrIs8AM4AmuJGMPOAh3Mqep0XkBR9WIDSmeBSwAJgf2hMIeNiXuVVERgCP+DIv\n+fTngbXAOSLyBlCAU4xeV9WlcchuGFnLuHHj6NOnDyJScuYIqlSpQosWLZg7d24SJCufZNr0Tjjn\nnnsuffsT2XvqAAAgAElEQVT25YorrkBVSy5gGAdAUAXjeWAgbhnvTpytx27i2814LU5xaObrqgeM\nA3qq6jpVfRW4DvgFuBS33PhyVX0vrI7QMmUXUC0ABvi8A3ArdG5W1cd8+magJzAF6IVTiEYCV8ch\nt1FGCA1JG8FRVd58881S2Z+ESIQdivXdXjJZQQH429/+xooVK3j66afTLYqR5QT1YxKfaX8UvLIw\ntIQ8T+F2SY6Wtpy9hrTh8WNwflNi1TmXvat9DMMIY8GCBWzdupXc3NxS15Gbm8vHH3+cQKnKLxs3\nbmTevHl07Ngx3aLEpEqVKowdO5ZOnTrRuXNncnKKW2hpGKWnxBEUbyT7ErBKVZdHHskX0TCCETLu\nM4ITWr1TmumdEIkYQbG+c3z00UeccsopGe/47rjjjuPxxx+nX79+bN68ueQChlEKSlRQVLUQN4IS\nj72JYRhlgNIuLw6nZcuWLFmyhC1btpSc2SiWTJ/eCad///6ceuqpXHvttekWxchSUmkkaxhJxewY\n4mPp0qV8//33nHbaaQdUT+XKlWnVqtWeZd6lwfrOUZYUFIAnn3ySTz75JN1iGFlKKo1kDcPIIMaP\nH0/v3r2pWHE/0664sZ2ND5yff/6ZpUuXHpA9UKqpVq0a999/f7rFMLKUlBnJGkayMTuG+Bg3blzC\ndqrNzc0lPz+/1OWt79wo0umnn06lSvHuwZpe+vbtm24RjCwlqKv7kEHsCtwIygozkjWMssvKlSuZ\nN29ewqYTbATlwClr0zshDsTA2jCKI5CCIiI1RWQ0sB34AdgmIi+JyKFJlc4w4sDsGIIzYcIEzjnn\nHKpUqZKQ+k488URWrFjBpk2bSlXe+g7y8/PLpIJiGMkiqA3KE0A1oBXOZf1JwCE+3jCMMkYiVu+E\nU6lSJVq3bs3s2bMTVmd54scff2TNmjW0bm2brBtGiKAKytnAZar6taruUNWvgSE+3jAyArNjCMb6\n9euZPn06Z5+d2J/vgUzzlPe+y8/P54wzzqBCBVsYaRghgv4atgOHR8TVBXYkVhzDMJLNxIkT6d69\nO9WqVUtovWaHUnrKqv2JYSSTeJYZTxaRa0Skl4hcA/wPGJE80QwjPsyOIRiJnt4J0b59+1IrKOW9\n70xBMYz9Cbqe7X7gR6A/cKT//DAwKklyGYaRBLZs2UJeXh6jRiX+p3vCCSewatUqNmzYQK1atRJe\nf7aydOlSduzYQfPmzdMtimFkFEGXGauqjlLVnqp6oj+PVNtv28ggyrsdQxAmTZpEx44dqV27dsLr\nrlixIjk5OXz++edxly3PfRcaPbHluoaxL0GXGT8hIqdGxJ0qIo8lRyzDMJLBuHHj6NOnT9LqNzuU\n+LHpHcOITlAblEuByH+dWbgpH8PICMq7HUNJ7Nixg3fffZfevXsnrY3SKijlte9U1RQUw4hBUAVF\no+StGEd5wzDSTF5eHi1btuSII45IWhs2ghIfCxcupGrVqjRt2jTdohhGxhFUwfgI+Gto92J/vtvH\nG0ZGUJ7tGIKQrNU74TRr1oy1a9eydu3auMqV176z0RPDiE1QBeV6oCewUkRm4FbxnAlcmyzBDMNI\nHIWFhUyYMCGp9icAFSpUoF27dsyaNSup7WQLpqAYRmyCruL5HmgH9Ab+H3Ah0N7HG0ZGUF7tGIIw\ndepUGjZsyNFHJ39j8tJM85THvisqKqKgoIBu3bqlWxTDyEgC25CoapGqfqqq//bnomQKZhhG4kjF\n9E6I9u3b2whKAObOnUu9evWSahNkGGWZlBq5ikiBiBRFHF+EpQ8TkW9FZLuILBSRgSXUd1eU+gpF\n5DCf3jVKepGIpOaf2kgp5dWOoSRUNaUKSmlGUMpj39n0jmEUT1BPsolC/fEYEPJK9COAiPQDngRW\nA2Nw00kviMhKVZ1cQp1vAD+EhbdF5PkUmObbVOCbA74SwygjzJw5k2rVqtGiRYuUtHfssceyadMm\nVq9eTb169VLSZlkkLy+Pyy+/PN1iGEbGElNBEZELVPVt//kgVd2VqEZV9aYo0bfglIdrVPUtEbkc\ntwfQrUBxCgrAP1T1w2LSJ6nqvaWT1igrFBQUlMs38ZIIjZ6kylOpiOyZ5unVq1egMuWt73bt2sXU\nqVMZPXp0ukUxjIyluCmef4V9jm/NYAmIyDp/vC8iuSJSEWjpk0OT16Ex4pySqgMmiMgWEZkjIpdG\nyXOTnzZaLCL3iMhBCbgMw8h4Uj29E8L8oRTPzJkzOeaYY6hTp066RTGMjKW4KZ5VIvIHYD5QSUS6\nsXdaZg+qmhdHe5uAibjpmE5Ad2ASTjmpiBtB2ezzbvHnQ0WksqrujFLfbmAKsBBoCpwF/EtEfvbT\nQgp8iVN2qgB9gDt8W7fHIbdRBihPb+BBWbBgAdu2baN9+/YpbTc3N5eXX345cP7y1ndmf2IYJSOx\n9vvze+/cCzQBjgZWRMmmqnpMqRoWqYSzBWkMDAJewI3oNFXVFSLSBpgNbFDVwwLWOQa4BBihqr+L\nkn418CywSFX3m5AXER00aNAer461atUiJydnz59naCmkhS1cVsIvv/wyNWrU4LHHHktp+8uWLSM3\nN5c33ngjo+5HpoR79OhBz5496dSpU0bIE2+4oKCAF198EYCmTZtyzz33oKq226GRWFS1xAP4Nki+\nEuqoChwRFq4MLAUKgV8Dc/znvj79KqAIyPPhSkBzoHlYHcdGtDHGl3nKh4+JSB/q07+KIaMaZZf8\n/Px0i5BxtG3bVqdMmZLydouKirROnTr6ww8/BMpfnvpu27ZtWr16dd24cWO6RUkY/r/zgJ4RdtgR\neQRaxaOqxwGISGPgKOB7VY02olIc9YBFIpIHLMdN8TQBVgJ5wEHAK8DTInIebhWPAg/68kcBCwAV\nkdqqugmYLCKrcNM4jXFTPIXAWF/mDhHpDHzi6+/j63wlTtkNo8yxdOlSfvjhBzp37pzytkWE3Nxc\nZs2axZFHHpny9jOZadOm0apVK2rWrJluUQwjownkB0VEGojIFOBbYBywWEQ+FJF4/nnWAi8BzYCB\nOIVlHNBTVdep6qvAdcAvuN2TVwOXq+p7YXWElimHGIEbmekHnAJMBc5X1ak+fTxuGfO5OIVnCXCj\nqv4tDrmNMkJoKNpwjB8/ngsuuICKFSumpf14HLaVp74z+xPDCEZMG5R9Mom8BXwH3KqqW0SkGvAA\ncLSqXpBkGVOGiGiQ+2EYZYHTTjuN2267LfBS30Qzfvx4Ro4cycSJE9PSfqbSuXNn7r33Xnr06JFu\nURKGiKBmg2IkmKAKys84+5FdYXFVgB9UtW4S5UsppqCUbQrKmS+N4li5ciUnnngiq1atokqVKmmR\nYcWKFXTo0IGVK1eW6IOlvPTdL7/8whFHHMGaNWuoWrVqusVJGKagGMkgqKv79cCJEXHNgQ2JFccw\njEQwYcIEzjnnnLQpJwANGzZEVfnhhx9KzlxOmDp1Kh06dMgq5cQwkkVQV/cPA++LyEicgWsTYAjO\np4hhZATl4Q08KOPGjWPo0KFplSFkKDtz5kwaNmxYbN7y0ndmf2IYwQk0gqKq/8T5F6kLnO/Pl6rq\niCTKZhhGKVi3bh2ffvopZ599drpFMY+yEZiCYhjBCbybsarmqeqVqnqOP8fjQdYwkk7IkVR5Z+LE\nifTo0YNq1aqlW5TACkp56Lt169bxzTff0KFDh3SLYhhlgsAKimEYZYN07L0Ti/bt2zNz5kzM+Bym\nTJlC586dqVy5crpFSTkiMkhEirwfrFS2e5dvd9QB1PGir+POGOlNfHqhiNT0cct8XJGIFLeRbUlt\nL/P1dgmYv0dYu0UiMrC0bWcCpqAYWUN5sWMojs2bN5OXl8d5552XblEAOPLII6lSpQrLly8vNl95\n6LvyMr0T9nAO9FBNAQeqHUf634qnzCjg9QNo+3ngMeD7gPm/8/nnc+DXHRURaS0i+SKyVUR+FpER\nIlK9mPxNIpSm0HFjSW0FNZI1DKMMMGnSJDp16kTt2rXTLcoeQg7bQntclVfy8vIYPXp0usVIBaV5\noO+H+LXpCfD9kM7lz/eq6nelLayqf40z/zfAjSLyArDffnMHildE3gfqAG/i9um7EqgG/LaE4vOB\n/7G3P0r04hjXCIqIVBCRI+IpYxipojzYMZTE+PHjM2Z6J0QQO5Rs77tVq1axcuVKcnJy0i1KUhGR\npbhVngAFUaYZKojI30RknYh8LyL9w8qG8j8oItOBnUAjEanq474Rkc0iMktEeoeVO1NEZvq0DT79\nwgjRqorI8yLyi6+nR1j5uj5tuYhsFJFpInJWMdd4kIg846/ha+BXAe9NaJprjogM97LME5EcEbnP\ny75YRM4MK7PPaFTYPXpARKaIyBYRmSoijYLIEFbvsSLymIg8GuOItQnwFbhFMv9R1d8AZwDbgd+I\nSNMSmp2hqjep6o3+mFKSnEFd3dcSt1Pwdpy7e0TkAhGJS7szDCN57Nixg3fffZfevXuXnDmF2Eoe\nyM/Pp2vXrmnbdiCFjMRtVwLwBvAo7s05xGlAN2AGcCTwbNj0QGjk5WZgFW7PtB24aZI/4/xuvYLb\nl+3NsCmkF4DWvr03cPuxtYqQ62Lcfm1fAsd6OUOjNP8BLgfWAG8B7YGJItIpxjXejtt4thD4ELi7\npJsSQSvgZNx9aQHkAxcB03AjEiPD8kaORoXCf8JN56zB7WsX77O4IXAtbnuZaEcsvwBtffuzAFR1\nC7AQp0u0LqHNi0Vkm1cEnxCRGiUJGXSK51mcs7Ym7P2yTQOG4zrLMNJOebBjKI68vDxatWpFgwYN\n0i3KPoQbykoMj7LZ3nflxf5EVf8qIlcA1XG7yn8IICItfZb1wOm4h9w23NTA8cDnYdW8rKpDfLm6\nOBcXhbhnTiFu09iuwDU4BaES7uX5beAr4Jsoos1X1V/5t/wluJGZw3DKyik4peo0Vd0uImuBG4Bh\nvs1Ifuvlv15Vx4jb3PbtOG7TFqAHTrHIB2oCHYEfgE3AUSJSR1XXFlPHM6p6nYgMxilwbeNoHz96\nURptub4/bw6L2+LPxf3xLMZt2rsbt2nvH4DDgAHFNRZUQekBHKmqu0REAVR1jYjUC1jeMIwkk0mr\nd8KpX78+NWrUYMmSJRx77LHpFict5OXlccMNN6RbjExgQWjLFBHZAtTAKTPhfBL2uak/V8ApDCEU\np1wAXA38P+DfOPuGtT5vuHHqHH8O935ePaz+Faq63X9e6M9NiE5ok9yvI85BWaaqO0UkXJavVVXD\nFPhquOuIReT1xDRSjYaIHIsbQYll3/Okqi6JEv9TlPZCn1dFq0hVl+M2CQ61/RowCYichtuPoDYo\nG3HzTnsQkcbAyoDlDSPpZLsdQ3EUFhYyYcIE+vTpk25RolLSNE82992yZcvYvHkzJ54YuVtI1lLo\nz9GeL7vDPsd6OO4I+7zMn3cCh6tqRVWtCFTBTYsATFLV5rhn1K9xBpz3x2g3ss1Q/Y1E5GD/+YSI\ntEhCezc0jzgHpTAyohSGwLGuJyilneKZg1MCTwbw0zQneDm+9HGNRKS5iNTy4cYiEj4YEtLCikoS\nMqiC8jxuzq8bzsipE/ASburHMIw0M3XqVBo1apSxK2XKsx1Kfn4+3bt3L3HDxCxihT/f5w0ujypt\nRar6M24kpDIwwxun/tu3cYXPNltE3gEewNmSgJtKCsJMYDpuFGCqiLyEm34oAp4OyxfeeWN8+HER\neR54Lu4LSzOqOiWk7MU4YvlueR43snOOiLwBFOD65nVVXerzvIybhgsZRw8BlorIK+L80YzFKTSv\nliRnUAXlIdyX5B/AQbg5rwnA4wHLG0bSyXY7huIYN25cxo6eQMkKSjb3XXmxPwnjbtxiio64t/GQ\n3UK05cdBRgAuBx7EjTwMwtlufIybJgCYjLNjGQh0BvKAqyLaiNquH7k4H2doezhu2mEWcL6qTovM\n77kfp5RUwBn83h+jDdh/iXOQexDvPYpWZ1K0YVXdDPQEpgC9cNNgI3HTbJHyhGTKw42u9AD6AauB\n+3DfjWIR8/C4FxFJwJJ7w0gtqkrjxo353//+l7HTCGvXruWYY45h/fr1VKhQfvxDqioNGzbkww8/\nzGr7GxFBVcvNEFFJ+OXWjXGKwlRVTYnTOr98erIPKjBEVcus851ARrIiEkv93wF8741gDCOtFBQU\nZPWbeCxmzpxJtWrVaNEi4X6ZEkadOnU47LDD+Pbbbzn++OP3S8/Wvvv666+pVKkSxxwTy62EkaWM\nxK1SAbdqKFWEPMmGmB8rY1kg6Cqekey1XF6LM0ICN1TTQES+APp5L3aGYaSQ0OqdTLdxCE3zRFNQ\nspXQ9E6m942RWOL1AJvAdr8BSnQhX1YIOtY6EngCqKWqRwK1cPYnz/rPn7GvQZFhpJxsfAMvCVXl\nzTffzMjlxZEUZ4eSrX1XDu1PDCNhBFVQrgduVdVtAP58G3CD9yR3E5CbHBENw4jF/Pnz2b59O+3b\nt0+3KCVS3lbyFBUVkZ+fT7du3dItimGUSYIqKFuADhFx7YGt/nOJ65lhn30Ewo8vwtKHici3IrJd\nRBZKCVtFy96ttMOPQu8hMJSnm4h85l3s/igiD4lI+bHSK0dksy+NWJSV6R2Adu3aMXv2bAoL93MD\nkZV99+WXX1KnTh0aNozlUsIwjOIIaoNyJ/CeiLyNW3/eELc061qf3gO3B0JJhJYePcbeZVA/AohI\nP+BJnF3LGKA38IKIrFTVyVHqCq/zDfY6zwm5UA45k3sXp4i9hlOy/oRzcnNbAHkNI6MZN24cjz9e\nNlb7165dmwYNGrBo0aKMXW2USGx6xzAOjEAKiqqOFpGZQF+csezXQCdVne/TJwITgzaqqjdFib4F\np1xco6pvicjlOKcwt7J32VQs/hHDscyNOCcyT6rqDd697zfAtSJyv6pujVLGKKNkqx1DLJYuXcqP\nP/5I586d0y1KYELTPJEKSjb2XV5eHgMHFjsIbBhGMQSe6lDV+ap6n6r+TlXvDSknpcFvU71ORN4X\nkVwRqQiENpOa5c+hyeqS9icXYILfdnqOiFwalhYqG9p5cTFu74JqwHGlld8wMoHx48fTu3fvMrVD\nbnmxQ9m9ezcfffRRVipehpEqAisoInKBiAwXkZdEZHToiLO9TbiRlrHAcqA7zhtgXfburBjaJTG0\nQ+KhIlI5Rn27cR7txuJ2tWwN/EtEzvTppd150SiDZKMdQ3Fk6uaAxdG+fXtmzZq1X3y29d3nn39O\nkyZNOPzww9MtimGUWYI6arsLt7X1WOBinJvf/ji7jsCoau+wOivhplsaA2fi3BhXwO2JsJ69OyRu\nVNWdMeq7n7BNoURkDG5r7otw00I/4VwgB955cfDgwXv2M6lVqxY5OTl73oJCf6IWzszwnDlzMkqe\nZIZXrlzJ3Llz9xk9yST5YoW3bNnC3Llz2b17N1OnTk27PMkK5+Xl0axZMwrCHNBlknwHGi4oKODF\nF18EyNj9n4wsQFVLPHCjHa385w3+fDLwdpDyPn9V4IiwcGVgKU4x+TVul8RCoK9Pvwq3OijPhyvh\ndo1sHlbHsRFtjPFlnvLhx3z4SR9u5sObgEOiyKiGURZ45pln9Le//W26xSgVzZs31y+++CLdYiSV\nM888U99+++10i5Ey/H9noGeBHXYEPYKu4qmlql/5zztF5CBVnSEiXePQheoBi0Qkzys8nXAbDa3E\nbSZ0EPAK8LSInIdbxaO4TaIAjsLtkKgiUltVNwGTRWQVbiOixsBZOCUnNLLzKG7kZ6jf+vlkX+dT\nagayRhlm3LhxXHPNNekWo1SE7FBOOumkdIuSFHbs2MGnn37Kv//973SLYhhlmqA2KItFJGTE+hXw\nOxG5jOBbWoNzkf8SbhRjIE5hGQf0VNV1qvoqbnfDX4BLccuNL1fV98LqiNy1cQRuZKYfcAowFbcL\n5UcA6vYI6oUbnfk1UAN4BLgjDrmNMkJoCDrbWbduHdOnT+ess85KtyilIpqhbDb13fTp02nRogWH\nHnpoukUxjDJN0BGU29m7/84tuKmU6sCwoA2p26Z5aAl5ngKeipG2nL2GtKG4B9k7whKrznzcyIlh\nZAUTJ06kR48eVKtWLd2ilIrc3FxeffXVdIuRNMz/iWEkBlHVknOVE0RE7X4Ymc6FF15I3759ueyy\ny9ItSqnYvHkz9evXZ/369VSuHGuBXtmlS5cu3HHHHZx55pklZ84SRARVzXx3xkaZIpCCIiLrVPWw\nKPGrVbVeUiRLA6agGJnO5s2bOfLII1m+fDm1a9dOtzilplWrVrz88su0bds23aIklC1bttCgQQN+\n+uknDjnkkHSLkzJMQTGSQVAblIMiI0TkICKmXAwjnWSTHUMsJk2aRKdOncq0cgL726FkS999/PHH\ntGvXrlwpJ4aRLIpVUETkIxH5EDhYRD4MP4BFwCcpkdIwDKBsOmeLRiyHbWUdsz8xjMRR7BSPiAzC\nuZJ/BrdcN4TinKDlqequpEqYQmyKx8hkduzYQYMGDViwYAENGpRtR8jTpk3j2muvzTq39yeffDLD\nhw/n9NNPT7coKcWmeIxkUOwqHlV9CUBEPlXVhakRyTCMaHzwwQe0atWqzCsnAG3atGH+/Pns2LGD\nKlWqpFuchLBhwwYWLlzIKaeckm5RDCMrCGSDoqoLReRXIvJnEbk3/Ei2gIYRlGyxY4hFtkzvABxy\nyCE0a9aML7/8EsiOvvvwww/p1KlTVq5MMox0EEhBEZGngH8B7YFGYUfD5IlmGEaI3bt38/bbb9On\nT590i5Iwsm1n47y8PLp165ZuMQwjawjqqO1SIEdVVyRTGMM4EEKbmmUjH3/8MY0aNcqqjdnCFZRs\n6Lu8vDyef/75dIthGFlD0GXGa4ENyRTEMIzYZNP0TohsGkFZvXo13333He3atUu3KIaRNQRVUIYD\nr4hIJxE5JvxIpnCGEQ/ZYMcQDVXNSgWldevWfP3112zbtq3M911BQQFdunShUqWgg9KGYZRE0F/T\nM/58XkS8Ys7aDCOpfPbZZ1SqVIkTTjgh3aIklCpVqtCiRQvmzp2bblEOGPN/YhiJJ+gqngoxDlNO\njIwhG+wYIvnqq68YMGAAGzduzIoHeSQhh21lve9MQTGMxBN0igcAEWkkIh2TJYxhGI7CwkIeeeQR\nunXrxv/93//xwQcf0KZNm3SLlXCywQ5lxYoVrF+/nlatWqVbFMPIKoIuM24sIh8DC4H3fdyvRcRM\n1o2MoazbMYRYtmwZ3bt35+2332bGjBlcccUVtG3bFpHsc9QZUlDKct/l5+fTrVs3KlSI633PMIwS\nCPqLeg54B6gBhFzbTwbKz37ihpFkVJUXXniBDh06cP7555Ofn8/RRx+dbrGSSqtWrVi8eDHbtm1L\ntyilxqZ3DCM5BDWSPRk4V1WLREQBVHWjiByaPNEMIz7Ksh3D6tWrufrqq1m2bBl5eXmcdNJJ6RYp\nJVSuXJlWrVpRs2bNdItSKlSVvLw8/vKXv6RbFMPIOoKOoPwEHBceISInAt8lXCLDKGdMmDCBNm3a\ncOKJJzJ9+vRyo5yEKMt2KIsXL6aoqIhmzZqlWxTDyDqCKiiPABNFZAhQSUQuBV4DHkqaZIYRJ2XN\njmHTpk0MGTKEm266iTfeeIMHHnggazbOi4fc3FwmTpyYbjFKRWh6Jxvtgwwj3QRdZjwK+DNwMbAC\nGAjcoaqvJFE2w8haCgoKaN26NZUrV2bOnDl07tw53SKljdzcXBYtWpRuMUqF2Z8YRvIQVU1dYyIF\nQJeI6K9UtbVPHwb8EbcJ4TLgAVUdHaDe44A5wCHAHFVt5+O7AvlRivxaVcdFqUdTeT+M8sf27du5\n7bbbGDt2LCNGjODcc89Nt0hpZ/fu3dSqVYuVK1dSo0aNdIsTGFWlfv36fPbZZzRp0iTd4qQVEUFV\nbRjJSCiBjGRF5AlgrKp+EhZ3KvAbVb0hjvbUH48BoS/zj76+fsCTwGpgDNAbeEFEVqrq5GJkq4Db\nafkgX3c0PgWm+TYV+CYOmQ0jIcyePZsBAwZw4oknMnfuXOrWrZtukTKCSpUqcdJJJzF79my6dIl8\nf8lc5s2bR82aNcu9cmIYySKoDcqlQKQV2yygf2kaVdWbVPVGfzzio2/BKQ/XqOrlwJ9wCsWtJVR3\nB9AKt19QLA1+UlibN6nql6WR28hsMtUGZffu3dx///2cddZZ3Hrrrbz++uumnETQoEGDMmcoa9M7\nhpFcgiooGiVvxTjK74OIrPPH+yKSKyIVgZY+eZY/h/6tcoqppwNwG3ATUNwk9k0isl1EFovIPSJy\nUGnkNox4+fbbbzn99NPJz89n1qxZDBgwwAwqo9C8eXNTUAzD2IegCsZHwF/9dEpoWuVuHx8Pm4CJ\nwFhgOdAdmATUZe+mg5v9eYs/HyoilSMrEpGqwMvAe6r6XIz2FPgSeMMfDXAjLnfFKbdRBsgkPyiq\nyrPPPkunTp249NJLee+992jUqFG6xcpYLrvssjKloBQWFjJlyhS6deuWblEMI2sJ6qjtepxisVJE\nlgONgZXA+fE0pqq9Q59FpBLOFqQxziNtIU5hqg6s92eAjaq6M0p1HYDjgXUi8h+cYS3AMSLyH1U9\nX1U/BPZsYCIiVwPPAn2B26PJOHjwYJo2bQpArVq1yMnJ2fPgC00hWNjCxYWPP/54rrjiCpYsWcLw\n4cMZOHBgRsmXieETTjiBFStWMHHiRM4777y0y1NSePbs2dSqVYsFCxZQv379tMuT6nBBQQEvvvgi\nwJ7/S8NIOKpa4oFTHCoAHXFLjTsCFYKUDaujKnBEWLgysBSnmPwatwqnEOjr068CioA8H64ENAea\n+3BXnz/yKAJ2+zzHRMgw1Kd/FUNGNcou+fn56RZBX3vtNa1Xr57efffdunPnznSLU2bIz8/X0047\nTT/44IN0ixKIBx98UPv166dFRUXpFiUj8P+dgZ8HdtgR5ChxBMXbh2wGaqnqp7gVMaWhHrBIRPJw\n08v5VK8AABivSURBVDudgCa4kZg83CqcV4CnReQ83CoeBR705Y8CFgAqIrVVdQp7p4UQkUHAC4Qt\nMwbuEJHOwCe+/j6+TvPfYiSU9evXM2zYMD7//HMmTpxIhw4d0i1SmSPkUTbT7Tq2b9/OiBEj2Lp1\nK3PnziUnJ6aZnGEYB0CJNiiqWgh8DdQ5wLbWAi8BzXCO3uoB44CeqrpOVV8FrgN+wa0aWg1crqrv\nhYtD7KXE0dLH45Yxn4tTeJYAN6rq3w7wWowMJDQUnWomT55M69atqVu3Lp9//rkpJ6XgjDPOKDMu\n72+++WbatWvHu+++S5s2bUouYBhGqQjkqE1E/gz0Ax4HvidMCVDVvKRJl2LMUZsRD1u3buXPf/4z\nEyZMYNSoUZx5pm3ufSAsWrSIc845h8WLF6dblJiMHz+eG2+8cY8NiuEwR21GMghqJPs7f747Il6B\nYxImjWEcAAUFBSkbRZk+fToDBw6kQ4cOfPHFF9SuXTsl7WYrBQUFdOnShTVr1rBu3ToOO+ywdIu0\nH8uXL2fo0KG8/fbbppwYRgoIpKCo6tHJFsQwygK7du3ivvvu47nnnuOpp57i4osvTrdIWUOFChVo\n164ds2bNyrjRqN27d9O/f39uvvlmOnbsmG5xDKNcENjRmogcJCKni8glPlxNRKolTzTDiI9kj54s\nWLCATp06MXPmTObMmWPKSQIJ9V2m2qHcfffdVK9enZtvvjndohhGuSGQgiIiJ+EMZf8JjPTRXYFR\nSZLLMDKGoqIiHn/8cbp06cJVV13FO++8wxFHHJFusbKSTFRQPvjgA0aNGsXo0aOpUKFUzrMNwygF\nQX9tzwB3quoJwC4fNwU4LSlSGUYpCDmSSiTfffcdZ555Jq+//jrTpk1j6NCh5qo+CYT6LtMUlNWr\nVzNw4EBGjx69xyGbYRipIaiC0hK3YzD4FTyqugXnfM0wspL//e9/5OTk0KNHDz788EOOO+64dIuU\n9Rx77LFs2rSJ1atXp1sUioqKGDRoEIMGDaJnz57pFscwyh1BFZRlQPvwCBE5Gfg20QIZRmlJpA3K\n888/T//+/Tn44IM555xzqFixYsmFjFIT6jsRoX379syaNav4Aing73//Oxs3buSee+5JtyiGUS4J\nusz4DuAdEXkWqCwitwLX4NzRG0bWUFRUxB133MFrr73GJ598wrZt28wZV4oJTfP06tUrbTLMmDGD\nhx9+mBkzZnDQQbb5uWGkg0AjKKo6EegFHI6zPWkCXBTh5dUw0sqB2qDs2LGDAQMGkJ+fz7Rp02je\nvDk5OTlmc5ICwvsuNzc3rSMoGzdupF+/fjzzzDO2EZ5hpJGgIyio6ufA75Moi2GkjbVr19KnTx/q\n16/PBx98QNWqZl6VLtq3b88NN9yQlrZVlauvvpqzzz6bvn37pkUGwzAcQZcZVxaRe0XkGxHZ4s/3\nicjByRbQMIJSWhuUxYsXc+qpp9KxY0dee+01U07SQHjfNW3alG3btrFy5cqUyzFy5EgWLFjA8OHD\nU962YRj7Es8y4+64zfw6+HNX4OkkyWUYKWHatGmcdtppXH/99Tz88MPm5yIDEJG0TPPMmzePW2+9\n1ZRUw8gQgv4bXwicp6r/VdX5qvpfH3dh8kQzjPiI1wblzTff5IILLuD555/n97+32ct0Etl3qfaH\nsm3bNi655BIeeughWrRokbJ2DcOITVAFZRVwSERcVSD1Y7CGcYCoKsOHD+f666/nvffe49xzz023\nSEYEqVZQ/vjHP9K6dWuGDBmSsjYNwygeUdWSM4ncAvQHngS+BxoBw4AxwGehfKqalxwxU4OIaJD7\nYZRddu/ezfXXX8//b+/eo7Sq6z2Ovz8NZhYBwlERQdBEMzxCgHeFg7b0nDAVNWVEEPHWsqOusHMW\nXvCUug6VEWqaXVC8gCassmMJAooTcCRNhDiipNGo6EAWDAGjiDHf88feg4/jzDAzPHc+r7We9Tz7\n9tu/zY955ju/33f/9sKFC5k9eza9evUqdJWsCWvWrOGoo45i7dq1Ob+LatasWVx33XW8+OKLdOrU\nKafnKleSiAjf7mZZ1doApboVZUVEHLzrVSocByjlbcuWLYwcOZJt27Yxa9YsOnfuXOgqWTMigu7d\nu7N06VJ69uyZs/NUV1dzzDHHMHv2bAYPHpyz85Q7ByiWC62dB+WgVrxKOjix0tdSDkpNTQ1Dhgxh\nv/3244knnnBwUmQat10+EmU/+OADKisrmTBhgoMTsyLkWxas7L300kscd9xxnHPOOUydOtUzg5aI\nXOehTJw4kW7duhVszhUza1mrJ2ozK3ZNzYPy1FNPccEFFzBlyhRGjRqV/0pZqzTVdoMGDeKee+7J\nyfnmzZvH9OnTWbZsmW8tNytSrcpB2V04B6W8TJs2jQkTJjBz5kyGDh1a6OpYG9XU1NC/f3/eeeed\nrCbKrlu3joEDBzJjxgyGDRuWtXJ3Z85BsVzwnw5WNhryGCKCiRMncuutt7Jw4UIHJyWgqfyhHj16\nsMcee/Dmm29m7Tz19fWMHj2aSy+91MGJWZHLa4AiqUpSfaPXioztX5f0J0lbJa2SNKaV5R4iaUta\n3ouNtg2T9HtJ70mqkfRdSQ7MytT777/P6NGjmT9//o4H/lnpynYeyve+9z22bt3KTTfdlLUyzSw3\n8p2DEunrdqChO7AGQNJIknlW3iGZX+VMYJqktRExv7kC02BjOrBHWnbmtgOB2SSB2KMk0/T/B/AP\n4IasXZUVhf79+3PaaafRtWtXFixYwKc/3XhuQStWzT1HqSFAycaD+5YsWcKUKVN44YUX6NDB6Xdm\nxa4gPQkRcW1EjE9f309XTyAJML4WEeNIAgkB1+2kuInAEcBkPgx6GowHPgncExFjgNPT9VdJ8m+v\nMlJdXc3xxx/PoEGDmDVrloOTMpGtHpTa2loqKyv56U9/6sn5zEpEQQIUSRvS11OSBkuqAPqlmxsm\nPmj4VhrQQjlHkfSEXAv8sYldGo5dChARq4GNwGeAQ3btKqxYPP/885xwwgmceuqpTJ48mYqKikJX\nydqouTlsBg0axNKlS9mV5PWI4LLLLuOMM87gzDPPbHc5ZpZf+e7n3AT8BngbOI7kCclPkgQnFSQ9\nKFvSfevS986SPhkR2zILkrQX8BAwLyJ+IumiJs63X/q+JWNdHdAZ6A6saHzA2LFj6dOnDwBdunRh\nwIABO7qfG75EvVw8y4sWLeLOO+/kvvvuY/Xq1VRVVRVV/by868sdO3akurp6R7JsW49ftWoVq1ev\n5vLLL/f/jywtV1VVcf/99wPs+L40y7aC3WYsqQPwGnAgcBEwjaRHp09ErJHUH1gGbIyIrk0cPwSo\nAn4HrAd6Av1JgqBFEfEVSVXAScDYiHgoPa4W6AR8MSJWNCrTtxmXkNtvv53bbruNxx9/nEGDBhW6\nOpYjI0aMoLKykvPOO6/Nx65YsYJTTjmFxYsXO2E6h3ybseVC3oZ4JO0laf9mzr0VWJl+PrrR+/L0\n+A6SDpPU8C0jkh6XY4AvA0emy52Af8s4Vg1lSepL0ntSB/wpO1dm+bZ9+3auvvpqpk6dyrPPPuvg\npMy1Nw+lrq6OkSNHMnnyZAcnZiUonzko+wLVkmZLugd4HugNrAMWAN8lCSZ+JGlauhzAd9LjDwBe\nAV6W1CkifhsRFQ0vYFx6/PKIaBi6mgJsA66Q9BDJ8FIAd0XEu3m4Zsuyuro6RowYwcqVK1m8eDG9\ne/fesa2hC9pKT0tt194A5ZprrmHw4MGMGdOq2QrMrMjkM0BZDzwA9AXGkAQsvwS+FBEbIuIR4Gpg\nM1BJcrvxuIiYl1FGw23KzfnI9oh4g6Q3ZTlwLvBZ4Pskd/5YiVm3bh1Dhw6lW7duzJkzhy5duhS6\nSpYHDYmy9fX1rT7mkUceYeHChdx99905rJmZ5ZKnus/gHJTitXLlSoYPH84ll1zCjTfemNWpz634\nHXTQQcydO5dDDz10p/uuXr2aY489lrlz5zJw4MA81M6cg2K54BlVregtWLCAYcOGccsttzBx4kQH\nJ7uh1g7zbNu2jZEjRzJx4kQHJ2YlzgGKFbUHH3yQyspKZs6cyejRo1vc1zkopWtnbdfaAOX6669n\n//3356qrrspSzcysUDzfsxWliODmm2/mgQceoKqqisMPP7zQVbICGjx4MN/+9rdb3Gf27NnMnDmT\nZcuWuZfNrAw4ByWDc1CKxze+8Q3mz5/PU089Rffu3QtdHSuw2tpaevfuTW1tbZMzBdfU1DBw4EBm\nzpzJkCFDClDD3ZtzUCwXPMRjRenEE0+krq6OdevWFboqVgT23ntv9t13X1599dWPbdu+fTsXXngh\nV155pYMTszLiAMWK0tlnn81jjz1G//79W32Mc1BKV2varrk8lEmTJlFfX88NN/gB5WblxAGKFSVJ\nDBgwwLkEtkNTAcqiRYu46667mDFjhh8SaVZmHKBY2Wh4qJmVnta0XeMAZcOGDYwaNYp7772XAw44\nIIe1M7NCcJJsBifJmhWvTZs20aNHDzZu3EhFRQUjRozg4IMP5gc/+EGhq7bbc5Ks5YJ7UKxsOAel\ndLWm7Tp16kTPnj155ZVXuPvuu3nrrbeYNGlS7itnZgXheVDMrGQMHjyYqVOn8vDDD7NkyRL23HPP\nQlfJzHLEQzwZPMRjVtymTJnC+PHjmT59OqNGjSp0dSzlIR7LBQ/xmFnJ6Nu3L127dqVfv36FroqZ\n5ZgDFCsbzkEpXa1tu+HDh/P000+3aX4cMytNzkExs5LRMD+OmZU/56BkcA6KmVnbOQfFcsFDPGZm\nZlZ0HKBY2XAOSuly25lZYw5QzMzMrOg4ByWDc1DMzNrOOSiWC3ntQZFUJam+0WtFxvavS/qTpK2S\nVkkas5PyrpL0mqR3Jf1d0u8lfTVj+9Amzlcv6excXqeZmZntmnzfZhzp63agIdquAZA0Evgh8A7w\nMHAmME3S2oiY30x5BwH/B8wF+gFDgYclLY2IP2fs9ztgSXrOAF7L5kVZcaiqqvITjUuU287MGivI\nPCgRcW0TqyeQBA9fi4hfSRoHTAWuA5oMUCJifOaypFqgE3AgkBmgPBkRN2ej7mZmZpZ7ec1BkfQM\nMAT4e7rqRZLAZBmwlWTIqU9ErJF0JLAc2BgRXVso8zTgdOBI4CRgIfCliPiHpKHAM8BmYE/gbWA6\ncGtEfNBEWc5BMTNrI+egWC7kuwdlE/AbkkDhOOBk4EmS4ZkKkh6ULem+del7Z0mfjIhtzZR5LHBl\n+vk9YE5E/CNdDpIhoBdIApQRwMT0XDc2VdjYsWPp06cPAF26dGHAgAE7up4bboX0spe97OXdebmq\nqor7778fYMf3pVm2FewuHkkdSHJBDgQuAqbx0R6U/iQ9Ky32oKRlfQL4Aknw0wu4MCIeaWK/y4Ef\nA3+MiMOb2O4elBJW5TyGkuW2K23uQbFcyNtdPJL2krR/M+feCqxMPx/d6H15enwHSYdJOiyjzI4A\nEVEfES8Bq9JNh6bbD25cjfR9+65cixWn5cuXF7oK1k5uOzNrLJ9DPPsCf5S0AHiDZIinN7AWWADs\nAcwAfiTpdJK7eAL4Tnr8AcArQEjaOyI2AeskPU0yZNQXOIUk+JiXHjNR0gnAs2n5I9IyZ+T4Wq0A\nNm7cWOgqWDu57cyssXzOg7IeeIAkkBhDErD8kiShdUM6JHM1SUJrJcntxuMiYl5GGQ23KTeYBwwE\nxpEkyVYBZ0TEknT7YyS3MQ8nCXj+DIyPiEm5uMBsaRjrLWRZbTmuNfvubJ/mtrd1faFlu16l0H5t\n3VasbQel137+2bNylrcAJSK2RMQVEdE3Ij4TET0i4tyIeCVjn7si4pCI+FREfD4iHsjY9kZEVERE\nh7T3hIg4OyJ6pfvvFxEnR8ScjGMej4h/iYh9IqJjRBwREXfk65rbywFK+9a//vrrO61HrpXaL7jW\n7pvrAKUY2g5Kr/2K5WfPLBc81X0GSf7HMDNrByfJWrY5QDEzM7Oi46cZm5mZWdFxgGJmZmZFxwGK\nmZmZFR0HKGZmZlZ0HKC0IJ29domkbZJqGm27UdJfJL2aPrDQipikCkk/k1Qr6Q+Sjt75UVYMJO0p\naZakTZLekXRdoetkrSfpvyTVS9qevtdL6lnoelnx8108LZBUAYwHTgX6RUSPdP1JwG+BrwLHA2OB\nnhHxXoGqajsh6WLgZySzDV8JfDEiDi1sraw1JJ1FMqnj10gmZrwM2Dci1he0YtYq6SNJOqWL04Fe\nEdG3gFWyEuEelBZExPaIuA14q9GmU4G6iPgF8CjQheSpyla8BgEbIuK3wHzgc5I+V+A6WeusBrYB\na0hmmN6WvqwEpJN01gD1wInAvQWukpWIsgtQJF2TduH/I+1KvKnR9j0l/TAdnnlX0uJ2dPfvA9Sl\nn7eQPIRwnyxU3zJkuS3XAV3SB1b+c7quxadkW/tlue1eAxYCvwZuAG6KiM05voTdWo6+R8em7w+0\ntJNZg7ILUEj+Ul4PvMlHn9vT4A7g6yS/sB4jeWjhPEldASTdIOm99IeuVzPn+CvQMf3cKWOdZVfW\n2pLkS3FVWtaF6fGNe8Yse7LZdv8JfInkGV6TgVsl9c79JezWcvE9OhaYExFrc115Kw9lF6BExJiI\nOBn4Q+NtkvYBLiZ54vHJETGK5MnGnwX+Pd3tbqAfcATwtqTPA52BCkmHSdqLZIhgL0nnA+cDtcBz\nub2y3U+W2/I94CKSHJQngYX+osydLLfdepJfku+TDO10AP4p19ewO8vB9+hJwKHA1DxU38pEh0JX\nIM/6AXsA1RkJdi+Q/EU9ACAiNgI7nv0u6WU+/AviZWBYRCyU9C3gTmATMCoi3s3LFViDNrWlpMOB\nJ0i+RBfzYS+K5V9b224aSQ/KfcAHwB0RsTTflbYd2vM9ejGwluRn0KxVdrcAZb/0fUvGuoZcku5N\nHRARTfYyRcQtwC3Zq5q1UZvaMn1qdo9cV8papa1t9y4wIteVslZrz/fouJzWyMpS2Q3x7MRf0veO\nGesaPq/Lc11s17gtS5fbrrS5/SwvdrcA5WWSLuID03FUgKNJhnCWF6xW1h5uy9Lltittbj/Li7Kb\nqE3SJcBJwDCgF0mS13LgsYh4XNJPgEtJfsheAs4DNgOf88RPxcVtWbrcdqXN7WfFoBxzUE4ERqef\nAzgyfVUDjwPXkNwJcB5wJvAscK1/qIqS27J0ue1Km9vPCq7selDMzMys9O1uOShmZmZWAhygmJmZ\nWdFxgGJmZmZFxwGKmZmZFR0HKGZmZlZ0HKCYmZlZ0XGAYmZmZkXHAYqZmZkVHQcoZmZmVnQcoJjt\nJiR9StKvJdVKelTSBZKeLHS9zMyaUo7P4jGzpp0L7AN0jQ+fcfFwAetjZtYs96CYlRhJauehvYFX\nww/gMrMS4ADFLIOkaknflPQHSZsl/UzSvpJmS9okaZ6kzum+x0r633TIZJmkoRnlPCPplnT7Zkn/\nI6mrpOmS/i7pOUkHZux/vKTn07Kek3Rco7JulbRYUh1wraQXGtX7Wkm/bOG6vgXcBIxMr+NiSRdJ\nWpSxT72kKyS9Kmm9pLsalTFO0svptjmZ9TczyzYHKGYfdzZwCnAocAYwG5gAdAMqgKsl9QB+A9wc\nEXsD3wR+IalbRjnnA6OAHsAhJI+kvxfYG1gF/BeApL3Tsm5PzzEFeCJd3+BC4FLgs8CdQB9Jh2Vs\nHwU82NwFRcS3gP8Gfh4RnSJiWsOmRrsOBwYBA4DzJJ2a1vGs9N/gLJJhokXAI82dz8xsVzlAMfu4\nH0bE3yJiLckv4uciYkVEfAA8BgwkCRieiIi5ABHxNPAC8OWMcqZFxOsRsRmYA6yOiGcioh6YBXwx\n3W84ydDLwxFRHxE/JwlgvpJR1v0RsSrdvg14NK0DkvqRDN88kYVrnxQRmyNiDfAMSaACcHm67dW0\n/t8BBkjqlYVzmpl9jAMUs4/7S8bn95pY7kgSEJwnaUP6qgVOALq3sRxIeljeaFSHN4ADMpbXNNr+\nIHBB+vlCYGYaQO2qzDq+m1HH3sAdDdcLrCfpfTkAM7Mc8F08Zm0XwJvAgxFxRRbKqwHOabTuQJJe\nl8xzfrgQ8ZykbZJOIglUKrNQj5asAW6NCA/rmFleuAfFrH2mA2dIOlXSJ9I5RoamuSltNRvoK2mk\npApJ5wOHA7/eyXEPAXcBH0TEs+04b1v8GLhe0hcAJHWWdG6Oz2lmuzEHKGYf1ThptMlbciPibZIE\n2uuBv5IMyXyTD3+mWn0rb0RsAE5Pj/9b+j48Imp3UtZDwBG0kBzbRs1ee0T8iiTv5OeSNgIrgH/N\n0nnNzD5GnhLBrDRJ+hRJzsjAiFhd6PqYmWWTe1DMSteVwO8dnJhZOXKSrFkJklSdfjyr0fqXSBJs\nd6wiGaq5wgmuZlZKPMRjZmZmRcdDPGZmZlZ0HKCYmZlZ0XGAYmZmZkXHAYqZmZkVHQcoZmZmVnT+\nHyiPC6zOKgxHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74517c8250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_options = {'x': 'log'}\n",
    "plot_data, _ = adaptive_random_plots.one_key_layout_data('adaptive_random_1',\n",
    "                                         'memory_fine',\n",
    "                                         \"threshold['min']\")\n",
    "adaptive_random_plots.save_layout(plot_data[0],\n",
    "                    'memory fine effect (half life: 2667, decay: 0.9)',\n",
    "                    ['memory_fine_effect', 'plots'],\n",
    "                    'new_nn128;ns80000;hl2667;dc0.9',\n",
    "                              plot_options=plot_options)\n",
    "adaptive_random_plots.draw(plot_data[0], 'memory fine effect (half life: 2667, decay: 0.9)', plot_options=plot_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       threshold:  0.5\n",
      "memory fine:  1e-07\n",
      "memory fine:  5e-08\n",
      "memory fine:  2.5e-08\n",
      "memory fine:  1.25e-08\n",
      "memory fine:  6.25e-09\n",
      "memory fine:  3.125e-09\n",
      "memory fine:  1.5625e-09\n",
      "memory fine:  7.8125e-10\n"
     ]
    }
   ],
   "source": [
    "normal_run_prob = {'init': 0.1, 'epochs': 79000}\n",
    "threshold_values = [0.5]\n",
    "memory_fine_values = [(0.0000001 / 2**i) for i in range(8)]\n",
    "threshold = {'fixed': True, 'min': 0.2, 'max': 0.7, 'epochs': 10000}\n",
    "optional_feed_dict = {'self.memory_fine': 0.001}\n",
    "results_GL = list()\n",
    "for threshold_value in threshold_values:\n",
    "    print(\"\\n\", ' '*5, \"threshold: \", threshold_value)\n",
    "    threshold['min'] = threshold_value\n",
    "    for memory_fine_value in memory_fine_values:\n",
    "        print(\"memory fine: \", memory_fine_value)\n",
    "        model = adaptive_random(64,\n",
    "                         vocabulary,\n",
    "                         characters_positions_in_vocabulary,\n",
    "                         30,\n",
    "                         1,\n",
    "                         [128],\n",
    "                         0.,\n",
    "                         threshold,    #{'fixed': True/False, 'min':  , 'max':  ,'epochs':  }\n",
    "                                normal_run_prob,\n",
    "                                0.07,\n",
    "                         train_text,\n",
    "                         valid_text)\n",
    "        text_list, trigger_list = model.run_for_analitics(model.get_triggers,\n",
    "                                                        'adaptive_random/new/variables/swpr0.1_th%s_mf%s' % (threshold_value, memory_fine_value),\n",
    "                                                        [100, 75, None])\n",
    "        triggers = list()\n",
    "        for text_number, text in enumerate(text_list):\n",
    "            trig = list()\n",
    "\n",
    "            text_triggers = trigger_list[text_number]\n",
    "            for text_trigger in text_triggers:\n",
    "                trig.append(text_trigger[0, 0])\n",
    "            triggers.append(trig)\n",
    "        structure_vocabulary_plots(text_list,\n",
    "                                   triggers,\n",
    "                                   'triggers for letter position (threshold %s, memory fine %s)' % (threshold_value, memory_fine_value),\n",
    "                                   'mean trigger',\n",
    "                                   ['adaptive_random', 'triggers', 'vocabulary_plots'],\n",
    "                                   'swpr0.1_ib0_th%s_mf%s' % (threshold_value, memory_fine_value),\n",
    "                                   show=False)\n",
    "        for i in range(99):\n",
    "            text_plot(text_list[i],\n",
    "                      triggers[i],\n",
    "                      'trigger',\n",
    "                      'triggers (threshold %s, memory fine %s)' % (threshold_value, memory_fine_value),\n",
    "                      ['adaptive_random', 'text_plots', 'new7', 'th%s_mf%s' % (threshold_value, memory_fine_value)],\n",
    "                      'swpr0.1_ib0_th%s_mf%s#%s' % (threshold_value, memory_fine_value, i),\n",
    "                      show=False)\n",
    "        model.destroy()\n",
    "        del model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
